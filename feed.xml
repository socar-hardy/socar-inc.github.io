<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.8.6">Jekyll</generator><link href="https://tech.socarcorp.kr/feed.xml" rel="self" type="application/atom+xml" /><link href="https://tech.socarcorp.kr/" rel="alternate" type="text/html" /><updated>2022-04-18T00:46:58+00:00</updated><id>https://tech.socarcorp.kr/feed.xml</id><title type="html">SOCAR Tech Blog</title><subtitle>쏘카 기술 블로그</subtitle><author><name>SOCAR</name></author><entry><title type="html">세차 인증 자동화 모델 개발 이야기</title><link href="https://tech.socarcorp.kr/data/2022/04/18/develop-model-classifying-washed-car.html" rel="alternate" type="text/html" title="세차 인증 자동화 모델 개발 이야기" /><published>2022-04-18T00:00:00+00:00</published><updated>2022-04-18T00:00:00+00:00</updated><id>https://tech.socarcorp.kr/data/2022/04/18/develop-model-classifying-washed-car</id><content type="html" xml:base="https://tech.socarcorp.kr/data/2022/04/18/develop-model-classifying-washed-car.html">&lt;p&gt;안녕하세요 쏘카 데이터 그룹 모델링 팀의 에스더(정현희)라고 합니다! 😎&lt;/p&gt;

&lt;p&gt;저는 computer vision 관련 다양한 task와 연구를 하고 있습니다. 이번 글에서는  &lt;strong&gt;세차 인증 자동화 모델을 개발한 과정&lt;/strong&gt;을 정리해보려고 합니다. 이 글을 끝까지 다 읽고 나면 현실에서 AI를 적용하여 비즈니스적인 임팩트를 내는 과정을 이해하실 수 있습니다.&lt;/p&gt;

&lt;h2 id=&quot;목차&quot;&gt;목차&lt;/h2&gt;

&lt;p&gt;목차는 다음과 같습니다&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;세차 인증 자동화는 왜 해야 할까&lt;/li&gt;
  &lt;li&gt;세차를 위한 데이터 스킴을 어떻게 정할 수 있을까&lt;/li&gt;
  &lt;li&gt;모델 적용기
    &lt;ul&gt;
      &lt;li&gt;3.1. 분류 모델 실험 과정&lt;/li&gt;
      &lt;li&gt;3.2. Rejection 모델 개발&lt;/li&gt;
      &lt;li&gt;3.3. 실무 적용 위한 External validation&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;이 글을 마치며&lt;/li&gt;
  &lt;li&gt;참고&lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;1-세차-인증-자동화는-왜-해야할까&quot;&gt;1. 세차 인증 자동화는 왜 해야할까&lt;/h2&gt;

&lt;p&gt;쏘카는 여러 유저가 쏘카의 차량을 공유하는 서비스입니다. 따라서 공유되는 차량을 주기적으로 세차해 주는 것이 중요한데, 이를 위해 반납 전 세차하는 고객에게 쏘카 크레딧을 제공해 주고 있습니다.&lt;/p&gt;

&lt;p&gt;쏘카 크레딧이 제공되는 과정은 다음과 같습니다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;고객은 세차장을 방문하여 세차를 진행합니다.&lt;/li&gt;
  &lt;li&gt;세차가 완료되면, 세차를 수행했음을 인증할 수 있는 사진을 쏘카 앱에 업로드합니다.&lt;/li&gt;
  &lt;li&gt;쏘카 직원이 업로드된 사진을 검토한 뒤, 크레딧 지급 여부를 결정합니다.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;하지만 서비스가 성장함에 따라 어느덧 담당 직원은 한 달에 6000건 이상 세차 사진을 보아야 하는 상황에 이르렀습니다. &lt;strong&gt;담당 직원은 단순 작업이 가중되었고, 고객에게도 크레딧 지급 여부 결과를 빠르게 받기 어려운 문제&lt;/strong&gt;가 생기게 되었습니다.&lt;/p&gt;

&lt;p&gt;이에 &lt;strong&gt;담당 직원을 대신하여 세차 인증을 해줄 딥러닝 모델&lt;/strong&gt;을 만들게 되었습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/develop-model-classifying-washed-car/0.png&quot; alt=&quot;0&quot; /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;2-세차를-위한-데이터-스킴을-어떻게-정할-수-있을까&quot;&gt;2. 세차를 위한 데이터 스킴을 어떻게 정할 수 있을까&lt;/h2&gt;

&lt;p&gt;딥러닝 관련 문제들을 풀다 보면, 중요한 것은 어떤 모델이나 프레임워크를 사용하는 것이 아니라 좋은 데이터를 사용하는 것임을 알 수 있습니다. 하지만 현실에서 수집되는 데이터는 우리가 생각하는 이상향과는 많이 다른 경우가 많습니다.&lt;/p&gt;

&lt;p&gt;같은 뷰로 찍은 사진이라도 접사가 있을 수 있고, 너무 멀리서 찍어서 어떤 것을 말하고자 하는 것인지 모를 때도 있습니다. 혹은 지금 풀고자 하는 문제와 완전히 distribution이 다른 데이터가 들어올 수도 있습니다. 이러다 보니, 비즈니스 문제 상황을 잘 표현하며 모델이 잘 학습할 수 있는 데이터 스킴을 만드는 작업이 매우 중요합니다.&lt;/p&gt;

&lt;p&gt;데이터 스킴에는 &lt;strong&gt;각 class마다 같은 characteristic을 가진 데이터&lt;/strong&gt;만이 속해있어야 합니다. 레이블러의 주관에 따라 달라질 수 있는 애매한 데이터들은 오히려 성능을 더 낮출 수도 있습니다. 따라서 전체 데이터 중에서 상대적으로 명확한 기준을 잡는 것은 매우 중요하지만 동시에 어려운 일이기도 합니다.&lt;/p&gt;

&lt;p&gt;저희 데이터 모델링 팀에서는 2020-2021, 약 2년간 적재된 고객 수행 세차 건 이미지 데이터를 분석하여 세차 여부를 검토하는 4개의 패턴을 발견할 수 있었습니다. 이에 따라 &lt;strong&gt;세차 여부를 분류해 주는 모델을 만들고, 분류가 애매한 이미지들을 매니저의 검토가 필요하도록 별도로 isolate 해주는 모델을 설계했습니다.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;분류 레이블은 크게 “인증 성공”과 “인증 보류” 2개로 나뉘고 구체적으로는 아래처럼 4개로 나뉩니다. 인증 성공과 보류로 거품이 묻어있는 외관이나 기계 세차장 내부에서 찍은 사진은 세차 인증으로 보고, 차량 외관만 찍은 사진이나 일반 차량 내부 사진들은 세차 인증 보류 클래스로 분류했습니다.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;(1) 인증 성공 : 외부에서 촬영한 거품 묻은 차량 이미지
(2) 인증 성공 : 내부에서 촬영한 기계 세차중인 이미지
(3) 인증 보류 : 세차 완료된 깨끗한 차량 이미지
(4) 인증 보류 : 일반 차량 내부 이미지
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;/img/develop-model-classifying-washed-car/1.png&quot; alt=&quot;1&quot; /&gt;&lt;/p&gt;

&lt;p&gt;아래처럼 명확한 분류 기준이 없는, 즉 사람이 검토해 줘야 할 애매한 경우에는 rejection 하도록 모델을 설계했습니다. 여기서 rejection 이란 4개의 분류 레이블 어느 것에도 속하지 않는 애매한 이미지가 들어올 경우, 완전히 다른 클래스인 rejection 클래스로 분류하는 것을 의미합니다. 저희는 아래와 같이, 우리가 분류하고자 하는 스킴에서 벗어나는 데이터들을 out-of-distribution 데이터라고 부르겠습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/develop-model-classifying-washed-car/2.png&quot; alt=&quot;2&quot; /&gt;&lt;/p&gt;

&lt;p&gt;세차를 위해 잡은 전체적인 구조는 아래와 같습니다. 첫 번째로 input으로 들어오는 데이터에 대해서 4-class classification을 진행하고, 그 output 값을 받아 open-set recognition을 적용하여 rejection class를 생성하는 형태로 보실 수 있습니다. 각 구조에 대한 자세한 설명은 &lt;code class=&quot;highlighter-rouge&quot;&gt;3. 모델 적용기&lt;/code&gt;에서 자세한 다루겠습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/develop-model-classifying-washed-car/3.png&quot; alt=&quot;3&quot; /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;3-모델-적용기&quot;&gt;3. 모델 적용기&lt;/h2&gt;

&lt;h3 id=&quot;31-모델-실험-과정&quot;&gt;3.1. 모델 실험 과정&lt;/h3&gt;

&lt;p&gt;세차 인증 모델을 만들기 위해 저희는 2가지 방법으로 접근했습니다. &lt;strong&gt;첫 번째 접근은 기본적인 supervised classifier 모델이었고, 두 번째 접근은 Image Retreival 활용하는 방식이었습니다.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Image Retreival은 간단하게 생각하면, training set의 이미지 feature 들을 데이터베이스에 저장해두고, 입력으로 들어오는 이미지와 가장 비슷한 이미지 k 개를 뽑아주는 방식의 접근입니다. 이 방식은 place recognition이나 map matching에서 많이 활용하는 접근 방법입니다. 세차 인증 시에도 결국 비슷한 차량의 부분들을 다른 view로 사진을 찍어 올라오게 되는 형태이므로 비슷한 접근으로 풀 수 있을 것이라고 생각했습니다.&lt;/p&gt;

&lt;p&gt;또 inference 시에 data-shift에 좀 더 유리할 것이라고도 생각했습니다. 예를 들어 “세차 기계 안에서 차 내부를 찍은 사진”과 “비가 많이 오는 날 차 내부를 찍은 사진”을 생각해 보면, 후자의 경우 training set에 없었다면 기본 분류 모델은 이 사진을 세차 완료로 잘못 분류할 수 있습니다. Image Retreival로 이 문제를 풀게 되면 feature vector가 다르게 생성되기 때문에 다른 클래스로 분류하게 될 수 있을 거라고 생각했습니다.&lt;/p&gt;

&lt;p&gt;저희는 Image Retreival 모델 중에서 place recognition 문제에서 높은 성능을 보였던 NetVLAD 모델을 저희 데이터에 맞게 변형하여 사용했고 classification 모델로는 resnet50을 사용했습니다.&lt;/p&gt;

&lt;p&gt;그리고 실험 결과는 다음과 같았습니다.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt; &lt;/th&gt;
      &lt;th&gt;NetVLAD&lt;/th&gt;
      &lt;th&gt;NetVLAD (w. self-supervision)&lt;/th&gt;
      &lt;th&gt;Supervised classifier&lt;/th&gt;
      &lt;th&gt;Supervised classifier (w. self-supervision)&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;test set acc&lt;/td&gt;
      &lt;td&gt;0.8694&lt;/td&gt;
      &lt;td&gt;0.8444&lt;/td&gt;
      &lt;td&gt;0.9583&lt;/td&gt;
      &lt;td&gt;0.9555&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;test set precision&lt;/td&gt;
      &lt;td&gt;0.8773&lt;/td&gt;
      &lt;td&gt;0.8604&lt;/td&gt;
      &lt;td&gt;0.9608&lt;/td&gt;
      &lt;td&gt;0.9565&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;test set recall&lt;/td&gt;
      &lt;td&gt;0.8759&lt;/td&gt;
      &lt;td&gt;0.8548&lt;/td&gt;
      &lt;td&gt;0.9576&lt;/td&gt;
      &lt;td&gt;0.9550&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;test set f1-score&lt;/td&gt;
      &lt;td&gt;0.8740&lt;/td&gt;
      &lt;td&gt;0.8556&lt;/td&gt;
      &lt;td&gt;0.9591&lt;/td&gt;
      &lt;td&gt;0.9557&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;이 실험을 통해 저희는 Imagenet pretrained Supervised classifier를 baseline으로 사용하기로 결정했고, 2가지 takeaway도 같이 정리해 볼 수 있었습니다.&lt;/p&gt;

&lt;h4 id=&quot;1-retreival-보다-supervised-classifier-사용했을-때가-성능이-더-좋다&quot;&gt;(1) Retreival 보다 Supervised classifier 사용했을 때가 성능이 더 좋다&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;대부분 Retrieval로 푸는 문제들을 보면 공통된 픽셀 값을 가지는 곳, 즉 이미지 내에서 같은 객체가 있는 곳을 landmark로 보고 같은 곳이라고 판단해 이 부분들을 매칭하는 방식을 사용합니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/img/develop-model-classifying-washed-car/4.png&quot; alt=&quot;4&quot; /&gt;
&lt;em&gt;patch Net-VLAD에서 비슷한 object가 있는 부분을 보고, 같은 place라고 예측하는 이미지&lt;/em&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;하지만 저희가 사용하는 사진의 경우는 같은 class 내에서 같은 object를 공유하는 형태가 아닙니다. 아래 사진과 같이 같은 “세차 보류 : 차량 내부” 사진이라도 핸들이 등장하는 경우도 있고 차량 시트 쪽이 등장하는 경우도 있기 때문에 feature space 상에서 유사하다고 판별하기 어려웠습니다. 따라서 motivation은 괜찮았지만 데이터 특성상 좋은 성능을 내기 힘들었습니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/img/develop-model-classifying-washed-car/5.png&quot; alt=&quot;5&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;2-self-supervised-learning-보다-imagenet-pretrained-weight을-사용했을때-성능이-더-좋다&quot;&gt;(2) self supervised learning 보다 Imagenet-pretrained weight을 사용했을때 성능이 더 좋다&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;저희는 upstream weight을 설계할 때 self-supervised weight을 사용하는 경우와 imagenet-pretrained weight을 사용하는 경우의 두 가지 성능도 같이 비교해 보았습니다&lt;/li&gt;
  &lt;li&gt;일반적으로 domain-specific 한 형태의 이미지에서는 self-supervision을 사용한 성능이 더 좋아야 했지만, 저희는 그렇지 않았습니다. 그 이유는 self-supervised learning을 학습한 데이터에 있었습니다&lt;/li&gt;
  &lt;li&gt;self-supervision weight의 training 데이터로 차종 분류 문제를 풀 때 사용했던 이미지를 사용했고, 해당 문제를 풀 때 좋은 성능을 냈던 weight을 가져와서 사용했습니다. 하지만 세차 인증을 위해서는 “깨끗한 외부 사진” 뿐만 아니라 “거품이 있는 외관”과 같은 fine-grained 한 특징까지 알아야 하므로 해당 weight으로는 좋은 성능을 내지 못했습니다.&lt;/li&gt;
  &lt;li&gt;더 좋은 성능을 내고자 했다면, 우리가 지금 풀고자 하는 fine-grained 한 문제를 푸는 도메인을 잘 이해하고 있는 모델로 self supervised learning 모델을 학습한 weight을 사용했었어야 합니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;32-rejection-모델-개발&quot;&gt;3.2. Rejection 모델 개발&lt;/h3&gt;

&lt;p&gt;이제 baseline classifier를 다 만들었다면, inference 시에 들어오는 out-of-distribution 데이터, 즉 저희가 classification 스킴 이외의 데이터가 들어온다면 이를 &lt;strong&gt;어떤 클래스로도 포함하지 않고 reject 하여 담당 매니저에게 검수를 요청하기 위한 모델을 개발&lt;/strong&gt;해야 합니다.&lt;/p&gt;

&lt;p&gt;예를 들어, 세차 인증을 위해 고객분들이 영수증을 찍어 업로드하시는 경우가 생각보다 많습니다. 이를 모델로 판단하기 위해서는 OCR로 영수증으로부터 텍스트를 읽어내고 다시 판단하는 과정을 거쳐야 하지만, 일단 지금 단계에서는 out-of-distribution으로 판단하고, reject 한 이후에 담당 매니저에게 검토를 요청하는 방식을 취하기로 결정했습니다.&lt;/p&gt;

&lt;p&gt;Rejection으로 들어가는 이미지는 다음과 같습니다. 영수증 사진이라 사람이 봐도 (세차 여부를 판단하기) 애매한 사진들 혹은 세차장 내부에서 찍은 사진인 것 같으나 역시나 애매한 사진들에 해당됩니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/develop-model-classifying-washed-car/6.png&quot; alt=&quot;6&quot; /&gt;&lt;/p&gt;

&lt;p&gt;이번에도 저희는 두 가지 접근 방법을 사용했는데요, &lt;strong&gt;첫 번째 방법은 모델 output의 certainty를 활용하여 threahold로 out-of-distribution 데이터를 골라내는 방식이고, 두 번째 방법은 open-set recognition 접근 방법을 사용했습니다.&lt;/strong&gt; 우선 첫 번째 방법으로 inference된 영수증 데이터들의 distribution을 확인해 본 그림은 아래와 같습니다. 아주 높은 certainty로 다른 in-of-distribution으로 예측하고 있으므로 이 데이터를 threaholding으로 reject 하기는 매우 어려워 보입니다. 이뿐만 아니라, 다른 애매한 사진들, 즉 사람의 판단이 필요한 데이터들이 들어왔을 때도 calibration problem 때문에 높은 certainty로 다른 클래스로 분류해버리는 문제가 생겼습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/develop-model-classifying-washed-car/7.png&quot; alt=&quot;7&quot; /&gt;&lt;/p&gt;

&lt;p&gt;따라서 &lt;strong&gt;두 번째 방법인 open-set recognition으로 넘어가게 되었는데요,&lt;/strong&gt; 이 방법의 접근 방법을 다음처럼 크게 두 가지로 떠올려볼 수 있는데요,&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;모델의 output logit 값을 이용해서 판단하는 방식&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;generative model을 활용하여 reject 될 만한 out-of-distribution을 일부러 만들어 이를 분류하는 모델을 추가적으로 개발하는 방식&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;저희는 좀 더 직관적이고 컴퓨팅 리소스가 덜 소모되는 &lt;strong&gt;1번 방법&lt;/strong&gt;을 사용하기로 했습니다. 또 SOTA로 분류되는 OpenHybrid, PROPOSER보다 더 간단하고 결과적으로도 더 좋은즉 “simple and effective”한 논문인 &lt;a href=&quot;https://arxiv.org/abs/2110.06207&quot;&gt;open set reocognition : a good closed-set classifier is all you need&lt;/a&gt;를 참고하여 저희 상황에 맞게 변형하여 실험 옵션을 구성해 보고자 했습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;첫 번째 실험에서의 calibration 문제를 해결하고자 label smoothing의 parameter를 조정해가면서 실험했고&lt;/li&gt;
  &lt;li&gt;softmax 전의 logit 값을 사용하여 thresholding 하는 실험을 진행했습니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;아래의 그림을 확인해 보면, 이 실험을 통해 어느 정도 bill, 즉 out-of-distribution으로 가장 대표적인 영수증 데이터가 thresholding으로 94% 정도 필터링 될 수 있음을 확인했습니다. 영수증 이외에 out-of-distribution으로 분류되는 다른 두 클래스의 경우(=human-hand-wash, ego-hand-wash)는 제대로 thresholding은 되지 않았지만, “사람이 직관적으로 판단하기에” 제대로 된 class에 분류되는 것을 확인했기에 큰 문제가 되지 않고 rejection 모델을 만들 수 있었습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/develop-model-classifying-washed-car/8.png&quot; alt=&quot;8&quot; /&gt;&lt;/p&gt;

&lt;p&gt;아래는 저희가 최종적으로 적용한 전체 구조입니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/develop-model-classifying-washed-car/9.png&quot; alt=&quot;9&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;33-실무-적용-위한-external-validation&quot;&gt;3.3. 실무 적용 위한 External Validation&lt;/h3&gt;

&lt;p&gt;모델의 최종 성능은 accuracy 기준 &lt;strong&gt;98%를 달성했습니다.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;마지막으로 &lt;strong&gt;실제 운영팀에서 세차 인증을 진행하는 단위로 External Validation을 수행&lt;/strong&gt;해보았습니다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;한 고객당 평균 3장의 이미지를 업로드 (=하나의 예약 건)&lt;/li&gt;
  &lt;li&gt;예약 건별로 세차 인증일지, 보류, 혹은 Rejection 일 지 예측&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;각 예약 건별로 한 장이라도 세차 인증 이미지가 들어있다면 해당 건은 세차 인증으로 분류했고, 전부 세차 보류라면 세차 보류로 분류했습니다. 또 Rejection으로 예측되는 이미지와 세차 보류의 이미지가 섞인 예약 건은 사람이 검수해 줄 수 있는 Rejection 클래스로 분류했습니다. 그리고 각 클래스마다의 precision을 확인해 보았습니다.&lt;/p&gt;

&lt;p&gt;모델이 “인증 성공”으로 분류한 건들의 97%는 실제로 사람도 인증을 해주고 있었습니다. 나머지 3%의 경우, 직접 이미지들을 확인해 보니, 월 3회 이상 세차 인증을 수행하여 쏘카 정책상 크레딧 지급이 불가능한 건들이었습니다. 즉 모델은 정확하게 판단했으나, 운영 정책상 사람이 인증해 주지 않은 부분이었기 때문에, 모델은 충분히 제 역할을 해주고 있다고 생각했습니다.&lt;/p&gt;

&lt;p&gt;또 모델이 “인증 보류”로 분류한 건들의 72%는 실제로 사람도 인증 보류를 해주고 있었습니다. 나머지 28%의 경우는, 아래 사진처럼 운영 정책상으로는 맞지 않지만 인간의 시각으로 봤을 때는 인증해 줘도 되는즉, 매니저 재량에 따라 달라지는 부분이었습니다. 이외에 모델이 판단하기에 애매한 사진들 즉 영수증 사진, 세차장 직원과 함께 찍힌 차량 사진 등은 사람이 검토할 수 있도록 rejection이 잘 되는 것까지 확인할 수 있었습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/develop-model-classifying-washed-car/9.png&quot; alt=&quot;10&quot; /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;4-이-글을-마치며&quot;&gt;4. 이 글을 마치며&lt;/h2&gt;

&lt;p&gt;이렇게 사내 직원의 단순 작업을 효율적으로 줄이면서도 고객에게 빠른 세차 피드백을 제공하기 위한 세차 모델의 첫 번째 모델을 마무리하게 되었습니다. 실제로 다양한 데이터를 보면서 Data-centric AI가 정말 현업에서는 중요하게 작용한다는 것을 다시 한번 느끼게 되었고 또 다양한 접근 방식을 통해 성능이 개선되는 과정을 통해 저 또한 많이 성장했던 것 같습니다.&lt;/p&gt;

&lt;p&gt;이후에는 실무에 실제로 도입하여 실제로 실무진 피드백을 받아볼 예정이고, 이를 통해 모델 개선을 해볼 예정에 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/develop-model-classifying-washed-car/11.png&quot; alt=&quot;11&quot; /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;5-참고&quot;&gt;5. 참고&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;NetVLAD : &lt;a href=&quot;https://arxiv.org/abs/1511.07247&quot;&gt;https://arxiv.org/abs/1511.07247&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Patch NetVLAD : &lt;a href=&quot;https://arxiv.org/abs/2103.01486&quot;&gt;https://arxiv.org/abs/2103.01486&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Open-Set Recognition : good closed set is all you need : &lt;a href=&quot;https://arxiv.org/abs/2110.06207&quot;&gt;https://arxiv.org/abs/2110.06207&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name>에스더</name></author><category term="data" /><category term="applied-research-scientist" /><category term="deep-learning" /><category term="ai" /><summary type="html">안녕하세요 쏘카 데이터 그룹 모델링 팀의 에스더(정현희)라고 합니다! 😎</summary></entry><entry><title type="html">쏘카 AI팀의 Applied Research Scientist는 어떤 일을 하나요?</title><link href="https://tech.socarcorp.kr/data/2022/04/05/role-of-applied-research-scientist-at-socar.html" rel="alternate" type="text/html" title="쏘카 AI팀의 Applied Research Scientist는 어떤 일을 하나요?" /><published>2022-04-05T00:00:00+00:00</published><updated>2022-04-05T00:00:00+00:00</updated><id>https://tech.socarcorp.kr/data/2022/04/05/role-of-applied-research-scientist-at-socar</id><content type="html" xml:base="https://tech.socarcorp.kr/data/2022/04/05/role-of-applied-research-scientist-at-socar.html">&lt;p&gt;안녕하세요, 쏘카 AI 팀의 케이피라고 합니다.&lt;/p&gt;

&lt;p&gt;저희 AI 팀은 다양한 데이터를 이용해 카셰어링 서비스의 운영을 효율화하고, 고객에게 더 나은 이동 경험을 제공하는 AI Product를 연구개발하고 있습니다. Computer Vision, Natural Language Processing 등의 도메인에서 현실의 문제를 해결하는 AI를 연구하고, 실질적인 Business Impact를 낼 수 있는 Product로 만들어가는 일을 하고 있습니다.&lt;/p&gt;

&lt;p&gt;최근 여러 기업에서 AI를 도입하면서 AI, Deep Learning, Machine Learning에 관련된 포지션이 많이 늘어나고 있습니다. 그러나 기업마다 정의하는 직무명이 나 요구하는 Responsibility가 달라서 헷갈려 하시는 분들을 종종 질문하는 분들이 많이 계셨습니다.&lt;/p&gt;

&lt;p&gt;이번 글에서는 AI에 관련된 포지션에 대해서 간단하게 정리해보고, 쏘카 AI팀의 Applied Research Scientist가 어떤 일을 하는지 소개드리고자 합니다. 이 글을 다 읽으시면 AI에 관련된 포지션이 요구하는 직무 역량에 대해 어느정도 윤곽을 잡고, 쏘카의 Applied Research Scientist가 어떤 일을 하는지도 이해하실 수 있습니다 :)&lt;/p&gt;

&lt;hr /&gt;
&lt;h2 id=&quot;목차&quot;&gt;목차&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;AI에 관련된 직무에는 무엇이 있을까?
    &lt;ul&gt;
      &lt;li&gt;Research Scientist&lt;/li&gt;
      &lt;li&gt;Applied Research Scientist&lt;/li&gt;
      &lt;li&gt;Machine Learning Engineer&lt;/li&gt;
      &lt;li&gt;Data Scientist&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;쏘카 AI팀은 어떤 일을 할까?
    &lt;ul&gt;
      &lt;li&gt;Vision Domain&lt;/li&gt;
      &lt;li&gt;NLP Domain&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;마무리&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;
&lt;h2 id=&quot;ai에-관련된-직무에는-무엇이-있을까&quot;&gt;AI에 관련된 직무에는 무엇이 있을까?&lt;/h2&gt;

&lt;p&gt;여러 회사의 Job Description들을 살펴보면, AI, Deep Learning, Machine Learning에 관련된 주요 포지션은 아래 4가지로 정리해 볼 수 있습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Research Scientist&lt;/li&gt;
  &lt;li&gt;Applied Research Scientist&lt;/li&gt;
  &lt;li&gt;Machine Learning Engineer&lt;/li&gt;
  &lt;li&gt;Data Scientist&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Research라는 단어가 포함된 포지션을 보면, Research와 Applied Research를 구분해두었습니다. 그뿐만 아니라, Scientist와 Engineer가 구분되어 있는 포지션도 있습니다. 직무 명만 봐서는 각 포지션이 어떤 일을 하는지 직관적으로 이해하기가 어렵습니다. 이번 글에서는 이 4가지 포지션이 주로 하는 일과 갖추어야 할 핵심 역량에 대해 간단하게 정리하고자 합니다. 이 글을 보시는 분들이 AI와 관련된 포지션을 찾는 데 도움이 되기를 바랍니다.&lt;/p&gt;

&lt;p&gt;단, 이 글에서 정리하는 정의가 정답은 아닙니다. 조직마다 추구하는 인재상이 다르고, 시간이 흐르면서 요구하는 역량이 달라질 수 있기 때문입니다. 어느 정도의 윤곽을 잡는 목적으로 참고해 주시면 감사드리겠습니다.&lt;/p&gt;

&lt;h3 id=&quot;research-scientist-어떻게-sota를-뛰어넘을-수-있을까&quot;&gt;Research Scientist: 어떻게 SOTA를 뛰어넘을 수 있을까?&lt;/h3&gt;

&lt;h4 id=&quot;concept&quot;&gt;Concept&lt;/h4&gt;

&lt;p&gt;Research Scientist는 AI에 관련된 원천 기술을 연구하는 포지션입니다. 특정 비즈니스 도메인 (i.e., 자율주행, 카셰어링 등)에만 적용할 수 있는 주제가 아닌, 여러 비즈니스 도메인에 적용될 수 있는 근간이 되는 원천 기술을 연구하는 포지션이라고 생각합니다.&lt;/p&gt;

&lt;p&gt;다양한 도메인에 적용할 수 있는 원천 기술을 연구하기 때문에, Research Scientist들은 여러 도메인의 연구자들이 이해하고 실험 결과를 납득할 수 있는 Public Benchmark Dataset을 이용하는 경우가 많습니다. &lt;strong&gt;Research Scientist는 Public Benchmark Dataset에서 이전 연구가 달성한 최고 성능 (State-of-the-Art; SOTA)를 넘어서는 기법을 연구하고, 이전 SOTA의 한계점을 보완하는 기법을 연구하기도 합니다.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;2010년 즈음부터 지금까지 이미지, 텍스트(자연어), 시계열, 생성(Generation) 등의 다양한 기법들의 SOTA가 개선되면서 AI 연구가 점점 성장하고 있습니다. 아직 해결되지 않은 문제들과 연구 주제들도 무수히 많이 남아있어, 더 많은 연구들이 등장할 것으로 기대하고 있습니다.&lt;/p&gt;

&lt;h4 id=&quot;key-responsibility&quot;&gt;Key Responsibility&lt;/h4&gt;

&lt;p&gt;Research Scientist는 과거에 제안된 연구들을 파악하고 새로운 연구를 수행해야 하기 때문에, 주로 요구되는 Responsibility는 아래와 같습니다. (조직마다 다르고, 시간이 흐름에 따라 변경될 수 있습니다)&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;기존에 제안된 연구들을 이해하고 구현할 수 있는 능력&lt;/li&gt;
  &lt;li&gt;기존 연구의 한계점을 개선할 수 있는 기법에 대한 Ideation 능력&lt;/li&gt;
  &lt;li&gt;독립적으로 연구 목적을 수립하고 실험 계획, 평가, 공유(논문 작성 등)를 수행할 수 있는 능력&lt;/li&gt;
  &lt;li&gt;다른 연구자들과 원활하게 소통하고 협력할 수 있는 능력&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;research-questions&quot;&gt;Research Questions&lt;/h4&gt;

&lt;p&gt;원활한 이해를 돕기 위해 Research Scientist가 고민할 만한 Research Question들을 한 번 정리해 보았습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Gradient Descent를 기반으로 Learning Objective를 달성하는 것이 아니라, 인간처럼 Reasoning을 하는 AI를 만들 수는 없을까?&lt;/li&gt;
  &lt;li&gt;이미지를 이해하는 여러 Neural Networks Architecture가 있는데, 특정한 패턴에 bias 되지 않고 더 인간처럼 이미지를 이해하는(혹은 인간보다 더 뛰어나게) 구조는 없을까?&lt;/li&gt;
  &lt;li&gt;최근에 제안된 Language Model (BERT, RoBERTa, S-BERT 등)보다 더 인간처럼 (혹은 인간보다 더 뛰어나게) 지식을 이해하는 모델은 없을까?&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;applied-research-scientist-우리-비즈니스-도메인의-문제를-어떻게-풀-수-있을까&quot;&gt;Applied Research Scientist: 우리 비즈니스 도메인의 문제를 어떻게 풀 수 있을까?&lt;/h3&gt;

&lt;h4 id=&quot;concept-1&quot;&gt;Concept&lt;/h4&gt;

&lt;p&gt;Applied Research Scientist는 특정 비즈니스 도메인의 문제를 풀 수 있는 AI를 연구하고, 연구된 모델을 배포하는 일을 수행하는 포지션입니다. &lt;strong&gt;Research Scientist가 여러 도메인에 범용적으로 적용될 수 있는 AI를 연구한다면, Applied Research Scientist는 특정 도메인에 최적화된 AI를 연구하고 이를 Production 환경에 맞게 구현하는 역할도 수행합니다.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Applied Research Scientist는 Public Benchmark Dataset을 이용하기도 하지만, 현실에서 발생한 Real-world Dataset을 주로 이용합니다. Real-world Dataset 이란 현실에서 발생하는 데이터 셋으로, 쏘카의 경우 카셰어링 서비스를 운영하면서 발생하는 여러 데이터 (i.e., 차량 이미지, 차량 센서, 채팅 텍스트 등)를 의미합니다. 조직이 직면하고 있는 문제를 해결하기 때문에, Public Benchmark Dataset은 논문에서 제안된 여러 기법의 성능을 확인하는 데 사용하고 주된 문제 해결에는 Real-world Dataset을 사용합니다. 하지만 세상만사 쉬운 일이 없듯이 public benchmark에서는 높은 성능을 달성한 기법(모델)이 Real-world Dataset에서는 잘 동작하지 않는 경우가 많습니다. &lt;strong&gt;Applied Research Scientist는 Public Benchmark와 Real-world의 차이를 고민하면서, SOTA 기법이 우리 도메인에서 왜 안되는지 (혹은 왜 잘 되는지)를 파악하고, 제안된 여러 기법들을 최적화하거나 새로운 기법을 디자인하기도 합니다.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;AI 연구에서 더 나아가, Applied Research Scientist는 Software Engineer, Data Engineer와 협업하여 AI 모델을 배포하는 과정에도 참여합니다. 리서치용으로 작성했던 코드를 배포 가능한 형태로 리팩토링하고, 다른 조직과 커뮤니케이션하며 배포에 필요한 요소들을 결정합니다. 그뿐만 아니라, AI 모델의 추론(Inference) 결과를 모니터링하여 Dataset Shift나 Feature Drift, Out-of-Distribution 샘플이 프로덕션에 들어오는지를 파악합니다.&lt;/p&gt;

&lt;h4 id=&quot;key-responsibility-1&quot;&gt;Key Responsibility&lt;/h4&gt;

&lt;p&gt;Applied Research Scientist는 도메인의 문제를 해결할 수 있는 AI를 연구하고, 다른 조직과 협업하여 배포하는 과정까지의 업무를 수행하므로, 주로 요구되는 Key Responsibility는 아래와 같습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;도메인에 대한 이해&lt;/li&gt;
  &lt;li&gt;기존에 제안된 연구들을 이해하고 구현할 수 있는 능력&lt;/li&gt;
  &lt;li&gt;기존에 제안된 연구를 도메인에 최적화하거나 더 나은 방법을 Ideation 할 수 있는 능력&lt;/li&gt;
  &lt;li&gt;독립적으로 연구 목적을 수립하고 실험 계획, 평가, 공유(논문 작성 등)를 수행할 수 있는 능력&lt;/li&gt;
  &lt;li&gt;다른 연구자, 엔지니어, End-User 들과 커뮤니케이션하고 니즈를 파악할 수 있는 능력&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;research-questions-1&quot;&gt;Research Questions&lt;/h4&gt;

&lt;p&gt;원활한 이해를 돕기 위해 Applied Research Scientist가 고민할 만한 Research Question들을 한 번 정리해 보았습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;논문 A는 ImageNet, SUN, Place 365에서 높은 성능을 달성했는데, 우리 도메인에서는 성능이 높지 않은데, 그 이유가 뭘지? 우리 데이터와 Public Benchmark에는 어떤 차이가 있어서 그럴까?&lt;/li&gt;
  &lt;li&gt;우리 도메인에서 다루는 데이터는 Public Benchmark들과는 너무 다른데, 우리 도메인에서 잘 동작하는 새로운 Neural Architecture를 디자인해 볼까?&lt;/li&gt;
  &lt;li&gt;모델 B가 배포되었을 때 낮은 Overhead를 달성하려면 코드를 어떻게 리팩토링 해야 할까? 모델에 들어가는 Input은 어떻게 설계하고, Inference 결과는 어떤 테이블에 어떻게 적재하지?&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;machine-learning-engineer-ai-모델을-어떻게-효과적으로-구현하고-서비스화-시킬까&quot;&gt;Machine Learning Engineer: AI 모델을 어떻게 효과적으로 구현하고 서비스화 시킬까?&lt;/h3&gt;

&lt;h4 id=&quot;concept-2&quot;&gt;Concept&lt;/h4&gt;

&lt;p&gt;Machine Learning Engineer는 AI 모델의 개발과 서비스에 더 무게를 두고 있는 포지션입니다. Scientist와 커뮤니케이션하며 모델을 구현하고, 효율적으로 모델을 학습시킬 수 있는 환경을 구축하기도 합니다. 모델이 학습이 완료된 이후에는, 효율적으로 Inference를 수행할 수 있는 아키텍처를 구성하거나 모델을 리팩토링합니다.&lt;/p&gt;

&lt;h4 id=&quot;key-responsibility-2&quot;&gt;Key Responsibility&lt;/h4&gt;

&lt;p&gt;전 문단에서 “효율”이라는 단어가 자주 등장했는데, Machine Learning Engineer는 특정 데이터 셋에서 성능을 향상시키기보다는 모델을 개발하고 운영하는 과정을 효율화하는 포지션입니다. AI 모델의 학습과 배포하는 단계에서 Machine Learning Engineer가 하는 일들을 나열해 보면, 아래 4가지 정도를 꼽아볼 수 있습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Scientist가 사용하는 데이터 셋을 효율적으로 구축하고 관리하기&lt;/li&gt;
  &lt;li&gt;AI 모델을 리팩토링하여 Computation Overhead 줄이기&lt;/li&gt;
  &lt;li&gt;GPU 클러스터를 더 효과적으로 사용할 수 있도록 최적화하기&lt;/li&gt;
  &lt;li&gt;반복적인 작업을 자동화할 수 있는 ML Pipeline 구성하기&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Machine Learning Engineer는 데이터 셋 구성에서부터 모델 구현, 학습 효율화, 그리고 배포에 이르는 AI 모델의 전 과정에 참여해 효율성을 높이고, 더 나아가 AI 조직의 생산성을 높이는 일을 수행합니다. Research Scientist, Applied Research Scientist뿐만 아니라 Software Engineer, Data Engineer와 자주 커뮤니케이션하면서 효율이 낮은 부분을 찾고, 기술적인 문제를 진단하며, 그 문제를 해결할 수 있는 방법을 찾는 것이 Machine Learning Engineer의 주요한 역할입니다.&lt;/p&gt;

&lt;h4 id=&quot;research-questions-2&quot;&gt;Research Questions&lt;/h4&gt;

&lt;p&gt;원활한 이해를 돕기 위해 Machine Learning Engineer가 고민할 질문들을 몇 개 가져왔습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;매 실험에 사용된 데이터 셋과 모델의 아키텍처, Weight 파일들이 관리가 어려운데, 이를 좀 효과적으로 관리할 수 있는 방법이 없을까?&lt;/li&gt;
  &lt;li&gt;Pytorch로 작성된 모델이 비효율적인 것 같아. 프로덕션에 들어가려면 더 Overhead를 낮춰야 할 것 같은데, Tensorflow로 이를 변환해 볼 수 있을까?&lt;/li&gt;
  &lt;li&gt;GPU의 개수는 많은데 그 성능을 100% 사용하지는 못하네. 최대한 효율적으로 GPU 자원을 사용할 수는 없을까?&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;data-scientist-데이터를-기반으로-어떤-action을-할-수-있을까&quot;&gt;Data Scientist: 데이터를 기반으로 어떤 Action을 할 수 있을까?&lt;/h3&gt;

&lt;h4 id=&quot;concept-3&quot;&gt;Concept&lt;/h4&gt;

&lt;p&gt;마지막으로, Data Scientist는 비즈니스 도메인에서 발생한 다양한 데이터를 분석하는 포지션입니다. 비즈니스의 여러 실무자와 커뮤니케이션하며 문제를 해결하며, 그 과정에서 필요한 다양한 업무를 진행합니다. 이때, 가장 중요한 것은 단순 Report가 아닌 Action을 위한 데이터 분석을 수행한다는 점입니다. 목적 없이 데이터를 분석하는 것이 아니라, 분석 결과를 기반으로 실무자가 실제 Action을 수행하기 위한 데이터 분석을 진행합니다.&lt;/p&gt;

&lt;h4 id=&quot;key-responsibility-3&quot;&gt;Key Responsibility&lt;/h4&gt;

&lt;p&gt;Data Scientist는 주로 비즈니스 도메인에서 발생하는 다양한 종류의 데이터를 다룹니다. 쏘카의 Data Scientist 포지션으로 예를 들어보겠습니다. 쏘카의 Data Scientist는 서비스의 앱, 웹 로그, 유저의 서비스 이용 데이터, 차량의 센서 데이터 등 다양한 영역에서 비즈니스 문제 해결을 위한 문제 정의, 가설 설정, 실험 설계와 성과 측정을 진행합니다. 쏘카는 주로 분석하는 데이터를 기준으로 Business Data Scientist와 Product Data Scientist로 나누어 채용하고 있는데, 공통적으로 요구되는 역량은 아래와 같습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;비즈니스 임팩트를 위한 문제 정의, 가설 설정, 실험 설계와 성과 측정 능력&lt;/li&gt;
  &lt;li&gt;데이터 기반 비즈니스 알고리즘 개발 능력&lt;/li&gt;
  &lt;li&gt;효과적인 데이터 분석을 위한 핵심 지표의 도출과 관리, 예측 모델링 능력&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;research-questions-3&quot;&gt;Research Questions&lt;/h4&gt;

&lt;p&gt;원활한 이해를 돕기 위해 Data Scientist가 고민할 질문들을 정리해 보았습니다. 이번에는 원활한 이해를 위해 Business Data Scientist와 Product Data Scientist로 나누어서 가져와 보았습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;(Business) 이번 주말에 강남역 10번 출구 쏘카 존의 예약 건은 얼마나 될까?&lt;/li&gt;
  &lt;li&gt;(Business) 2022년에 서울시 은평구에 몇 대의 차량을 배차하면 대 당 매출이 얼마나 될 것으로 예측할 수 있을까?&lt;/li&gt;
  &lt;li&gt;(Business) 가장 적은 매출이 나올 지역을 데이터에 기반해 찾아주는 알고리즘을 어떻게 만들 수 있을까?&lt;/li&gt;
  &lt;li&gt;(Product) 쏘카의 Funnel 중 가장 전환율이 낮은 부분은 어디일까? 그 부분을 개선하기 위해서는 어떤 Action을 할 수 있을까? 어떤 실험을 진행하면 이에 대한 결론을 얻을 수 있을까?&lt;/li&gt;
  &lt;li&gt;(Product) 새로운 기능 개발을 시작하려고 하는데, 이 기능 개발이 성공했다고 보려면 어떤 Metric을 결정해야 할까? 그 Metric을 보기 위해 어떤 앱, 웹 데이터를 로깅해야할까 새로운 기능을 AB Test 하려고 할 경우, 어떤 방법으로 설계할 수 있을까?&lt;/li&gt;
  &lt;li&gt;(Product) 새로운 기능이 출시된 이후에 성공적인지 확인하기 위해 대시보드는 어떻게 구성해야 할까?&lt;/li&gt;
  &lt;li&gt;더 자세한 내용은 쏘카의 &lt;a href=&quot;https://www.notion.so/socarcorp/d458b6b77a2243fb873d1ac800c321f7&quot;&gt;채용 노션 페이지&lt;/a&gt;를 참고하시면 좋을 것 같습니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;다시 한번 강조 드리고 싶은 점은, Research Scientist / Applied Research Scientist / Machine Learning Engineer / Data Scientist로 나누어진 포지션이 절대적인 기준이 아니라는 것입니다. AI에 관련된 일들이 칼로 무 자르듯이 나누기 어렵기 때문에, 조직마다 수행하는 역할이 겹치기도 하고 한 포지션에서 여러 역할을 수행하는 경우도 많습니다. 각 조직이 풀고 있는 문제, 성향, 문화 등 여러 가지 요인이 작용하여 포지션을 구성하기 때문에, JD를 보실 때 참조하는 용도로 이 글을 읽으시는 것을 추천합니다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;쏘카-ai팀은-어떤-일을-할까&quot;&gt;쏘카 AI팀은 어떤 일을 할까?&lt;/h2&gt;

&lt;p&gt;쏘카의 AI 팀은 Human-Interactive AI System라는 목표 아래, Vision, NLP 기술을 활용해 카셰어링 서비스에서 발생하는 여러 문제를 해결하고 있습니다. “Human-Interactive”라는 말이 다소 생소하실 텐데요, 저희 팀이 정의한 &lt;strong&gt;Human-Interactive AI System 이란 End User(사람)의 피드백을 기반으로 지속적으로 성장하는 시스템으로, 현실에서 Robust 하게 동작하여 비즈니스 임팩트를 내는 AI 시스템을 뜻합니다.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/role-of-applied-research-scientist-at-socar/human_in_the_loop.png&quot; alt=&quot;&quot; /&gt;
&lt;em&gt;&lt;a href=&quot;https://hai.stanford.edu/news/humans-loop-design-interactive-ai-systems&quot;&gt;Human-Interactive AI(Human-In-The-Loop)&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;

&lt;h3 id=&quot;vision-domain&quot;&gt;Vision Domain&lt;/h3&gt;

&lt;p&gt;현실에서 Robust 한 AI 시스템을 디자인하기 위해서는 많은 고민들이 필요합니다. 먼저 Vision 도메인에서 간단한 예를 들어보겠습니다.&lt;/p&gt;

&lt;p&gt;경차와 중형차 이미지를 구분하는 이진 차종 분류 모델 (Binary Classifier)이 존재한다고 가정해 봅시다. 이진 분류기를 만드는 것은 간단합니다. DB에 쿼리를 날려 경차와 중형차 이미지를 수집하고, 레이블링을 수행하고, ResNet과 같은 Neural Network Architecture에 Cross Entropy Loss를 설정하여 분류 모델을 학습시키면 됩니다. 그러나 이 분류기가 현실에 배포되기 위해서는 더 깊고, 다양한 고민이 필요합니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/role-of-applied-research-scientist-at-socar/car_images.png&quot; alt=&quot;&quot; /&gt;
&lt;em&gt;경차(왼쪽)와 SUV(오른쪽) 이미지 예시&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;만약 분류기에 들어가는 Inference 이미지가 경차도, 중형 차도 아닌 경우에는 어떻게 해야 할까요? 자동차 사진이 아니라 음식 사진, 차종을 판단할 수 없는 사진, 심한 blur 등으로 식별할 수 없는 사진이 들어오면 어떻게 처리해야 할까요?&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/role-of-applied-research-scientist-at-socar/not_car_images.png&quot; alt=&quot;&quot; /&gt;
&lt;em&gt;차종 분류와 관련없는 이미지들 예시&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;모델이 풀고자 하는 Task에 관련 없는 이미지 (Out-of-Distribution sample)가 분류기에 들어오면, Supervised Learing 패러다임으로 학습된 분류기는 무조건 경차나 중형차 중에 하나로 판단을 내리게 됩니다. 즉, 불필요하고 잘못된 정보가 Inference 되어 End-User에게 전달됩니다. (고기 사진을 경차라고 판단하여 실무자에게 전달하는 것입니다!) 이러한 문제는 어떻게 해결할 수 있을까요? &lt;strong&gt;사전에 경차나 중형 차에 속하지 않는다고 판단하면서 (Out-of-Distribution Detection), 기존 분류기의 성능을 유지할 수는 없을까요? (Open-Set Recognition)&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;다른 관점에서 차종 분류 모델을 살펴보겠습니다. CNN 기반의 분류 모델은 이미지가 들어왔을 때, 해당 이미지에 대한 예측의 Confidence를 갖습니다. 이 Confidence가 특정 이미지가 Class에 속할 Probability(확률)이라고 말할 수 있을까요? 일반적인 CNN들은 대부분의 판단에 대해 overly-confident 한 예측을 수행하는 Overconfidence Problem을 가지고 있습니다. 이때, 과도하게 높은 Confidence를 갖는 문제를 어떻게 해결할 수 있을까요? &lt;strong&gt;잘못된 예측을 수행했을 때는 less-confident 하게 틀리고, 옳은 예측에 대해서는 more confident 하게 맞추도록 할 수는 없을까요? (Calibration) 실무에서는 모델의 예측 결과뿐만 아니라, 모델이 확실하게 예측한 건들을 먼저 검토하고자 하는데, 이 확신의 정도를 어떻게 잘 측정할 수 있을까요?&lt;/strong&gt;&lt;/p&gt;

&lt;h3 id=&quot;nlp-domain&quot;&gt;NLP Domain&lt;/h3&gt;

&lt;p&gt;AI 팀에서는 고객이 쏘카 이용 중 겪을 수 있는 문제를 빠르게 해결해 줄 수 있는 채팅 AI(Dialogue Sytem)를 연구하고 있습니다. 예를 들어, 고객이 겪는 문제 상황을 이해하기 위해 간단한 Intent Classifier가 있다고 가정해 보겠습니다. 고객의 여러 문제상황(Intent)들 중 “쏘카 존에 반납이 불가능해요”라는 Intent가 있을 때, 아래와 같은 고객의 문의들은 어떻게 처리할 수 있을까요?&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;1) “쏘카 존 입구가 어디에 있는지 몰라서 반납을 못하겠어요”&lt;/li&gt;
  &lt;li&gt;2) “쏘카 존이 침수되어 진입이 불가능해서 반납을 못할 것 같아요”&lt;/li&gt;
  &lt;li&gt;3) “차단기가 열리지 않아 쏘카 존에 들어갈 수 없어요. 어떻게 할까요?”&lt;/li&gt;
  &lt;li&gt;4) “기름이 떨어져서 차량이 중간에 멈췄어요. 쏘카 존에 반납을 못하겠어요.”&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;이 문의들은 공통적으로 “쏘카 존에 반납이 불가능하다”라고 생각할 수 있지만, 각 문의들은 모두 다른 Reply가 필요합니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;1의 경우 쏘카 존 입구를 안내드려야 하고&lt;/li&gt;
  &lt;li&gt;2의 경우 인근 쏘카 존을 안내드려야 하고&lt;/li&gt;
  &lt;li&gt;3의 경우 쏘카 존 관리자와의 커뮤니케이션이 필요하며&lt;/li&gt;
  &lt;li&gt;4의 경우 긴급출동이 필요합니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;고객이 필요로 하는 솔루션이 각기 다른데, 이 문의들을 하나의 Intent로 묶을 수 있을까요? 혹은 한 문장에 여러 가지 문제가 섞여있을 때는 어떻게 처리할 수 있을까요? (Multi-Labeled Sample)&lt;/strong&gt; 뿐만 아니라, &lt;strong&gt;사전에 정의해둔 Intent에서 벗어난 문의는 어떻게 응답해야 할까요? (Unknown Intent Detection)&lt;/strong&gt; Vision 도메인에서와 마찬가지로, 고객의 문의에 대해 &lt;strong&gt;예측한 Intent에 대한 Confidence를 어떻게 측정할 수 있을까요?&lt;/strong&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;마무리&quot;&gt;마무리&lt;/h2&gt;

&lt;p&gt;쏘카의 AI 팀은 이러한 고민들을 해결하기 위해 여러 분야의 논문을 스터디하고 구현하며, 실무에 적용하고 있습니다. 과거 논문에서 제안된 기법을 이용하는 것뿐만 아니라, 비즈니스 도메인에서 최적의 성능을 달성하는 새로운 기법을 디자인하기도 합니다. 기술적인 문제를 해결한 후에는 다른 팀과 협업하며 현실에서 Business Impact을 달성합니다. 데이터 사이언스 팀과 협업하여 개발한 AI가 가져올 임팩트를 산정하기도 하고, 엔지니어링 그룹과 협업하여 모델을 배포하고, 모델의 예측 결과를 모니터링합니다. 모델을 실무에 적용하고 프로젝트의 한 Cycle을 완수한 이후, End-User의 피드백을 기반으로 모델을 성장시키고 있습니다 (Human-in-the-Loop).&lt;/p&gt;

&lt;p&gt;앞으로 이어질 테크 블로그 글에서는 쏘카 AI 팀이 비즈니스의 문제를 해결한 Case들을 소개하고, Conference나 Journal에 Publish 한 저희 팀의 연구 실적에 대해서도 소개 드리고 자 합니다.&lt;/p&gt;

&lt;p&gt;다음 글에서 뵙겠습니다. 긴 글 읽어주셔서 감사합니다!&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;AI 팀에서는 Human-Interactive AI System을 함께 만들어갈 Applied Research Scientist를 채용하고 있습니다. AI 팀 채용에 관심이 있으시다면, 저희 &lt;a href=&quot;https://www.notion.so/socarcorp/Applied-Research-Scientist-78d277441aba4b8e91b2f053abb8f2c0&quot;&gt;채용 페이지&lt;/a&gt;에 방문하셔서 공고를 확인해 주시면 감사드리겠습니다.&lt;/p&gt;
&lt;/blockquote&gt;</content><author><name>케이피</name></author><category term="data" /><category term="applied-research-scientist" /><category term="deep-learning" /><category term="ai" /><summary type="html">안녕하세요, 쏘카 AI 팀의 케이피라고 합니다.</summary></entry><entry><title type="html">CES 2022 - 미래 모빌리티를 만나다</title><link href="https://tech.socarcorp.kr/product/2022/03/31/ces2022-review-by-gigi.html" rel="alternate" type="text/html" title="CES 2022 - 미래 모빌리티를 만나다" /><published>2022-03-31T01:00:00+00:00</published><updated>2022-03-31T01:00:00+00:00</updated><id>https://tech.socarcorp.kr/product/2022/03/31/ces2022-review-by-gigi</id><content type="html" xml:base="https://tech.socarcorp.kr/product/2022/03/31/ces2022-review-by-gigi.html">&lt;p&gt;안녕하세요. 저는 쏘카에서 신규 서비스를 기획하는 프로덕트 매니저 지지입니다. 올해 1월, 저는 프로덕트 본부를 대표하여 모빌리티 서비스의 동향을 파악하고자 CES(Consumer Electronics Show) 2022에 다녀왔습니다.&lt;/p&gt;

&lt;p&gt;CES는 익히 알려진 것처럼 세계 최대 IT 제품 박람회입니다. 몇 년 전부터 CES에서 모빌리티 분야는 모빌리티 전시관(Vehicle Technology, Self-Driving Cars)이 따로 운영될 만큼 핵심 분야로 자리매김하고 있습니다. 여러 매체의 기사를 통해서 CES 행사장에 전시된 제품에 대해서는 많이 접해보셨을 텐데요. 저는 CES 행사가 열린 라스베이거스에서 체험해 볼 수 있는 미래 모빌리티 제품 경험을 공유드리려 합니다.&lt;/p&gt;

&lt;h2 id=&quot;목차&quot;&gt;목차&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;리프트(Lyft)의 자율주행 택시
    &lt;ul&gt;
      &lt;li&gt;라스베이거스 특산품, 자율주행 택시&lt;/li&gt;
      &lt;li&gt;자율주행 택시 이용하기&lt;/li&gt;
      &lt;li&gt;비대면 커뮤니케이션은 어디까지 가능할까&lt;/li&gt;
      &lt;li&gt;고객 경험을 특별하게 하기&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;베이거스 루프(Vegas Loop) 체험
    &lt;ul&gt;
      &lt;li&gt;이동 수단인가, 놀이 기구인가&lt;/li&gt;
      &lt;li&gt;막힘없는 이동 경험&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;시속 300Km의 자율주행 레이싱
    &lt;ul&gt;
      &lt;li&gt;스포츠도 로봇 간 경쟁 시대&lt;/li&gt;
      &lt;li&gt;사람의 마음이 담긴 레이싱카&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;가까이 다가온 미래 모빌리티
    &lt;ul&gt;
      &lt;li&gt;트랙터부터 우주선까지 모빌리티화&lt;/li&gt;
      &lt;li&gt;쏘카가 그리는 미래 모빌리티&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;리프트lyft의-자율주행-택시&quot;&gt;리프트(Lyft)의 자율주행 택시&lt;/h2&gt;

&lt;h3 id=&quot;라스베이거스-특산품-자율주행-택시&quot;&gt;라스베이거스 특산품, 자율주행 택시&lt;/h3&gt;

&lt;p&gt;라스베이거스 시내에서 이동할 일이 있어서 리프트(Lyft) 앱을 실행해 보니 처음 보는 자율주행 표기가 된 리프트 차량이 눈에 띄었습니다. 자율 주행 택시는 간혹 뉴스에서나 보던 터라 정말로 자율주행 차량인가 궁금증이 들었고 일단 타보자 싶어서 차를 호출해 봤습니다. 탑승 이후에 찾아보니 이 택시는 라스베이거스에서는 이미 2021년 11월부터 현대와 앱티브(Aptiv)가 합작한 모셔널(Motional)이 리프트를 통해서 자율주행 택시를 시범 운행 중인 서비스였습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/ces2022-review-by-gigi/1.jpg&quot; alt=&quot;1&quot; /&gt;
&lt;em&gt;외관상 차량이 특별해 보이지 않지만, 하드웨어 담당 동료로부터 차량에 설치된 라이다나 카메라에 대한 설명을 듣고 나니 좀 더 특별해 보였습니다.&lt;/em&gt;&lt;/p&gt;

&lt;h3 id=&quot;자율주행-택시-이용하기&quot;&gt;자율주행 택시 이용하기&lt;/h3&gt;

&lt;p&gt;리프트(Lyft) 앱에서 차량을 호출할 때에는 먼저 자율주행 차량이라는 점과 두 명의 안전 직원이 상주하고 있다는 내용이 안내되었습니다. 이어서 &lt;strong&gt;별도의 신규 서비스 메뉴로 진입할 필요 없이 기존 리프트 차량을 이용하는 방식과 동일하게 차량을 호출할 수 있었습니다&lt;/strong&gt;. 사용자에게 자연스럽게 시범 서비스를 이용하도록 유도하고 추가로 안내가 필요한 정보만 잘 제공하였다는 느낌을 받았습니다.&lt;/p&gt;

&lt;p&gt;세세한 부분에서는 다른 점도 있었습니다. 기존 리프트 차량은 운행이 종료되면 드라이버에게 팁을 권유하는 안내 문구가 보였는데 자율주행 이용 후에는 별도의 팁 권유가 없는 점은 재밌는 부분이었습니다. 아무래도 무인 차량이다 보니 팁을 줄 필요가 없다는 이치가 자연스럽게 느껴졌습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/ces2022-review-by-gigi/2.png&quot; alt=&quot;2&quot; /&gt;
&lt;em&gt;기존 차량 호출 과정과 크게 다르지 않은 대신, Self-Driving 차량임을 인지하도록 안내합니다.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/ces2022-review-by-gigi/3.jpg&quot; alt=&quot;3&quot; /&gt;
&lt;em&gt;10분 정도 탑승했는데 택시비는 만 오천 원이 나왔네요. 라스베이거스 물가는 상당히 비싼 편이에요.&lt;/em&gt;&lt;/p&gt;

&lt;h3 id=&quot;비대면-커뮤니케이션은-어디까지-가능할까&quot;&gt;비대면 커뮤니케이션은 어디까지 가능할까&lt;/h3&gt;

&lt;p&gt;차량에 탑승하니 보조석에 앉은 직원분께서 간단히 이용 안내를 해주셨습니다. 실제 자율주행 과정과 유사한 환경이 되도록 &lt;strong&gt;문의 사항이나 궁금한 점이 있을 경우에는 뒷좌석 앞에 부착된 태블릿을 통해서 문의할 수 있다고 합니다.&lt;/strong&gt; 주행 중에 태블릿에서는 제 이름과 간단한 안내 문구, 문의를 할 수 있는 버튼, 그리고 실시간으로 이동 경로가 안내되었습니다.&lt;/p&gt;

&lt;p&gt;그럼에도, 자율주행 택시에서는 오로지 태블릿을 통해 소통해야 하는 점에 대해 의문인 점도 있었습니다. 즉각적으로 하차할 장소를 변경하거나, 또 운행 중 발생할 수 있는 긴급한 연락할 일이 생겼을 때 과연 이 태블릿으로 빠른 소통이 가능할까 하는 생각이 들었습니다.&lt;/p&gt;

&lt;p&gt;비대면 또는 무인 기반의 자율주행 서비스가 좀 더 보편화된다면 탑승 과정에서 발생하는 &lt;strong&gt;일상적인 문의에 대한 대응을 쉽게 할 수 있는 방식에 대한 고민이 필요해 보였고, 또 불편한 분들을 위해 화장실에 설치된 긴급 호출 버튼처럼 대응할 수 있는 장치가 필요하지 않을까&lt;/strong&gt;라는 생각이 들었습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/ces2022-review-by-gigi/4.png&quot; alt=&quot;4&quot; /&gt;
&lt;em&gt;좌석 앞에 비치된 태블릿은 탑승 전 환영부터 이동 경로 안내, 문의 사항 전달, 탑승 완료를 안내하는 역할을 합니다.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/ces2022-review-by-gigi/5.jpg&quot; alt=&quot;5&quot; /&gt;
&lt;em&gt;때로는 이런 긴급 버튼이 더 안전한 대안이 될 수도 있겠다는 생각을 했습니다.&lt;/em&gt;&lt;/p&gt;

&lt;h3 id=&quot;고객-경험을-특별하게-하기&quot;&gt;고객 경험을 특별하게 하기&lt;/h3&gt;

&lt;p&gt;자율 주행이 탑재된 상용 택시를 타본다는 것이 제게는 새롭고 흥분되는 경험이었는데요. 그럼에도 불구하고, 앱에서 차량을 호출하거나 차량을 탑승할 때를 돌이켜보면 크게 이를 느끼게 한다는 인상은 없었습니다. 그래서 저도 운행이 끝나고 리프트의 블로그를 통해서나마 좀 더 자세한 내용을 알 수 있었는데요.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/ces2022-review-by-gigi/6.png&quot; alt=&quot;6&quot; /&gt;
&lt;em&gt;리프트 블로그에 자율주행 택시 도입에 관한 &lt;a href=&quot;https://www.lyft.com/blog/posts/motional-and-lyft-to-launch-fully-driverless-ride-hail-service-in-las-vegas&quot;&gt;글&lt;/a&gt;이 있었습니다.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;저는 좀 더 &lt;strong&gt;탑승자가 자율주행 택시임을 느낄 수 있도록 장치를 만들어뒀으면 훨씬 더 특별한 이용 경험으로 만들 수 있지 않았을까&lt;/strong&gt;란 생각이 들었습니다.&lt;/p&gt;

&lt;p&gt;예를 들어 리프트 차량에서는 자율주행 기술이 적용되는 때에는 운전자가 보는 디스플레이에 작은 글씨로 “AUTO”라고 표시된 것으로 알 수 있었는데요. 탑승자도 이를 차량 내에서 식별할 수 있도록 표현해 줄 수 있지 않을까 상상했습니다. 또, 태블릿에 자율주행으로 주행되는 경로를 표현해 줘서 자율주행이 어떤 판단을 하였는지를 알 수 있으면 “자율주행 기술이 어떤 판단을 하여 차선을 바꿨구나”라는 구체적인 생각으로 연결되지 않을까 생각이 들었습니다.&lt;/p&gt;

&lt;p&gt;이처럼 새로운 서비스나 기술을 선보일 때에는 &lt;strong&gt;기술적인 완성 이외에도, 사람이 탑승하고 그 사람을 위한 서비스이니 자율주행을 체험하는 사용자를 고려할 필요가 있지 않을까&lt;/strong&gt;라는 생각이 들었습니다.&lt;/p&gt;

&lt;p&gt;그럼에도, 실제로 신호등에 따라 차량이 서기도 하고, 목적지에 다다르니 인도 옆 차선까지 스스로 이동하는 것을 체험해 보니 자율주행 기술이 코앞까지 왔음을 실감할 수 있었습니다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;베이거스-루프vegas-loop-체험&quot;&gt;베이거스 루프(Vegas Loop) 체험&lt;/h2&gt;

&lt;h3 id=&quot;이동-수단인가-놀이-기구인가&quot;&gt;이동 수단인가, 놀이 기구인가&lt;/h3&gt;

&lt;p&gt;라스베이거스에서만 체험할 수 있는 또 하나의 교통수단으로 라스베이거스 컨벤션 센터(LVCC)의 웨스트홀, 사우스홀, 노스홀 구간을 오가는 베이거스 루프가 있습니다. 베이거스 루프는 일론 머스크의 보링 컴퍼니에서 제작하였는데 라스베이거스 지하에 터널을 뚫어서 라스베이거스 주요 도심의 교통 체증을 해소하는 것을 목표로 현재 컨벤션 센터 주변에서 운행되고 있습니다.&lt;/p&gt;

&lt;p&gt;베이거스 루프를 탑승하기 위해 승차장인 지하로 내려가면 안내하는 직원이 있고, 직원으로부터 탑승할 구역을 안내받아서 대기하였습니다. 곧 테슬라 차량이 탑승 구역에 도착하였고, 차량에 탑승하여 운전자에게 가고자 하는 홀을 이야기하니 차량은 곧 출발하였습니다.&lt;/p&gt;

&lt;p&gt;재밌는 점은 구간이 그리 길지 않아서 차량 탑승 시간은 1, 2분 이내이지만 탑승장 내 울리는 음악과 터널 구간의 조명 때문인지 왠지 테마파크의 놀이 기구를 탑승하는 기분으로 자주 애용하게 되었습니다.&lt;/p&gt;

&lt;div style=&quot;padding:56.25% 0 0 0;position:relative;&quot;&gt;&lt;iframe src=&quot;https://player.vimeo.com/video/693440889?h=a156dcdff5&amp;amp;badge=0&amp;amp;autopause=0&amp;amp;player_id=0&amp;amp;app_id=58479&quot; frameborder=&quot;0&quot; allow=&quot;autoplay; fullscreen; picture-in-picture&quot; allowfullscreen=&quot;&quot; style=&quot;position:absolute;top:0;left:0;width:100%;height:100%;&quot; title=&quot;PXL_20220105_233317086.mp4&quot;&gt;&lt;/iframe&gt;&lt;/div&gt;
&lt;script src=&quot;https://player.vimeo.com/api/player.js&quot;&gt;&lt;/script&gt;

&lt;h3 id=&quot;막힘없는-이동-경험&quot;&gt;막힘없는 이동 경험&lt;/h3&gt;

&lt;p&gt;베이거스 루프를 이용해 보면 탑승장에 들어서서 이동 후 차량에서 내리기까지 막힘이 없다는 인상을 줍니다. 차량을 선택하고 목적지로 호출하는 등 고민할 필요 없이 그저 원하는 장소를 떠올리고 이동해서 기다리면 되었는데요. 짧은 거리이지만 탑승 후 일 방향의 지하 터널로 이동하다 보니 트래픽을 마주할 일도 없고, 어떤 경로로 이동할지 고민할 필요 없이 목적지로 이어지는 구간을 따라가다 보면 목적지에 다다르는 경험은 새로웠습니다.&lt;/p&gt;

&lt;div style=&quot;padding:56.25% 0 0 0;position:relative;&quot;&gt;&lt;iframe src=&quot;https://player.vimeo.com/video/693440867?h=e2d46a7392&amp;amp;badge=0&amp;amp;autopause=0&amp;amp;player_id=0&amp;amp;app_id=58479&quot; frameborder=&quot;0&quot; allow=&quot;autoplay; fullscreen; picture-in-picture&quot; allowfullscreen=&quot;&quot; style=&quot;position:absolute;top:0;left:0;width:100%;height:100%;&quot; title=&quot;PXL_20220105_233426550.mp4&quot;&gt;&lt;/iframe&gt;&lt;/div&gt;
&lt;script src=&quot;https://player.vimeo.com/api/player.js&quot;&gt;&lt;/script&gt;

&lt;p&gt;베이거스 루프를 직접 체험해 보니 일부 기술의 한계도 보입니다. 베이거스 루프의 구간은 2km 남짓으로 길지 않은 구간이며 법적인 제한으로 인하여 자율주행 운행이 제한되기도 하였습니다. 그래서 사람이 1-2분의 구간을 운전해 주는데 꼭 차로 이러한 터널을 이동해야 하나 싶은 생각도 들었습니다.&lt;/p&gt;

&lt;p&gt;그럼에도, 일론 머스크는 베이거스 루프는 본 사업의 시작에 그치지 않는다고 합니다. 베이거스 루프보다 더 첨단 기술로 구현한 하이퍼 루프를 통해서 라스베이거스 도심을 벗어나 샌프란시스코까지 30분 만에 이동할 수 있는 교통수단을 만드는 것을 장기적인 목표라고 하는데요. 아직은 사람이 자동차를 통해 라스베이거스 일부 지하에서만 이동하는 것에 그치는 수준이지만, 머지않아 하이퍼 루프가 실현된다면 한 번쯤 다시 이곳에 와서 이용해 보고 싶다는 생각이 들었습니다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;시속-300km의-자율주행-레이싱&quot;&gt;시속 300Km의 자율주행 레이싱&lt;/h2&gt;

&lt;h3 id=&quot;스포츠도-로봇-간-경쟁-시대&quot;&gt;스포츠도 로봇 간 경쟁 시대&lt;/h3&gt;

&lt;p&gt;이번 CES2022 야외 행사로 라스베이거스 모터 스피드웨이(Las Vegas Motor Speedway, LVMS) 경기장에서 자율주행 레이싱 경기(Autonomous Challenge)가 열렸습니다. 이번 대회에 전 세계의 8개의 대학팀이 참여하였고 국내에서는 카이스트가 한국 대표로 출전하였습니다.&lt;/p&gt;

&lt;p&gt;자율주행 레이싱은 일반 자율주행 자동차와 몇 가지 차이가 있습니다. 먼저, 최대 300Km의 속도에서도 자율 주행 센서가 안정적으로 동작해야 하며 경쟁 경기에서는 공기저항을 줄이기 위해 앞차의 경로를 따라야 합니다.&lt;/p&gt;

&lt;p&gt;또, 주행 중 차량에 이상이 있을 시에는 벽이나 사물에 충돌하지 않도록 스스로 멈추는 상황도 고려되어야 하는데요. 이처럼 자율주행 레이싱은 가장 극한의 자율주행 기술로 현재 개발 중인 자율주행 기술이 어느 수준까지 다다른 상태인지 체감할 수 있는 스포츠입니다.&lt;/p&gt;

&lt;div style=&quot;padding:56.25% 0 0 0;position:relative;&quot;&gt;&lt;iframe src=&quot;https://player.vimeo.com/video/693440806?h=5aeeb94baf&amp;amp;badge=0&amp;amp;autopause=0&amp;amp;player_id=0&amp;amp;app_id=58479&quot; frameborder=&quot;0&quot; allow=&quot;autoplay; fullscreen; picture-in-picture&quot; allowfullscreen=&quot;&quot; style=&quot;position:absolute;top:0;left:0;width:100%;height:100%;&quot; title=&quot;PXL_20220107_204436844.mp4&quot;&gt;&lt;/iframe&gt;&lt;/div&gt;
&lt;script src=&quot;https://player.vimeo.com/api/player.js&quot;&gt;&lt;/script&gt;

&lt;h3 id=&quot;사람의-마음이-담긴-레이싱카&quot;&gt;사람의 마음이 담긴 레이싱카&lt;/h3&gt;

&lt;p&gt;자율주행 레이싱은 이제 시범 도입되는 단계이기에 우리가 아는 레이싱 경기처럼 박진감 넘치는 경기는 아니었습니다. 두 가지 경기 방식으로 진행이 되었는데 하나는, 차량별로 한 대씩 누가 더 빠른 속도를 내는지를 겨루는 기록 경쟁 방식이 있었고, 또 하나는 두 대가 같이 주행하되 서로 공격 순서를 정해서 뒤 차가 앞차를 추월하는 턴 방식으로 진행되는 등 정해진 규칙 내에서만 이뤄지다 보니 보는 이로 하여금 경기 상황을 체감하기 어려운 점이 있었습니다.&lt;/p&gt;

&lt;p&gt;그럼에도 재밌었던 점은 자율주행으로 경기장을 돌고 무사히 첫출발 선으로 돌아온 차에게 각 팀의 팀원들은 물론이고, 경기를 지켜보는 이들 모두 경기 결과에 관계없이 차량이 사고 없이 &lt;strong&gt;무사히 완주하고 돌아왔을 때 손뼉을 치고 기뻐하는 모습은 영락없이 사람이 직접 참여하는 스포츠의 한 장면이라는 생각이 들었습니다.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;한편, 차량에 문제가 생겼을 때 차량이 도로에 정차하여 이를 수리하는 것 역시 사람의 몫이었는데요. 문제 상황을 인지하고 기술적인 문제를 해결해야 하는 정밀한 조치가 필요한 순간에는 아직 한계가 보였습니다. 그럼에도 빠르게 홀로 주행하는 자율주행 차량을 보니 놀랍다는 생각이 들었는데요. 2016년, 이세돌과 알파고와의 대결처럼 빅 테크 기업이 제작한 AI 레이싱카와 드라이버 간 대결을 하는 때도 곧 오지 않을까 상상이 됩니다.&lt;/p&gt;

&lt;div style=&quot;padding:56.25% 0 0 0;position:relative;&quot;&gt;&lt;iframe src=&quot;https://player.vimeo.com/video/693440840?h=63f2778c33&amp;amp;badge=0&amp;amp;autopause=0&amp;amp;player_id=0&amp;amp;app_id=58479&quot; frameborder=&quot;0&quot; allow=&quot;autoplay; fullscreen; picture-in-picture&quot; allowfullscreen=&quot;&quot; style=&quot;position:absolute;top:0;left:0;width:100%;height:100%;&quot; title=&quot;PXL_20220107_203939894.mp4&quot;&gt;&lt;/iframe&gt;&lt;/div&gt;
&lt;script src=&quot;https://player.vimeo.com/api/player.js&quot;&gt;&lt;/script&gt;

&lt;p&gt;주행을 마치고 돌아온 차량에 팀원과 관객들 모두 박수를 보냅니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/ces2022-review-by-gigi/7.jpg&quot; alt=&quot;7&quot; /&gt;
&lt;em&gt;경기장에 방문하니 맛있는 음식과 음료가 제공되네요.&lt;/em&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;가까이-다가온-미래-모빌리티&quot;&gt;가까이 다가온 미래 모빌리티&lt;/h2&gt;

&lt;h3 id=&quot;트랙터부터-우주선까지-모빌리티화&quot;&gt;트랙터부터 우주선까지 모빌리티화&lt;/h3&gt;

&lt;p&gt;CES 야외 전시장에서는 대형 모빌리티 제품들을 경험해 볼 수 있었습니다. 오로라사(Aurora)는 자율주행 센서를 탑재한 트럭을 전시하였고, 우주항공 스타트업 시에라 스페이스(Sierra Space)는 우주선과 스테이션 모듈을 전시하였습니다. 시에라 스페이스의 전시 제품은 실물은 아닌 모형이었지만 거대한 크기가 인상적이었고, 스테이션은 마치 우리가 업무를 보는 공간인 것처럼 일상화된 공간으로 디자인된 것이 흥미로웠습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/ces2022-review-by-gigi/8.png&quot; alt=&quot;8&quot; /&gt;
&lt;em&gt;모빌리티 전시장에 트럭부터 우주선까지 볼 수 있어서 마치 놀이동산에 온 듯했습니다.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;농업용 중장비를 제작하는 존 디어(John Deer)도 모빌리티 전시장에 참여하였는데요. 영화 인터스텔라에서나 봤던 무인 자율주행 트랙터를 선보였습니다. 트랙터에 인공지능(AI) 프로세서, 그래픽 처리 장치(GPU), 위성항법 시스템(GPS) 기술을 접목하여 작업자가 설정한 작업 구간을 따라 자율 주행하는 동시에 데이터를 기반으로 작물을 재배할 수 있다고 합니다.&lt;/p&gt;

&lt;p&gt;존 디어는 이러한 기술이 농부의 편의성만 개선하는 것이 아니라, 농작물의 생산성을 높여서 미래에 다가올 식량난까지 극복하는 것이 목표라고 합니다.&lt;/p&gt;

&lt;h3 id=&quot;쏘카가-그리는-미래-모빌리티&quot;&gt;쏘카가 그리는 미래 모빌리티&lt;/h3&gt;

&lt;p&gt;라스베이거스에서 경험한 미래 모빌리티는 사람이나 물건을 수송하는 것에 그치지 않았습니다. 이동 과정의 편의는 물론이며 이동에 가장 적합한 이동 수단을 제공하기도 합니다. 그뿐만 아니라 고도로 발달된 자율주행으로 불의의 사고를 방지하는가 하면, 식량난과 같은 전 지구적인 어려움까지 해결할 수도 있다는 생각이 들었습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/ces2022-review-by-gigi/9.png&quot; alt=&quot;9&quot; /&gt;
&lt;em&gt;쏘카에서 함께 미래 모빌리티를 그려 나가는 동료들&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;쏘카 또한 스트리밍 모빌리티라는 비전을 갖고 미래 모빌리티를 그려 나가고 있습니다. 고객 개인에게는 다양한 이동 수단을 제공하여 최종 목적지까지 끊김 없이 이동하도록 하고, 이동 전후로 이동과 연계된 호스피탈리티 경험까지 제공하고자 합니다. 사회적으로는 자차 소유를 줄임으로써 전 지구적 관심사인 탄소 줄이기를 실현하는 것을 목표로 하고 있습니다.&lt;/p&gt;

&lt;p&gt;이처럼 멋진 미래 모빌리티를 만드는 일에 관심이 있다면 쏘카의 프로덕트 매니저(Product Manger)를 지원해 보세요. 미래 모빌리티를 직접 기획하고 제품화하여 우리 삶을 긍정적으로 변화시킬 수 있습니다.&lt;/p&gt;</content><author><name>지지</name></author><category term="product" /><category term="mobility" /><category term="ces" /><summary type="html">안녕하세요. 저는 쏘카에서 신규 서비스를 기획하는 프로덕트 매니저 지지입니다. 올해 1월, 저는 프로덕트 본부를 대표하여 모빌리티 서비스의 동향을 파악하고자 CES(Consumer Electronics Show) 2022에 다녀왔습니다.</summary></entry><entry><title type="html">쏘카 QA는 무슨 일을 하고 어떻게 일하나요?</title><link href="https://tech.socarcorp.kr/qa/2022/03/18/probationary-period_QA.html" rel="alternate" type="text/html" title="쏘카 QA는 무슨 일을 하고 어떻게 일하나요?" /><published>2022-03-18T02:00:00+00:00</published><updated>2022-03-18T02:00:00+00:00</updated><id>https://tech.socarcorp.kr/qa/2022/03/18/probationary-period_QA</id><content type="html" xml:base="https://tech.socarcorp.kr/qa/2022/03/18/probationary-period_QA.html">&lt;p&gt;안녕하세요.  작년 11월에 쏘카 QA 팀에 경력직으로 입사한 카밀라입니다.&lt;/p&gt;

&lt;p&gt;신입 때 QA 업무는 반복적인 업무를 하는 단순 직무라 생각했었습니다. 하지만 여러 프로젝트들을 진행하며 커버리지를 높이기 위한 활동들과 기본 기능을 지속적으로 검증하기 위한 자동화 테스트 구축 등 계속해서 배워야 할 것들이 많은 직무라는 것을 몸소 깨달았습니다.&lt;/p&gt;

&lt;p&gt;이번 글에서는 저의 입사 지원 과정부터 입사 후 3개월간의 수습 기간 동안 경험하며 느꼈던 내용을 공유해 보려고 합니다.&lt;/p&gt;

&lt;p&gt;다음과 같은 내용에 관심 있으신 분들이 보시면 도움 될 거라 생각합니다. 🙂&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;쏘카 QA 팀에 어떻게 입사했을까?&lt;/li&gt;
  &lt;li&gt;QA가 하는 일?&lt;/li&gt;
  &lt;li&gt;쏘카 QA 팀은 온보딩을 어떻게 진행할까?&lt;/li&gt;
  &lt;li&gt;쏘카의 QA 팀이 어떻게 업무할까?&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;목차&quot;&gt;목차&lt;/h2&gt;

&lt;p&gt;저는 다음 순서에 따라 글을 적어보았습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;QA 팀 입사 지원 과정
    &lt;ul&gt;
      &lt;li&gt;쏘카에 지원한 이유&lt;/li&gt;
      &lt;li&gt;입사 과정&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;QA란?
    &lt;ul&gt;
      &lt;li&gt;QA? 뭐 하는 팀이지?&lt;/li&gt;
      &lt;li&gt;일반적으로 QA는 무엇을 하나?&lt;/li&gt;
      &lt;li&gt;이슈를 찾기 위한 QA의 활동들&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;쏘카 QA의 업무
    &lt;ul&gt;
      &lt;li&gt;업무 방식&lt;/li&gt;
      &lt;li&gt;회의&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;쏘카 QA 팀의 온보딩 과정
    &lt;ul&gt;
      &lt;li&gt;쏘키에 익숙해지기&lt;/li&gt;
      &lt;li&gt;업무 경험하기&lt;/li&gt;
      &lt;li&gt;혼자 프로젝트 진행하기&lt;/li&gt;
      &lt;li&gt;온보딩을 하며 느낀 점&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;QA 직군 지원자를 위한 TIP&lt;/li&gt;
  &lt;li&gt;끝으로&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;1-qa-팀-입사-지원-과정&quot;&gt;1. QA 팀 입사 지원 과정&lt;/h2&gt;

&lt;p&gt;먼저 간략히 쏘카 QA 팀에 입사하게 된 과정에 대해 소개해 보려고 합니다.&lt;/p&gt;

&lt;h3 id=&quot;11-쏘카에-지원한-이유&quot;&gt;1.1. 쏘카에 지원한 이유&lt;/h3&gt;

&lt;p&gt;제가 쏘카에 지원한 이유는 모빌리티 산업에 관심이 많았고 자동차를 좋아해서였습니다. 또한 다음의 기준들을 만족하는지도 중요했습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;내가 좋아하는 일을 하면서 회사가 성장하고 나도 성장할 수 있는지&lt;/li&gt;
  &lt;li&gt;자체 서비스를 운영하는 회사인지&lt;/li&gt;
  &lt;li&gt;직원 규모가 어느 정도 이상인지(100명 이상)&lt;/li&gt;
  &lt;li&gt;지속적으로 성장하고 있는 회사인지&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;쏘카는 ‘쏘카 앱’을 기반으로 다양한 서비스를 운영하고 있고, 위와 같은 기준을 충분히 만족하는 회사였습니다. 그리고 채용공고와 커뮤니티 후기에서 QA 팀에서는 ‘주도적인 업무를 진행해 볼 수 있다’라는 부분과 ‘테스팅 자동화’를 진행한다는 부분이 가장 마음에 들었습니다. 쏘카에서는 저의 부족한 부분을 발전시키고 이전과는 다른 업무 경험을 쌓을 수 있을 것이라는 생각이 들었습니다.&lt;/p&gt;

&lt;h3 id=&quot;12-입사-과정&quot;&gt;1.2. 입사 과정&lt;/h3&gt;

&lt;p&gt;입사 과정은 다음 프로세스로 진행되었습니다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;서류 제출&lt;/li&gt;
  &lt;li&gt;1차 면접 (기술)&lt;/li&gt;
  &lt;li&gt;2차 면접 (본부장 면접)&lt;/li&gt;
  &lt;li&gt;3차 면접 (CTO 면접)&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;서류를 제출하고 일주일이 지나기 전에 전화로 채용 과정에 대해 안내받았습니다. 1차 면접 전날까지 사전과제를 제출해야 한다는 안내를 받았고 1차 면접이 통과하면 2차, 3차 면접이 있다고 안내받았습니다. 사전과제는 채용공고에도 나와있듯 쏘카의 서비스 중 하나를 선택하여 테스트 케이스를 작성하는 것이었습니다.&lt;/p&gt;

&lt;p&gt;1차 면접(기술면접)에 실무진, 쏘카에 입사하면 같이 일하게 될 팀장님과 팀원 두 분이 면접관으로 참여하였습니다. 주로 이력서 위주의 질문이 나왔습니다. 참여했던 프로젝트에서 어떤 업무를 어떤 프로세스와 방식으로 진행했는지에 대한 질문과 업무를 하면서 마주할 수 있는 문제들에 대한 해결 방법을 묻는 질문이었습니다. 제출한 사전과제에 대해 해당 주제를 선택한 이유와 본인이 진행한 과제에 대해 설명하는 시간을 가졌고 마지막으로 입사해서 하고 싶은 업무와 본인의 성격에 대한 질문으로 마무리되었습니다.&lt;/p&gt;

&lt;p&gt;1차 면접 후 1주일 안에 합격 연락이 왔고 2차와 3차 면접이 같은 날에 진행될 것이라 안내받았습니다. 2차는 본부장 면접이고 3차는 인사팀과 CTO 면접이라 안내받았습니다.&lt;/p&gt;

&lt;p&gt;2차 면접에서는 본부장님과의 면접이 이루어졌고 1차와 비슷하게 이력서 위주의 질문들과 기술적인 부분, 인성 관련 질문도 있었습니다. 2차는 30분 정도 진행되었고 2차 면접 종료 후 바로 3차 면접을 진행했습니다. 3차 면접에서는 주로 CTO 님이 질문을 하셨고 딱딱한 질의응답보다는 저의 경험을 바탕으로 자유롭게 대화를 하듯 진행되었습니다. 그리고 조언도 해주셨는데 면접이 종료되고 난 뒤에도 해주신 말씀이 계속 생각나고 질문을 곱씹어 생각할 정도로 여운이 남는 면접이었습니다.&lt;/p&gt;

&lt;p&gt;3차 면접 이후로 최종적으로 합격하여 쏘카에서 일하게 되었습니다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;2-qa란&quot;&gt;2. QA란?&lt;/h2&gt;

&lt;p&gt;먼저 쏘카 QA 업무 설명에 앞서, 일반적으로 QA는 어떤 일을 하는지 먼저 설명해 보고자 합니다.&lt;/p&gt;

&lt;h3 id=&quot;21-qa-뭐-하는-팀이지&quot;&gt;2.1. QA? 뭐 하는 팀이지?&lt;/h3&gt;

&lt;p&gt;QA에 대해 궁금하고 생소하신 분들도 계시고 왜 필요한지에 대한 의문을 가지는 분들도 많을 겁니다. 먼저 QA는 Quality Assurance의 약자로 ‘품질 보증’ 이란 뜻을 가지고 있습니다. QA 팀은 서비스의 ‘품질 보증’ 관련 업무를 하는 팀으로, &lt;strong&gt;서비스의 기능을 검증하고 관리하기 위한 일련의 활동을 합니다.&lt;/strong&gt; 프로젝트, 조직 규모가 작은 경우 개발자나 관리 조직에서 직접 기능 검증을 진행하기도 하지만, 프로젝트와 조직 규모가 커지는 경우 QA를 전담으로 하는 QA 팀을 구성해서 운영하기도 합니다.&lt;/p&gt;

&lt;p&gt;‘QA = Tester’라고 생각하시는 분들이 많습니다. 물론 QA의 활동 중 기능 테스트도 포함되어 있습니다. 하지만 QA는 단순히 서비스의 기능 테스트만 하지 않습니다. QA는 프로젝트의 시작부터 마무리까지 모든 과정에 참여하여 각 단계별로 품질을 저하시키거나 리소스가 낭비될 수 있는 요소를 발견한 뒤, 해당 프로젝트의 품질을 향상시키고 리소스 낭비를 방지하는 것을 목적으로 품질 보증 활동을 합니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/QA/qa_1.png&quot; alt=&quot;img&quot; width=&quot;50%&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;22-일반적으로-qa는-무엇을-하나&quot;&gt;2.2. 일반적으로 QA는 무엇을 하나?&lt;/h3&gt;

&lt;h4 id=&quot;킥오프-참여&quot;&gt;킥오프 참여&lt;/h4&gt;

&lt;p&gt;회사마다 QA가 투입되는 시기는 다를 수 있지만 주로 QA는 킥오프(Kick-off) 단계부터 참여하게 됩니다. &lt;strong&gt;단순히 버그를 찾기 위한 것이 아니라 프로젝트의 방향성, 목적, 요구사항 등 프로젝트의 근본적인 목적을 명확히 파악해야 올바른 검증을 진행할 수 있기 때문입니다.&lt;/strong&gt; 또한 초기 단계에서 발생할 수 있는 오류를 사전에 방지하여 낭비될 수 있는 리소스를 줄일 수 있습니다.&lt;/p&gt;

&lt;p&gt;프로젝트가 진행되는 중간에 QA가 참여할 경우 프로젝트의 구성과 기능 파악, 테스트 범위, 검증 항목 선정 등에 더 많은 시간을 소모하게 되고 초기에 발견할 수 있던 문제점이 발견된다면 불필요한 리소스가 낭비될 수 있습니다. 그리고 프로젝트의 기간과 목적에 적합한지, 프로젝트 기간을 고려하여 진행 가능한지, 기간이 얼마나 더 필요한지 등을 제대로 판단할 수 없게 됩니다.&lt;/p&gt;

&lt;p&gt;QA는 지속적으로 개발자, 기획자와 소통하며 기획의 목적대로 흘러가고 있는지 업무상 진행되는 과정에서 비효율적인 부분은 없는지 리뷰를 진행하고 개선안을 제시합니다. 또한 유저의 입장에서 발생할 수 있는 불편함은 없는지 확인합니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/QA/qa_3.png&quot; alt=&quot;img&quot; /&gt;
&lt;em&gt;QA의 업무 단계별 활동과 산출물입니다.&lt;/em&gt;&lt;/p&gt;

&lt;h4 id=&quot;분석--qa-plan-작성&quot;&gt;분석 &amp;amp; QA Plan 작성&lt;/h4&gt;

&lt;p&gt;킥오프가 진행된 후에는 기획서를 분석하여 프로젝트 수행 시 발생할 수 있는 리스크를 예상해 보고 테스트 전략을 수립합니다.&lt;/p&gt;

&lt;p&gt;이후에는 QA Plan 또는 테스트 계획이라고도 하는 문서는 작성합니다. &lt;strong&gt;QA Plan은 테스트를 하기 위해 필요한 리소스들을 요약해놓은 문서로, QA가 정해진 프로세스대로 업무를 수행하기 위한 청사진 역할을 합니다.&lt;/strong&gt; 이 안에서 테스트의 명확한 기준을 세워 원하는 방향으로 테스트가 진행될 수 있도록 합니다. 이 문서는 테스트를 수행하는 도중 변경되기도 하는 등 지속적으로 관리됩니다.&lt;/p&gt;

&lt;p&gt;QA Plan에는 다음 내용들이 포함됩니다.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[프로젝트 명] QA Plan

1. 요약
2. 프로젝트명
3. 프로젝트 자료
    3.1. 기획서
    3.2. 디자인
    3.3. Test case
    3.4. Test data
4. 참여자
5. 배포되는 버전
6. QA 기간
    6.1. Test case 작성 기간
    6.2. 테스트 기간
    6.3. Sign off 날짜
    6.4. 배포 요청일
    6.5. 모니터링
7. 테스트 범위
8. 테스트 제외 범위
9. 품질 목표 설정
10. 테스트 종료 조건 설정
11. 테스트 환경
    11.1. 디바이스
    11.2. OS 버전
12. 테스트 요청사항
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;테스트-케이스-작성&quot;&gt;테스트 케이스 작성&lt;/h4&gt;

&lt;p&gt;QA Plan이 작성되었다면 테스트 케이스(TC)를 작성합니다. &lt;strong&gt;테스트 케이스를 작성하는 과정에서 요구사항에 대한 오류를 찾을 수도 있고 고려되지 않았던 부분을 찾아낼 수 있습니다&lt;/strong&gt;. 또한 테스트 케이스 리뷰 과정을 통해 팀 구성원들에게 테스트 케이스 적정성을 점검하고 잘못된 이해로 인한 오류도 점검할 수 있습니다.&lt;/p&gt;

&lt;p&gt;다음은 테스트 케이스 예시입니다.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;ID&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Category&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;Preconditions&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;Steps&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;Expected result&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Galaxy21 (Android 11)&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;iPhoneX (iOS 14.4.2)&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;Comment&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Socar_001&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;예약하기&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;쏘카 앱에 로그인되어 있는 상태&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;지도에서 쏘카 존을 선택&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;선택한 쏘카 존의 차량 목록이 노출됨&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;PASS&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;N/A&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;다른 기종 확인 필요&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h4 id=&quot;테스트-데이터와-환경-준비&quot;&gt;테스트 데이터와 환경 준비&lt;/h4&gt;

&lt;p&gt;테스트 케이스 작성과 리뷰가 완료되었다면, 본격적으로 테스트에 들어가기에 앞서 테스트 데이터와 환경을 준비해야 합니다. &lt;strong&gt;테스트를 수행하기 위한 기본 데이터들을 정리하고 어떤 환경에서 테스트가 시작될지를 미리 준비하는 과정입니다.&lt;/strong&gt; 테스트를 위한 데이터의 예로는 테스트 계정, 계정에 따른 권한 등이 있을 수 있고 테스트 환경은 테스트 서버 설정이 포함됩니다.&lt;/p&gt;

&lt;h4 id=&quot;테스트-수행--버그-리포트-작성&quot;&gt;테스트 수행 &amp;amp; 버그 리포트 작성&lt;/h4&gt;

&lt;p&gt;본격적으로 테스트 수행을 시작하게 되면 준비된 테스트 케이스 외에도 &lt;strong&gt;탐색적 테스트, ad-hoc 테스트&lt;/strong&gt;를 통해 이슈를 발견할 수 있습니다. 이때 발견한 이슈들을 구두로만 개발자와 주고받게 된다면 히스토리 관리가 힘들어질 수 있습니다. 이런 불편함을 줄이고 프로젝트 이슈들을 관리하기 위해 버그 리포트를 작성합니다.&lt;/p&gt;

&lt;p&gt;버그 리포트에는 다음 내용들이 포함됩니다.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[버그리포트 제목]

- 발생 환경(os 버전, 앱/웹 버전, 서버)
- 재현율
- 이슈 설명
- 사전 조건
- 재현 절차
- 예상 결과
- 실제 결과
- 담당 부서
- 우선순위/심각도
- 발생 버전/수정 버전
- 이슈 카테고리
- 첨부파일
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;테스트-결과-공유&quot;&gt;테스트 결과 공유&lt;/h4&gt;

&lt;p&gt;테스트가 완료되고 나면 결과를 정리하여 프로젝트 구성원들에게 공유합니다. QA Plan에서 정한 품질 목표를 달성하여 &lt;strong&gt;릴리즈가 가능한 상태인지를 알려주고 테스트 수행 결과와 품질 목표 달성에 따른 판단 결과, 테스트 진행하면서 발생한 이슈 현황들에 대한 정보&lt;/strong&gt;를 담고 있습니다.&lt;/p&gt;

&lt;p&gt;QA가 수행하는 단계마다 산출물이 발생하고 있고 이 산출물들은 QA가 프로젝트를 수행함에 있어 어떤 업무를 수행하고 어떻게 진행해야 하는지 방향을 알려주는 표지판 역할을 하게 됩니다. 수행하는 단계별로 QA 업무에 대해 정리하였지만 사실 ‘여기까지가 QA의 업무입니다’라고 할 수 없습니다.&lt;/p&gt;

&lt;p&gt;사실 유관부서와 협의하에 품질 향상에 도움이 되는 일 중 QA가 할 수 있는 모든 일들을 한다고 생각하시면 QA 업무가 더 쉽게 와닿을 것 같습니다.&lt;/p&gt;

&lt;h3 id=&quot;23-이슈를-찾기-위한-qa의-활동들&quot;&gt;2.3. 이슈를 찾기 위한 QA의 활동들&lt;/h3&gt;

&lt;p&gt;“이슈 찾는 활동? 테스트 케이스로만 테스트하고 이슈 찾는 거 아니었나요?”라고 생각하실 수 있습니다.&lt;/p&gt;

&lt;p&gt;작성한 테스트 케이스로만 이슈를 찾을 수는 없습니다. 일반적으로 테스트 케이스는 기획서를 기반으로 재현 조건과 기대 결과를 도출하여 기대 결과가 정상적으로 출력되는지 확인하는 긍정 테스트에 가깝습니다. 그럼 부정 테스트 케이스를 추가하면 되지 않을까? 물론 부정 테스트의 방법도 있지만 비정상적인 상황은 너무 다양하기 때문에 모든 것을 다 케이스화하는 것은 현실적으로 불가능합니다. 또한 자주 업데이트가 되는 서비스라면 더욱 힘들 겁니다.&lt;/p&gt;

&lt;p&gt;그래서 QA는 각 단계에서 할 수 있는 최선의 활동들을 통해 이슈를 찾아가고 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;개발 전에 프로젝트의 목적과 기획서를 바탕으로 다양한 시나리오를 생각하는 과정에서 명확히 정의되지 않은 것들을 확인한 뒤, 이해관계에 따라 발생할 수 있는 문제점들을 발견하여 개선될 수 있도록 합니다.&lt;/strong&gt; 또한 기획이나 컨텐츠 리뷰를 통해 논리적 오류나 유저에게 잘못 이해될 수 있는 부분, 오타 등을 확인하여 &lt;strong&gt;개발 이후 발생할 수 있는 이슈들을 파악&lt;/strong&gt;합니다.&lt;/p&gt;

&lt;p&gt;또한 단순히 버그를 찾는 것이 아닌 유저 입장에서 미래에 발생할 수 있는 문제들을 미리 예측해 보는 것도 이슈를 찾는 활동입니다. 실제 유저의 입장에서 서비스를 사용해 보며 유저가 사용할 수 있는 경로는 어떤 것이 있으며 어떤 부분에서 불편함을 느낄 수 있을지에 대한 고민을 합니다. 이때 유저 사용성에 따른 시나리오를 분리하여 테스트를 진행하기도 하는데 앞서 언급한 부정 테스트(Unhappy Path Test)와 긍정 테스트(Happy Path Test) 방법이 있습니다. 부정 테스트는 주어진 소프트웨어가 올바르게 작동하는지 확인하기 위해 잘못된 데이터를 입력하고 잘못된 작업을 수행하도록 구성합니다. 그러면 소프트웨어는 작동되지 않고 &lt;strong&gt;사용자가 이해할 수 있는 오류 메시지를 노출해 주는지 확인합니다.&lt;/strong&gt; 반대로 긍정 테스트는 오류가 생성되지 않는 데이터를 입력하여 &lt;strong&gt;소프트웨어가 의도대로 작동하는 것을 확인합니다.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;기존 서비스에 기능이 추가되는 경우 기존 서비스가 정상 동작하는지 확인하기 위해 기본 기능에 대한 체크리스트를 수행하기도 하지만, 반복적으로 진행해야 되는 테스트의 경우 자동화 테스트를 진행하기도 합니다. 자동화 테스트란 자동화 도구로 테스트 스크립트를 개발하여 소프트웨어의 유효성을 검사하는 것입니다. &lt;strong&gt;자동화 테스트를 통해 기존에는 발생하지 않았던 문제점들을 찾아낼 수 있고 변경된 부분을 발견할 수 있습니다.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;이처럼 QA는 테스트 케이스를 활용하는 테스트 외에도 다양한 활동들 가운데 품질 향상을 위해 문제점을 찾고 개선하는 노력을 하고 있습니다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;3-쏘카-qa의-업무&quot;&gt;3. 쏘카 QA의 업무&lt;/h2&gt;

&lt;p&gt;이제 쏘카 QA 팀에서는 구체적으로 어떻게 업무하는지에 대해서 설명드리고자 합니다.&lt;/p&gt;

&lt;h3 id=&quot;31-업무-방식&quot;&gt;3.1. 업무 방식&lt;/h3&gt;

&lt;p&gt;QA라도 회사마다 각기 다른 프로세스에 따라 업무를 진행합니다. 기획과 개발이 다 완료된 상태에서 QA가 투입되는 경우도 있고, 주제만 정하고 기획을 만들어 가는 과정에서 QA가 투입되는 경우, 기획서가 만들어진 후 QA가 투입되는 경우 등 다양한 단계에서 참여가 이루어지고 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/QA/qa_2.png&quot; alt=&quot;img&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;쏘카에서는 QA 요청서가 발의되었을 때 QA가 프로젝트에 참여합니다.&lt;/strong&gt; QA 요청서는 JIRA를 통해 만들어지고 정해진 양식에 맞춰 프로젝트 리더가 작성하여 요청합니다. 이 요청서에는 기획서가 포함되어 있고 기획, 개발, 디자인 일정이 포함됩니다. 프로젝트별로 상이하긴 하지만 디자인이 완료된 경우 디자인 링크도 포함됩니다. 그리고 프로젝트에 관련된 자료들이 첨부됩니다.&lt;/p&gt;

&lt;p&gt;QA 요청서가 발의되면 팀 내에서 &lt;strong&gt;담당자를 정하게 되고 본격적으로 프로젝트에 투입&lt;/strong&gt;되어 업무를 하게 됩니다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;배정된 담당자는 킥오프(Kick-off) 회의에 참여&lt;/strong&gt;하여 프로젝트의 규모와 목적을 파악하고 다음 내용들을 &lt;strong&gt;QA Plan에 작성&lt;/strong&gt;합니다.
    - 프로젝트 정보
    - QA 일정
    - 테스트 데이터
    - 테스트 기준
    - 테스트 범위
    - 테스트 환경&lt;/p&gt;

&lt;p&gt;QA Plan을 작성할 때 보통 QA 요청서를 참고하고 QA를 진행하면서 필요할 사항들을 수집하고 정리합니다. 프로젝트를 진행하기에 앞서 필요한 전제 조건들과 검증 시 반드시 확인해야 될 사항들, 그리고 검증 진행 방법들도 회의를 통해 확인하고 적어놓습니다. 쏘카의 QA Plan은 초기에 한번 적고 끝나는 것이 아니라 테스트 케이스를 작성하거나 테스트를 수행하면서도 새로운 내용이나 참고할 사항들을 꾸준히 업데이트하게 됩니다.
프로젝트에 관해 설명이 더 필요한 부분이나 의견이 있다면 PM, 개발자, 디자이너 등 프로젝트에 참여하는 인원들과 소통하여 문제를 해결합니다.&lt;/p&gt;

&lt;p&gt;프로젝트에 대해 파악되었다면 &lt;strong&gt;테스트 케이스 혹은 체크리스트를 작성&lt;/strong&gt;합니다. 프로젝트의 규모가 크지 않거나 빠르게 확인해야 프로젝트의 경우, 확인해야 될 주요 항목을 간략하게 적어서 정상적으로 수행이 되는지를 판단하기 위해 체크리스트를 작성하게 됩니다. 체크리스트와 다르게 테스트 케이스의 경우에는 전제조건과 수행하는 절차 그리고 수행함으로 인해 기대되는 결과가 포함되기 때문에 체크리스트보다 더 세밀하게 기능을 테스트를 진행할 수 있습니다. 쏘카에서는 테스트 케이스 관리를 웹 기반 테스트 관리 시스템인 &lt;a href=&quot;https://testlink.org/&quot;&gt;Testlink&lt;/a&gt;로 하고 있습니다. 테스트 케이스는 작성하는 사람에 따라 다르겠지만 주어진 형식은 맞추되 작성하는 건 본인 성향에 따라 작성하고 있습니다. 어떤 사람은 오타와 띄어쓰기 하나까지 세세하게 테스트 케이스로 작성할 수 있고 어떤 사람은 기능만 위주로 작성하여 차이가 나지 않을까 우려할 수 있지만 테스트 케이스를 작성한 후 팀 내에서 리뷰를 진행하고 피드백을 통해 맞춰가고 있습니다. 또한 필요에 따라 &lt;strong&gt;팀 내에서 테스트 케이스 리뷰가 진행된 후 프로젝트 내에서도 테스트 케이스 리뷰&lt;/strong&gt;를 진행합니다.&lt;/p&gt;

&lt;p&gt;개발이 완료되고 나면 개발 환경에서 테스트를 수행할 수 있게 &lt;strong&gt;테스트 서버를 띄워 QA를 수행&lt;/strong&gt;합니다. 작성한 테스트 케이스를 바탕으로 테스트를 수행하는 데 프로젝트에 따라서 앱 또는 웹 테스트를 진행합니다. 데이터를 확인해야 되는 프로젝트라면 DB를 조회해서 테스트를 진행할 수도 있고 실제 차량에 들어가는 장비를 가지고 테스트를 진행하기도 합니다. 또한 일정에 따라 실제 차량으로 테스트를 진행하는 등 다양한 테스트 활동을 추가로 진행하기도 합니다. &lt;strong&gt;테스트를 수행하면서 발견되는 이슈들은 JIRA에 등록&lt;/strong&gt;합니다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;QA가 완료된 후에 팀과 프로젝트 내에 프로젝트가 종료되었다는 의미로 Sign off&lt;/strong&gt;를 합니다. 프로젝트 수행 내용을 간략하게 전달하고 서버나 웹 관련 프로젝트라 배포까지 완료되었다면 모니터링에 대한 내용도 포함하여 공유합니다.&lt;/p&gt;

&lt;p&gt;그 후에는 &lt;strong&gt;프로젝트를 수행하면서 알게 된 내용이나 공유할 내용, 남겨야 되는 주요 토픽 등에 대해 자유롭게 문서 정리&lt;/strong&gt;를 합니다. QA Plan에 내용을 추가하여 정리하는 경우도 있지만 규모와 히스토리가 긴 프로젝트의 경우엔 컨플루언스에 따로 페이지를 만들어서 작성합니다.&lt;/p&gt;

&lt;p&gt;프로젝트별로 QA가 완료되고 나면 &lt;strong&gt;하나의 버전으로 배포하기 위해 검토를 한 후 빌드 요청&lt;/strong&gt;을 합니다. 빌드 된 앱의 회귀 테스트(Regression test)를 진행한 후 앱 심사를 요청하고 &lt;strong&gt;심사가 완료되고 난 뒤 QA 팀에서 마켓 배포를 수행합니다.&lt;/strong&gt;&lt;/p&gt;

&lt;h3 id=&quot;32-회의&quot;&gt;3.2. 회의&lt;/h3&gt;

&lt;p&gt;쏘카 QA 팀에서 정기적으로 진행되는 회의는 2개가 있는데 그중 하나는 &lt;strong&gt;매일 아침 10시에 업무공유를 위한 회의&lt;/strong&gt;입니다. 각자 당일에 진행할 업무에 대해 공유하고 전달사항을 공유 받는 회의입니다. 또한 새로운 업무가 생겼을 때 담당자를 지정하는 것도 아침 회의 시간에 주로 진행됩니다.&lt;/p&gt;

&lt;p&gt;또 다른 하나는 &lt;strong&gt;매주 금요일 오후 2시에 진행하는 회고&lt;/strong&gt;입니다. 한주를 돌아보며 자유롭게 이야기하고 의견을 나누는 시간입니다. 한 주 동안 업무를 하면서 좋았던 점과 아쉬웠던 점에 대해 이야기를 하고 진행하고 있는 프로젝트나 팀 내에서 논의하고 싶은 내용에 대해 주제를 정해 이야기하기도 합니다. 처음에는 회고라 해서 무겁고 딱딱한 분위기일 수도 있겠다라 생각이 들었지만, 실제로 해보니  편하게 수다 떨듯 얘기하면서도 진지한 얘기를 할 때는 진지하게 의견을 나누기도 했습니다. 참여하기 전에는 무슨 얘기를 해야 될지, 이런 얘기도 해도 되나? 하는 걱정이 들었지만 생각보다 2시간이 훌쩍 지나가곤 합니다. 회고 시간을 통해 팀원들과 다 같이 얘기하는 시간을 갖고 업무에 대한 조언과 도움도 받을 수 있습니다. 또한 우리 팀이 나아 갈 방향과 진행할 업무들 그리고 개선할 점들을 토론하며 각자가 QA 팀의 일원으로서 함께 팀을 만들어나가는 의미 있는 시간이라 생각합니다.&lt;/p&gt;

&lt;p&gt;이 외에 한 달에 한 번 쏘카의 전 직원들이 참여하는 &lt;strong&gt;Town Hall 이라는 회의&lt;/strong&gt;가 있고 각자가 속한 &lt;strong&gt;프로젝트에서 진행하는 회의&lt;/strong&gt;가 있습니다. 팀 내에서 갑자기 생긴 논의사항이나 전달사항이 있을 경우에도 회의가 생기기도 합니다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;4-쏘카-qa-팀의-온보딩-과정&quot;&gt;4. 쏘카 QA 팀의 온보딩 과정&lt;/h2&gt;

&lt;p&gt;다음으로 QA 팀에 합류한 이후 온보딩 과정의 경험을 공유해 보려 합니다.&lt;/p&gt;

&lt;h3 id=&quot;41-쏘카에-익숙해지기&quot;&gt;4.1. 쏘카에 익숙해지기&lt;/h3&gt;

&lt;p&gt;채용 프로세스가 끝나고 드디어 쏘카 입사 첫날! 로비로 가는 것부터 지하를 뱅글뱅글 돌고 물어보고서야 찾아갈 수 있었습니다. 팀 내에서 진행되는 온보딩은 4주 과정으로 계획되어 있었지만 일정상 5주간 진행되었습니다.&lt;/p&gt;

&lt;p&gt;재택근무를 시행하고 있어 동료들을 많이 만나진 못했지만 화상회의로 또는 종종 사무실에 출근하시는 분들과 인사하고 같이 점심을 먹거나 티타임을 가졌습니다. 팀 온보딩을 진행하는 동안 저는 사무실 출근을 했고 사무실 투어도 하고 근처 맛집들을 가보기도 하며 종종 서울숲 산책도 했습니다. 그동안 미로 같던 회사 길도 이리저리 잘 찾아다닐 수 있게 되었고 예약도 찾기도 어렵던 회의실도 척척 예약하고 찾아갈 수 있게 되었습니다.&lt;/p&gt;

&lt;p&gt;PX(People Experience) 팀에서 진행하는 온보딩은 입사 후 일주일 뒤에 하루 일정으로 진행되었습니다. 같은 날 입사한 동료들과 온보딩에 참여하여 자연스럽게 서로에 대해 알아가며 점심도 같이 먹으며 친해질 수 있었습니다. 또한 쏘카의 히스토리와 문화를 액티비티를 통해 몸으로 익히며 알 수 있었습니다. 온보딩을 같이한 동료들과는 팀이 달라 자주는 아니지만 종종 만나서 점심을 먹기도 하고 티타임을 갖고 있습니다. 입사 후 몇 번의 만족도 조사를 시행했는데 신규 입사자가 쏘카에 적응할 수 있도록 지속적으로 돕는 프로세스가 정말 잘 되어있다고 느꼈습니다.&lt;/p&gt;

&lt;h3 id=&quot;42-업무-경험하기&quot;&gt;4.2. 업무 경험하기&lt;/h3&gt;

&lt;p&gt;QA 팀에서 진행된 온보딩은 5주 동안 진행되었고 입사 후 첫 주는 주로 PC 세팅과 업무에 필요한 장비와 계정을 등록했습니다. 업무 파악을 위해 각종 회의에 참여하기도 했습니다. 2주에 걸쳐 팀장님에게 업무 프로세스와 쏘카 앱에 대한 설명과 히스토리에 대해 교육을 받았습니다. 이후에는 쏘카 앱을 직접 사용해 보는 시간을 가졌고 각 서비스들을 담당했던 팀원들과 같이 해당 서비스를 살펴보는 시간을 가졌습니다. 3주 차엔 테스트 케이스 관리 툴의 사용법을 익혔습니다. 쏘카 앱 체크리스트를 직접 수행하면서 교육받은 내용을 리마인드하고 모르는 부분을 체크하는 시간도 가졌습니다. 마지막으로 4주 차, 5주 차에는 팀원과 같이 프로젝트에 참여하여 실제 업무를 익혔습니다. 해당 프로젝트 종료 후에는 혼자 프로젝트에 참여하여 직접 QA 업무를 수행할 수 있었습니다.&lt;/p&gt;

&lt;h4 id=&quot;문서-작성은-중요해&quot;&gt;문서 작성은 중요해&lt;/h4&gt;

&lt;p&gt;쏘카에 입사 후 놀랐던 것 중 하나가 신규 입사자가 볼 수 있는 자료가 많다는 것이었습니다.
회사와 업무에 대해 궁금한 것들을 찾아볼 수 있게 자료들이 잘 정리되어 있습니다.
신규 입사자들이 쏘카의 업무방식과 쏘카에 대한 이야기, 그리고 업무지원 및 요청 가이드 등을 알 수 있도록 ‘SOCAR 백과사전’ 이라는 것이 있고 노션(Notion)과 컨플루언스(Confluence)에 각 팀별, 프로젝트 별로 문서가 정리되어 있습니다.&lt;/p&gt;

&lt;p&gt;신규 입사자를 위한 것뿐 아니라 쏘카의 모든 직원들을 위한 자료도 많았습니다. 저도 입사 후 온보딩을 진행하면서 필요하다고 생각되는 문서들은 직접 만들거나 기존 문서를 업데이트하기도 했습니다.
이 문서들은 한 번에 일괄적으로 작성되는 것은 아니고, 업무를 하는 동안 본인이 수행한 업무를 리마인드하고 히스토리를 관리하기 위해 작성되곤 했습니다. 이렇게 모인 자료들은 쏘카의 모든 직원들에게 공유될 수 있었습니다. 저는 본인이 수행한 일을 문서로 남기는 것은 실제 업무를 수행하는 것만큼이나 중요하다고 생각하는데, 이게 생각과 다르게 지속되기란 쉽지 않은 문제입니다. 그런데 쏘카에서는 많은 동료들이 본인이 진행한 업무뿐만 아니라, 다른 동료들에게 필요할 수 있는 정보들을 문서화하고 지속적인 업데이트를 통해 관리해나가고 있는 것을 볼 수 있어서 인상 깊었습니다.&lt;/p&gt;

&lt;h4 id=&quot;같이하는-프로젝트-진행-경험하기&quot;&gt;같이하는 프로젝트 진행 경험하기&lt;/h4&gt;

&lt;p&gt;온보딩 4주 차에는 팀원과 같이 프로젝트에 참여하여 실제 업무를 하며 익히는 시간을 가졌습니다. 업무에 익숙한 팀원과 같이 프로젝트를 진행하면서 쏘카의 업무를 알아가도록 도와주는 과정이었습니다. 저는 팀 동료 에이미와 같이 프로젝트에 참여하였는데, 어느 단계에서 무엇을 해야 하는지, 다음 순서는 무엇인지, 제가 수행할 수 있는 업무는 직접 해볼 수 있게 에이미가 도와주셨고, 처음 해보는 것은 같이 수행하면서 업무에 적응할 수 있도록 도와주셨습니다. 물론 프로젝트마다 참여하는 인원은 다르지만 담당자와 어떻게 소통을 해야 하는지, 어떤 방식으로 업무가 진행되는지에 대해서도 배울 수 있는 시간이었습니다.&lt;/p&gt;

&lt;h4 id=&quot;모르는-건-질문하기&quot;&gt;모르는 건 질문하기&lt;/h4&gt;

&lt;p&gt;새로운 회사에 경력직으로 입사를 하더라도 새로운 회사의 업무방식에 맞춰 기존에 알던 것도 다시 보고 사용하던 도구들도 다시 배우게 됩니다. “경력직이니까 이런 건 당연히 알겠지?”라고 생각하시는 분들이 종종 있기 때문에, 입사 전에 심적으로 꽤 큰 부담이 있었습니다. 하지만 걱정했던 게 무색할 정도로 쏘카에 첫 출근하는 날 모두들 “모르는 거 궁금한 거 언제든 물어보세요”라고 먼저 말씀해 주셨습니다. 저도 마음을 조금 내려놓고 정말 많이 질문했는데 다들 하나같이 친절하게 알려주셨습니다. 시간 날 때마다 계속 신경 써주시고 알려주셔서 업무를 익히고 적응하는 데 도움이 되었습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/QA/qa_4.png&quot; alt=&quot;img&quot; width=&quot;50%&quot; /&gt;
&lt;img src=&quot;/assets/images/QA/qa_5.png&quot; alt=&quot;img&quot; width=&quot;50%&quot; /&gt;
&lt;em&gt;팀 채널에 궁금한 사항을 남기면 팀원 분들이 친절하게 알려주십니다.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;또한 회사 뒤편에 서울숲이 있어 점심을 먹고 가볍게 산책하면서 소소한 이야기를 나누기도 합니다. 회사가 카페가 많은 성수동에 있어, 커피를 종종 마시면서 수다를 떨면서 자연스럽게 모르는 걸 묻기도 하고, 팀원들 간에 서로 일상을 공유하는 시간을 가지기도 합니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/QA/qa_6.jpeg&quot; alt=&quot;img&quot; width=&quot;50%&quot; /&gt;
&lt;em&gt;성수동엔 이쁜 카페가 많습니다.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/QA/qa_7.jpeg&quot; alt=&quot;img&quot; width=&quot;50%&quot; /&gt;
&lt;em&gt;가을에 서울숲에 꼭 가보시길 추천드립니다.&lt;/em&gt;&lt;/p&gt;

&lt;h3 id=&quot;43-혼자-프로젝트-진행하기&quot;&gt;4.3. 혼자 프로젝트 진행하기&lt;/h3&gt;

&lt;p&gt;같이 프로젝트를 진행해 본 후 혼자서 프로젝트에 참여하게 되었습니다. 쏘카의 QA로서 처음 맡은 업무였습니다.&lt;/p&gt;

&lt;p&gt;참여하게 된 프로젝트는 일부 기능 변경이 있는 작은 규모였습니다. 하지만 당혹스럽게도 팀 동료 에이미와 함께 진행했던 프로젝트와는 일하는 방식이 달랐습니다. 팀원들에게 조언을 구하며 업무를 진행했고, 예상치 못한 문제들이 발생하여 일정이 기존에 계획했던 것보다 딜레이가 되었지만 결과적으로는 잘 마무리를 할 수 있었습니다. 프로젝트가 종료된 후에는 진행한 업무에 대해 문서 정리를 하고, 이해관계자들과 논의하는 자리를 마련하여 개선되었으면 하는 부분과, 정리가 아직 안 된 부분에 대해 정리하였습니다.&lt;/p&gt;

&lt;h3 id=&quot;44-온보딩을-하며-느낀-점&quot;&gt;4.4. 온보딩을 하며 느낀 점&lt;/h3&gt;

&lt;p&gt;쏘카에 와서 처음부터 지금까지 너무 좋다고 생각하는 부분은 모두가 자유롭게 의견을 내고 듣는 사람들도 편견 없이 들어주고 같이 고민하고 개선하려 한다는 것입니다. 적극적이고 쏘카의 서비스를 쏘카의 모든 직원들이 같이 만들어나가고 있다는 느낌을 받았고 제가 그런 쏘카의 직원이라는 게 자랑스럽게 느껴졌습니다. 개개인이 아닌 쏘카라는 하나의 목표를 향해 나아간다는 느낌을 들었고 그것이 누군가의 강요가 아닌 모두의 자발적인 모습에서 비롯된 것이라는 점이 인상 깊었습니다.&lt;/p&gt;

&lt;p&gt;한편 온보딩을 하는 동안 좀 더 개선하면 좋겠다고 생각한 것은 ‘회의가 너무 많아서 줄었으면 좋겠다’ 이었습니다. 어떤 날은 정말 하루 종일 점심시간을 제외하고 회의에 참석한 날도 있었으니까요. 하지만 조직 개편 후에는 정기적으로 진행되던 많은 회의들이 사라졌고 본인 업무에 직접적인 연관이 있는 회의로 많이 축소되었습니다. 맡은 업무에 따라 여전히 많은 회의를 참석하는 날도 있지만 그만큼 할 수 있는 일이 늘었다는 것에 한편으로는 정말 쏘팸이 된 걸 느끼게 됩니다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;5-qa-직군-지원자를-위한-tip&quot;&gt;5. QA 직군 지원자를 위한 TIP&lt;/h2&gt;

&lt;p&gt;이번에는 QA 직군 지원자분들을 위한 저만의 팁에 대해 공유드리려 합니다.&lt;/p&gt;

&lt;p&gt;QA는 꼼꼼해야 해, 커뮤니케이션이 능숙해야 해, 대처법을 잘 알아야 해, 문제를 많이 찾을 수 있어야 해, 남들과 다른 관점에서 볼 줄 알아야 해 등 QA 직무에 대해 물어보면 주로 들을 수 있는 말입니다. 하지만 모든 QA가 저런 특성을 가지진 않습니다. 커뮤니케이션이 약한 사람도 있고 꼼꼼하지 못한 사람도 많습니다. 저런 부분은 각 사람의 성향에 해당하는 것이기 때문에 저런 성향을 가지신 분들이라면 좋겠지만 저는 다음 세 가지가 더 중요하다 생각합니다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;먼저 QA를 하고 싶다면 QA가 사용하는 기본적인 용어를 알고 있어야 된다 생각합니다.&lt;/strong&gt; 왜 그런 걸 알아야 하지? 몰라도 할 수 있지 않나? 하고 생각하실 수 있습니다. 물론 모르셔도 업무는 할 수 있습니다. 하지만 해당 직군에서 사용하는 용어들을 알고 있으면 본인 업무에 대한 이해와 수행할 수 있는 업무의 폭을 넓혀줄 수 있다 생각합니다. QA 채용공고를 보면 우대 항목에 ‘ISTQB 자격증’ 이 있습니다. 자격증이 있어야 된다는 것은 아닙니다. 하지만 QA에 대한 지식이 없다면 ISTQB 책을 한 번 정도는 읽어보면 업무를 이해하는 데 도움이 될 것입니다.&lt;/p&gt;

&lt;p&gt;두 번째로는 &lt;strong&gt;QA 프로세스를 알고 있어야 된다 생각합니다.&lt;/strong&gt; 여기서 말하는 프로세스는 단순히 ‘QA Plan을 작성하고 테스트 케이스를 만들어 테스트를 한다’가 아닌 프로젝트에 투입된 순간부터 QA가 각 단계별로 수행할 수 있는 업무와 만들어지는 산출물들의 구성을 파악하고 있는지를 말합니다. 회사별로 프로젝트 진행은 다르더라도 QA가 수행하는 기본 프로세스는 동일합니다. 해당 직무의 업무 순서와 정의를 알고 있다면 어떤 프로젝트에 참여하던지 흔들리지 않고 본인의 역할을 해낼 수 있다 생각합니다.&lt;/p&gt;

&lt;p&gt;마지막으로는 &lt;strong&gt;스스로 나아가려는 의지가 필요합니다.&lt;/strong&gt; 알아서 모든 일을 하라는 의미가 아니고 품질 개선을 위해 스스로 다양한 방법을 시도하고 업무를 찾아서 할 수 있어야 한다는 의미입니다. 글을 시작할 때 언급했던 바와 같이 QA 업무는 결코 단순하지 않습니다. 소프트웨어 개발 환경이 발전함에 따라 품질을 높이기 위한 방법들도 다양해지고 빠르게 변화하고 있습니다. 틀에 박힌 테스트 방식이 아닌 새로운 방법들을 스스로 해보고 발전시키려는 의지가 필요하다 생각합니다.&lt;/p&gt;

&lt;p&gt;위의 세 가지는 제가 면접관일 때나 지원자일 때 중요하게 생각하는 부분입니다. 그래서 면접을 보기 전에 QA 용어와 프로세스에 대해 다시 리마인드를 하고, 항상 배우려는 마인드 셋을 갖추려고 합니다. 저의 팁이라고 하기엔 거창한 거 같지만 이 팁이 QA 지원을 준비하거나 생각하시는 분들에게 작은 도움이라도 되길 바랍니다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;6-끝으로&quot;&gt;6. 끝으로&lt;/h2&gt;

&lt;p&gt;처음 쏘카 블로그 글 제안을 받았을 때 걱정이 앞섰습니다. 글을 잘 쓰는 것도 아니고 누군가에게 설명하는 것도 잘하지 못해 글 순서를 정하는 것부터 쉽지 않았습니다. 글도 생각한 것처럼 써지지 않아 다시 읽을 때마다 수정하고 있고, 글의 마지막을 작성하는 지금도 다시 읽을 때마다 계속 지웠다 썼다를 반복하고 있습니다. 여전히 이 글이 어떻게 보일까 걱정은 되지만 최선을 다해 글을 썼고,  제가 쏘카에서 보낸 3개월을 돌아보며 QA로서 스스로도 다시 한번 돌아 볼 수 있는 뜻깊은 시간이었습니다. 쏘카 블로그 글 작성을 제안해 주신 팀장님 감사드리고 응원해 주신 팀원들도 감사합니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/QA/qa_8.png&quot; alt=&quot;img&quot; width=&quot;30%&quot; /&gt;
&lt;em&gt;쏘카 10주년 기념으로 키카쿠브를 받았어요&lt;/em&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;-참고&quot;&gt;* 참고&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://brunch.co.kr/@210a51cb29764cb/2&quot;&gt;https://brunch.co.kr/@210a51cb29764cb/2&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://blog.illunex.com/202010105-2/&quot;&gt;http://blog.illunex.com/202010105-2/&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://neklo.com/what-is-quality-assurance-testing/&quot;&gt;https://neklo.com/what-is-quality-assurance-testing/&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://tech.devsisters.com/posts/not-enough-testcase/&quot;&gt;https://tech.devsisters.com/posts/not-enough-testcase/&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://brunch.co.kr/@hsoochun/13&quot;&gt;https://brunch.co.kr/@hsoochun/13&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name>카밀라</name></author><category term="QA" /><category term="qa" /><category term="onboarding" /><summary type="html">안녕하세요. 작년 11월에 쏘카 QA 팀에 경력직으로 입사한 카밀라입니다. 신입 때 QA 업무는 반복적인 업무를 하는 단순 직무라 생각했었습니다. 하지만 여러 프로젝트들을 진행하며 커버리지를 높이기 위한 활동들과 기본 기능을 지속적으로 검증하기 위한 자동화 테스트 구축 등 계속해서 배워야 할 것들이 많은 직무라는 것을 몸소 깨달았습니다.</summary></entry><entry><title type="html">데이터 디스커버리 플랫폼 도입기 - 2편. GKE에 Datahub 구축하기</title><link href="https://tech.socarcorp.kr/data/2022/03/16/metdata-platform-02.html" rel="alternate" type="text/html" title="데이터 디스커버리 플랫폼 도입기 - 2편. GKE에 Datahub 구축하기" /><published>2022-03-16T07:00:00+00:00</published><updated>2022-03-16T07:00:00+00:00</updated><id>https://tech.socarcorp.kr/data/2022/03/16/metdata-platform-02</id><content type="html" xml:base="https://tech.socarcorp.kr/data/2022/03/16/metdata-platform-02.html">&lt;p&gt;안녕하세요, 데이터 플랫폼 팀의 디니입니다.&lt;/p&gt;

&lt;p&gt;이번 글은 ‘쏘카의 데이터 디스커버리 플랫폼 도입기’ 3부작 중 2편입니다. &lt;a href=&quot;https://tech.socarcorp.kr/data/2022/02/25/data-discovery-platform-01.html&quot;&gt;1편 : 데이터 디스커버리 플랫폼 도입기 - 데이터 디스커버리란?&lt;/a&gt;에서는 데이터 디스커버리의 개념과 쏘카가 데이터 디스커버리 플랫폼으로 Datahub를 선택하게 된 의사결정 과정을 소개했습니다.&lt;/p&gt;

&lt;p&gt;2편에서는 Datahub를 GKE 환경에 배포한 과정과 데이터 디스커버리 플랫폼에 필요한 추가 기능들을 어떻게 구현하였는지에 대해 소개하려고 합니다. 다음과 같은 분들이 읽으시면 도움이 되리라고 생각합니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;메타데이터 플랫폼 도입에 관심이 있는 개발자&lt;/li&gt;
  &lt;li&gt;클라우드 환경에 메타데이터 플랫폼 배포하는 과정에 관심이 있는 사람&lt;/li&gt;
  &lt;li&gt;쏘카 데이터 플랫폼팀 업무에 관심이 있는 사람&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;목차는 다음과 같습니다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;#problem-definition&quot;&gt;문제 정의&lt;/a&gt;&lt;/p&gt;

    &lt;p&gt;1.1. 무엇을 해야 하나요?&lt;/p&gt;

    &lt;p&gt;1.2. 고려해야 할 부분&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;#datahub-on-gke&quot;&gt;Datahub on GKE 배포 과정&lt;/a&gt;&lt;/p&gt;

    &lt;p&gt;2.1. GKE 배포&lt;/p&gt;

    &lt;p&gt;2.2. CloudSQL DB migration&lt;/p&gt;

    &lt;p&gt;2.3. Keycloak 인증&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;#metadata-ingestion&quot;&gt;메타데이터 주입 과정&lt;/a&gt;&lt;/p&gt;

    &lt;p&gt;3.1. 메타데이터 주입 방법&lt;/p&gt;

    &lt;p&gt;3.2. 메타데이터 주입 정책 결정&lt;/p&gt;

    &lt;p&gt;3.3. 메타데이터 주입 과정 자동화 (with Airflow)&lt;/p&gt;

    &lt;p&gt;3.4. 메타데이터 추출 과정의 권한 축소&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;#wrap-up&quot;&gt;마무리&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;1-문제-정의&quot;&gt;1. 문제 정의&lt;a name=&quot;problem-definition&quot;&gt;&lt;/a&gt;&lt;/h2&gt;

&lt;h3 id=&quot;11-무엇을-해야-하나요&quot;&gt;1.1. 무엇을 해야 하나요?&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Datahub를 사내 클라우드 환경에 안정적으로 배포합니다.&lt;/li&gt;
  &lt;li&gt;Datahub에 메타데이터 주입 파이프라인을 자동화합니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;12-고려해야-할-부분&quot;&gt;1.2. 고려해야 할 부분&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;쏘카는 데이터 소스로 MySQL(운영)과 BigQuery(분석)를 사용하고 있습니다. 두 데이터 소스의 특성을 고려한 메타데이터 주입 파이프라인이 필요합니다.&lt;/li&gt;
  &lt;li&gt;플랫폼 상의 데이터가 유실 위험 없이 안전하게 저장되어야 합니다.&lt;/li&gt;
  &lt;li&gt;인증된 사용자만 플랫폼에 접속할 수 있어야 합니다.&lt;/li&gt;
  &lt;li&gt;CI/CD 파이프라인을 이용한 배포 자동화가 되어야 합니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;2-datahub-on-gke-배포-과정-&quot;&gt;2. Datahub on GKE 배포 과정 &lt;a name=&quot;datahub-on-gke&quot;&gt;&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;먼저 Datahub를 어떻게 사내 클라우드 환경에 안정적으로 배포했는지 알아보겠습니다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Datahub는 오픈소스 기반으로 매우 빠르게 업데이트되고 있습니다. 해당 배포는 6개월 전에 이루어진 것으로, 현재 Datahub 배포 및 metadata ingestion 과정과는 다소 차이가 있을 수 있습니다. 이 점 양해 부탁드립니다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;21-gke-배포&quot;&gt;2.1. GKE 배포&lt;/h3&gt;

&lt;p&gt;쏘카 데이터 엔지니어링 그룹의 쿠버네티스 환경은 GCP(Google Cloud Platform)의 GKE(Google Kuberentes Engine)를 사용하고 있습니다. 또한 대부분의 애플리케이션을 &lt;a href=&quot;https://helm.sh/&quot;&gt;Helm&lt;/a&gt; Chart를 이용하여 클러스터에 배포하고 있습니다. Datahub 역시 공식 &lt;a href=&quot;https://github.com/acryldata/datahub-helm&quot;&gt;Helm Chart&lt;/a&gt;를 제공하고 있으며, 총 2벌의 차트로 구성되어 있습니다. Datahub Helm Chart 구성은 다음과 같습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;datahub&lt;/code&gt; : Datahub 애플리케이션에 필요한 요소들 설치 (Frontend, GMS 등)&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;prerequisites&lt;/code&gt; : Datahub에 필요한 사전 요소들을 설치 (MySQL, Kafka, ElasticSearch, Neo4j 등)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/img/data-discovery-platform-02/datahub-helm-chart-tree.png&quot; alt=&quot;datahub-helm-chart-tree&quot; /&gt; &lt;em&gt;Datahub 차트 구조&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;공식 Datahub Helm Chart의 Ingress를 쏘카의 환경에 맞게 수정한 뒤 배포하였습니다. 또한 원활한 테스트를 위해 개발 클러스터, 운영 클러스터에 각각 배포하였습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/data-discovery-platform-02/datahub-pods.png&quot; alt=&quot;datahub-pods&quot; /&gt; &lt;em&gt;Datahub 최초 배포 시 Pod 상태&lt;/em&gt;&lt;/p&gt;

&lt;h3 id=&quot;22-cloudsql-db-migration&quot;&gt;2.2. CloudSQL DB migration&lt;/h3&gt;

&lt;p&gt;Datahub는 자체 DB(storage)로 MySQL Pod을 사용합니다. 물론 PVC(PersistentVolumeClaim)이 붙어있긴 했지만, 앞으로 Datahub 애플리케이션 상에서 쌓일 데이터가 점점 늘어날 것이며 데이터의 내용 또한 중요하기 때문에, 앞으로의 확장성과 만에 하나라도 있을 유실 가능성을 방지하는 방향으로 아키텍처를 고민했습니다. 결국에는 MySQL Pod 대신 외부 데이터베이스로 GCP CloudSQL Instance를 연결하기로 결정했습니다.&lt;/p&gt;

&lt;p&gt;구체적으로는 다음 과정으로 진행했습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;CloudSQL DB (혹은 새로운 Instance) 생성&lt;/li&gt;
  &lt;li&gt;(Optional) 사용자 생성&lt;/li&gt;
  &lt;li&gt;Datahub가 CloudSQL 가리키게 하기&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;기존 Datahub의 Helm Chart는 SQL Host로 MySQL Pod을 가리키고 있습니다. 위에서 만든 CloudSQL DB를 가리키게 하기 위해서 Helm Chart를 다음과 같이 수정합니다.&lt;/p&gt;

&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# charts/datahub/values.yaml&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;sql&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;datasource&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;host&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;lt;cloudsql_host_address&amp;gt;:&amp;lt;port&amp;gt;&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;url&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;jdbc:mysql://&amp;lt;cloudsql_host_address&amp;gt;:&amp;lt;port&amp;gt;/&amp;lt;cloudsql_db_name&amp;gt;?verifyServerCertificate=false&amp;amp;useSSL=true&amp;amp;useUnicode=yes&amp;amp;characterEncoding=UTF-8&amp;amp;enabledTLSProtocols=TLSv1.2&quot;&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;hostForMysqlClient&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;lt;cloudsql_host_address&amp;gt;&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;port&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;lt;port&amp;gt;&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;driver&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;com.mysql.jdbc.Driver&quot;&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;username&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;lt;username&amp;gt;&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;password&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;secretRef&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;lt;별도로 생성한 secret 이름&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;secretKey&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;lt;별도로 생성한 secret 키&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# charts/datahub/subcharts/datahub-gms/values.yaml&lt;/span&gt;

&lt;span class=&quot;na&quot;&gt;sql&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;datasource&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;host&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;lt;cloudsql_host_address&amp;gt;:&amp;lt;port&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;url&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;jdbc:mysql://&amp;lt;cloudsql_host_address&amp;gt;:&amp;lt;port&amp;gt;/datahub?verifyServerCertificate=false&amp;amp;useSSL=true&quot;&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;driver&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;com.mysql.jdbc.Driver&quot;&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;username&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;lt;username&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;password&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;secretRef&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;lt;별도로 생성한 secret 이름&amp;gt;&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;secretKey&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;lt;별도로 생성한 secret 키&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;실제로는 민감한 정보들을 Helm Chart에 직접 명시하지 않고 다음처럼 별도의 Secret으로 생성하여 참조하였습니다.&lt;/p&gt;

&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  &lt;span class=&quot;na&quot;&gt;sql&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;datasource&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;host&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;secretRef&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;mysql-secrets&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;secretKey&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;mysql-host&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;url&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;secretRef&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;mysql-secrets&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;secretKey&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;mysql-url&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;hostForMysqlClient&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;secretRef&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;mysql-secrets&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;secretKey&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;mysql-hostForMysqlClient&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;port&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;3306&quot;&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;driver&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;com.mysql.jdbc.Driver&quot;&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;username&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;secretRef&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;mysql-secrets&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;secretKey&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;mysql-username&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;password&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;secretRef&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;mysql-secrets&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;secretKey&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;mysql-password&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Secret yaml 파일은 다음과 같습니다.&lt;/p&gt;

&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;na&quot;&gt;apiVersion&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;v1&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;kind&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;Secret&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;metadata&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;mysql-secrets&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;namespace&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;datahub&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;Opaque&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;mysql-host&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;lt;data&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;mysql-hostForMysqlClient&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;lt;data&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;mysql-password&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;lt;data&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;mysql-root-password&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;lt;data&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;mysql-url&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;lt;data&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;mysql-username&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;lt;data&amp;gt;&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;최종적으로 정상 작동을 테스트합니다. 예를 들어, Datahub UI 상에서 데이터를 수정한 뒤 해당 CloudSQL DB에서 동일한 데이터가 업데이트되는지 확인합니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/data-discovery-platform-02/datahub-create-policy.png&quot; alt=&quot;create-test-policy&quot; /&gt;&lt;em&gt;test_policy라는 정책을 생성해 보았습니다.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/data-discovery-platform-02/datahub-check-data.png&quot; alt=&quot;check-data&quot; /&gt;&lt;em&gt;CloudSQL DB에서 동일한 데이터가 확인됩니다.&lt;/em&gt;&lt;/p&gt;

&lt;h3 id=&quot;23-keycloak-인증&quot;&gt;2.3. Keycloak 인증&lt;/h3&gt;

&lt;p&gt;Datahub이 배포되고 나면, 인증된 사용자만 애플리케이션에 접속되어야 합니다. Datahub는 Okta, Keycloak 등 여러 SSO를 지원합니다. 쏘카에서 이미 Keycloak을 이용하고 있기 때문에 Keycloak을 사용하기로 결정했습니다.&lt;/p&gt;

&lt;p&gt;Datahub에 Keycloak 로그인을 적용하는 방법은 간단했습니다. Helm Chart의 &lt;code class=&quot;highlighter-rouge&quot;&gt;values.yaml&lt;/code&gt;파일에서 frontend 부분에 몇 줄의 설정만 넣어주면 가능했습니다.&lt;/p&gt;

&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;na&quot;&gt;datahub-frontend&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;s&quot;&gt;...&lt;/span&gt;
  &lt;span class=&quot;s&quot;&gt;extraEnvs&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;AUTH_OIDC_ENABLED&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;true&quot;&lt;/span&gt;
    &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;AUTH_OIDC_CLIENT_ID&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;your-client-id&lt;/span&gt;
    &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;AUTH_OIDC_CLIENT_SECRET&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;your-client-secret&lt;/span&gt;
    &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;AUTH_OIDC_DISCOVERY_URI&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;your-provider-discovery-url&lt;/span&gt;  
    &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;AUTH_OIDC_BASE_URL&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;your-datahub-url&lt;/span&gt;  
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;또한 다음과 같은 다양한 설정을 쉽게 정의할 수 있었습니다.&lt;/p&gt;

&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# User and groups provisioning&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# OIDC 로그인 시, Datahub 상에 유저 없으면 자동 생성 여부&lt;/span&gt;
&lt;span class=&quot;s&quot;&gt;AUTH_OIDC_JIT_PROVISIONING_ENABLED=true&lt;/span&gt; 

&lt;span class=&quot;c1&quot;&gt;# OIDC 로그인 시, Datahub 상에 유저가 이미 존재해야 로그인 성공하는지 여부&lt;/span&gt;
&lt;span class=&quot;s&quot;&gt;AUTH_OIDC_PRE_PROVISIONING_REQUIRED=false&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# OIDC의 그룹 정보를 Datahub에 연동&lt;/span&gt;
&lt;span class=&quot;s&quot;&gt;AUTH_OIDC_EXTRACT_GROUPS_ENABLED=true&lt;/span&gt; 
&lt;span class=&quot;s&quot;&gt;AUTH_OIDC_GROUPS_CLAIM=&amp;lt;your-groups-claim-name&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;3-메타데이터-주입-과정--&quot;&gt;3. 메타데이터 주입 과정  &lt;a name=&quot;metadata-ingestion&quot;&gt;&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;이렇게 Datahub를 클라우드 상에 안정적으로 구축했습니다. 하지만 아직 데이터 디스커버리 플랫폼으로서의 기능을 하지는 못합니다. 데이터 소스에서 실제로 메타데이터를 가져와서 플랫폼에서 보여줘야 하고, 이렇게 메타데이터를 가져오는 과정(=metadata ingestion)이 자동화되어야 합니다.&lt;/p&gt;

&lt;h3 id=&quot;31-메타데이터-주입-방법&quot;&gt;3.1. 메타데이터 주입 방법&lt;/h3&gt;

&lt;p&gt;Datahub에서는 &lt;code class=&quot;highlighter-rouge&quot;&gt;recipe&lt;/code&gt;라고 불리는 yaml 파일을 &lt;code class=&quot;highlighter-rouge&quot;&gt;datahub CLI&lt;/code&gt;로 실행하여 메타데이터를 주입합니다. 다음은 BigQuery에서 메타데이터를 가져오는 recipe 파일의 기본 예시입니다.&lt;/p&gt;

&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;na&quot;&gt;source&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
 &lt;span class=&quot;na&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;bigquery&lt;/span&gt;
 &lt;span class=&quot;na&quot;&gt;config&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
   &lt;span class=&quot;na&quot;&gt;project_id&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;lt;project_id&amp;gt;&lt;/span&gt;
   &lt;span class=&quot;na&quot;&gt;options&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
     &lt;span class=&quot;na&quot;&gt;credentials_path &lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;${GOOGLE_APPLICATION_CREDENTIALS}&lt;/span&gt;

&lt;span class=&quot;na&quot;&gt;sink&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
 &lt;span class=&quot;na&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;datahub-rest&quot;&lt;/span&gt;
 &lt;span class=&quot;na&quot;&gt;config&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
   &lt;span class=&quot;na&quot;&gt;server&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;${DATAHUB_GMS_ADDRESS}&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# datahub 애플리케이션의 backend 서버&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;source&lt;/code&gt; : 데이터 소스, 즉 “데이터를 어디서 가져오는지” 정의합니다.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;sink&lt;/code&gt; : “데이터를 어디에 저장하는지” 를 정의합니다. Datahub 어플리케이션에 올릴 수도 있고, 콘솔에 출력할 수도 있고, 파일로 저장할 수도 있습니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;이 형식을 바탕으로 데이터 소스를 바꿀 수도 있고 여러 설정을 적용할 수도 있습니다. 파일을 실행할 때는 &lt;code class=&quot;highlighter-rouge&quot;&gt;datahub ingestion -c &quot;&amp;lt;파일_이름&amp;gt;&quot;&lt;/code&gt;으로 실행합니다.&lt;/p&gt;

&lt;h3 id=&quot;32-메타데이터-주입-정책-결정&quot;&gt;3.2. 메타데이터 주입 정책 결정&lt;/h3&gt;

&lt;p&gt;먼저 “어떤 데이터 소스”에서 메타데이터를 “얼마나 자주” 가져올 건지 결정해야 합니다.&lt;/p&gt;

&lt;p&gt;쏘카에서는 주요 데이터 소스로 MySQL Aurora(운영)와 BigQuery(분석)를 사용하고 있습니다. 하지만 이 데이터 소스의 모든 테이블을 가져올 필요는 없었습니다. 예를 들면 DB에 따라서 개인 정보 관련 민감한 데이터들도 있고, 분석 DB 쪽에는 굳이 전사에 공유될 필요는 없는 임시 테이블들도 다수 존재했습니다. 따라서 각 데이터 소스 별 DB의 목록을 사전에 정하고, 해당 DB의 메타데이터를 주입하기로 했습니다.&lt;/p&gt;

&lt;p&gt;참고로, 다음과 같이 Table 혹은 DB의 이름을 &lt;code class=&quot;highlighter-rouge&quot;&gt;regex pattern&lt;/code&gt;으로 감지하여 선택적 메타데이터 주입이 가능합니다. (물론 데이터 소스마다 방법이 약간 다를 수 있습니다 - 예시는 BigQuery입니다.)&lt;/p&gt;

&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;na&quot;&gt;source&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;bigquery&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;config&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;schema_pattern&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;allow&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# 허용하는 dataset 패턴&lt;/span&gt;
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;my_dataset&quot;&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;table_pattern&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;allow&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# 허용하는 table 패턴&lt;/span&gt;
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;^my_project.my_dataset.my_good_table&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;\&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;$&quot;&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;deny&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# 허용하지 않는 table 패턴&lt;/span&gt;
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;^my_project.my_dataset.my_bad_table&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;\&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;$&quot;&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;include_views&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;false&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;그러면 얼마나 자주 가져와야 할까요? 매일매일 필요에 따라 테이블이 생겨났다가 사라지기도 하고, 테이블의 칼럼이 추가되거나 변경되는 일도 있을 것입니다. 하지만 이런 변화들을 꼭 실시간으로 봐야 할 필요는 없다고 생각했습니다. 하루에 한 번 정도 업데이트한다면, 리소스도 효율화하고 사내 데이터 현황을 파악하는 데 충분하다고 결정을 내렸습니다.&lt;/p&gt;

&lt;h3 id=&quot;33-메타데이터-주입-과정-자동화-with-airflow&quot;&gt;3.3. 메타데이터 주입 과정 자동화 (with Airflow)&lt;/h3&gt;

&lt;p&gt;이렇게 하루에 한 번 메타데이터 주입을 결정하고 난 뒤, 메타데이터 주입을 어떻게 자동화했는지 알아보겠습니다.&lt;/p&gt;

&lt;p&gt;하루에 한 번 Batch 단위의 주입이라면 &lt;code class=&quot;highlighter-rouge&quot;&gt;Airflow DAG&lt;/code&gt;로 간단하게 구현할 수 있었습니다. 데이터 소스에서 메타데이터를 주입하는 Task를 만들고, 하루 한 번만 돌려주면 됐습니다. 그런데 이 작업에는 &lt;code class=&quot;highlighter-rouge&quot;&gt;datahub&lt;/code&gt; 패키지를 설치해야 하는 의존성이 필요합니다.&lt;/p&gt;

&lt;p&gt;데이터 플랫폼 팀에서는 이런 경우 Airflow에 직접 의존성을 설치하지 않고, 필요한 의존성을 담은 Docker Image를 실행하는 &lt;code class=&quot;highlighter-rouge&quot;&gt;KubernetesPodOperator&lt;/code&gt;를 만들어 해결하고 있습니다. 이렇게 하면 DAG 가 아무리 많아도 DAG 간 사용하는 라이브러리나 환경의 의존성 충돌을 방지할 수 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/data-discovery-platform-02/metadata-ingestion-flow.png&quot; alt=&quot;metadata-ingestion-flow&quot; /&gt; &lt;em&gt;메타데이터 주입 흐름&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;작성한 Dockerfile은 다음처럼 간단합니다.&lt;/p&gt;

&lt;div class=&quot;language-dockerfile highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;# datahub-ingestion 이미지를 이용합니다. &lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; linkedin/datahub-ingestion:v0.8.20 &lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# 미리 정의한 recipe 파일을 복사해 가져옵니다. &lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;COPY&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; datahub-ingestion-bigquery /datahub-ingestion-bigquery &lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# datahub CLI를 이용하여 recipe를 실행합니다. &lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;CMD&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; [&quot;ingest&quot;, &quot;-c&quot;, &quot;/datahub-ingestion-bigquery/recipe_bigquery.yaml&quot;] &lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;datahub-ingestion-bigquery 안에는 recipe 파일이 들어 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/data-discovery-platform-02/datahub-ingestion-bigquery.png&quot; alt=&quot;datahub-ingestion-bigquery&quot; /&gt; &lt;em&gt;datahub-ingestion-bigquery 디렉터리 구조&lt;/em&gt;&lt;/p&gt;

&lt;h3 id=&quot;34-메타데이터-추출-과정의-권한-축소&quot;&gt;3.4. 메타데이터 추출 과정의 권한 축소&lt;/h3&gt;

&lt;h4 id=&quot;어떻게-하면-최소한의-권한으로-메타데이터를-추출할-수-있을까&quot;&gt;어떻게 하면 최소한의 권한으로 메타데이터를 추출할 수 있을까?&lt;/h4&gt;

&lt;p&gt;Datahub는 메타데이터를 끌어오는 모든 대상 DB에 SELECT 권한을 허용해야 메타데이터 추출이 가능하도록 만들어져 있습니다. 예를 들면 MySQL DB에 3000개의 DB가 있다고 가정할 때, Datahub의 서비스 계정은 3000개의 DB에 대해 모두 권한이 있어야 하는 것입니다.&lt;/p&gt;

&lt;p&gt;하지만 이 권한을 단독 솔루션에 부여하기에는 보안상 너무 무겁다고 판단했습니다. 그래서 어떻게 하면 최소한의 DB에 접근하면서 같은 기능을 구현할 수 있을지가 큰 고민거리였습니다.&lt;/p&gt;

&lt;h4 id=&quot;information-schema에서-직접-뽑아내-보자&quot;&gt;Information Schema에서 직접 뽑아내 보자&lt;/h4&gt;

&lt;p&gt;당시 데이터 엔지니어링 팀 팀장(이시고 지금은 그룹장이신) 토마스가 아이디어를 주셨습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/data-discovery-platform-02/file-based-ingestion-flow.png&quot; alt=&quot;file-based-ingestion-flow&quot; /&gt; &lt;em&gt;file을 이용하여 메타데이터 상태를 저장하는 흐름&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Datahub에는 데이터 소스의 메타데이터를 특정 형태의 &lt;code class=&quot;highlighter-rouge&quot;&gt;json file&lt;/code&gt;로 변환하여 저장하는 기능이 있습니다. 또한 같은 형식의 json file을 기반으로 메타데이터를 Datahub 플랫폼에 주입하는 것도 가능했습니다. 그리고 해당 파일 형식을 확인해 본 결과 &lt;code class=&quot;highlighter-rouge&quot;&gt;information_schema&lt;/code&gt;에서 대부분(사실 모두) 가져올 수 있는 정보였습니다.&lt;/p&gt;

&lt;p&gt;그러면 &lt;code class=&quot;highlighter-rouge&quot;&gt;information_schema&lt;/code&gt;에서 정보를 가져와서 file 형식을 맞춰 만들어주는 기능을 개발하고, 그 file을 기반으로 Datahub에 메타데이터를 주입하면 되지 않을까? 하는 생각이 들었습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/data-discovery-platform-02/metadata-ingestion-as-is.png&quot; alt=&quot;metadata-ingestion-as-is&quot; /&gt;&lt;em&gt;metadata ingestion AS-IS 흐름&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/data-discovery-platform-02/metadata-ingestion-to-be.png&quot; alt=&quot;metadata-ingestion-to-be&quot; /&gt;&lt;em&gt;metadata ingestion TO-BE 흐름&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;그래서 앞부분은 python script로 개발하고, file을 기반으로 메타데이터를 주입하는 부분은 기존 Datahub 프레임워크를 그대로 이용했습니다.&lt;/p&gt;

&lt;div class=&quot;language-dockerfile highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;# 파이썬 이미지를 이용합니다. &lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; python:3.8 &lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;COPY&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; datahub-ingestion-mysql /datahub-ingestion-mysql &lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;WORKDIR&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; /datahub-ingestion-mysql/src&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;USER&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; root&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# datahub를 포함한 필요한 의존성을 설치합니다. &lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;RUN &lt;/span&gt;pip &lt;span class=&quot;nb&quot;&gt;install&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;--no-cache-dir&lt;/span&gt; mysql-connector-python&lt;span class=&quot;o&quot;&gt;==&lt;/span&gt;8.0.27 &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; pip &lt;span class=&quot;nb&quot;&gt;install&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;--no-cache-dir&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;--upgrade&lt;/span&gt; acryl-datahub&lt;span class=&quot;o&quot;&gt;==&lt;/span&gt;0.8.20 

&lt;span class=&quot;c&quot;&gt;# information_schema에서 메타데이터를 추출하는 python script를 실행하고, datahub CLI로 Datahub 플랫폼에 주입합니다.&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;CMD&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; python main.py ; datahub ingest -c recipe_mysql_prod.yaml &lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;main.py&lt;/code&gt;의 내용은 다음과 같습니다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# main.py
&lt;/span&gt;	
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;json&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;os&lt;/span&gt;

&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;get_info_from_query&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;get_json_result&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;make_and_execute_query&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;execute_query&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;mysql.connector&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Error&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;connection&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;errorcode&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;templates&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;json_table_template&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;user&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;os&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;environ&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;USER&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;password&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;os&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;environ&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;PASSWORD&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;host&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;os&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;environ&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;HOST&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;pattern_conditions&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&quot;schema_pattern_allowed&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;json&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loads&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;os&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;environ&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;PATTERN&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)),&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&quot;schema_pattern_denied&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[],&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&quot;table_pattern_allowed&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[],&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&quot;table_pattern_denied&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[],&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;


&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;get_metadata_from_info_schema&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;user&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;password&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;host&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pattern_conditions&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;try&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;cnx&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;connection&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;MySQLConnection&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;user&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;user&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;password&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;password&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;host&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;host&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;database&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;information_schema&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;port&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;3306&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;cursor&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cnx&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cursor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

        &lt;span class=&quot;n&quot;&gt;table_and_column_result&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;constraint_result&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;execute_query&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;cursor&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cursor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pattern_conditions&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pattern_conditions&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;json_result&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;get_json_result&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;table_and_column_result&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;constraint_result&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;json_table_template&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;json_table_template&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;open&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;metadata.json&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;w+&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;write&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;json_result&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;cursor&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;close&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;cnx&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;close&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;except&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Error&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;err&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;err&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;errno&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;errorcode&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ER_ACCESS_DENIED_ERROR&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;err&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Something is wrong with your user name or password&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;elif&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;err&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;errno&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;errorcode&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ER_BAD_DB_ERROR&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Database does not exist&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;err&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;


&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;__name__&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;__main__&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;get_metadata_from_info_schema&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;user&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;password&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;host&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pattern_conditions&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;information_schema에서는 Table 정보, Column 정보, Constraint (Primary Key 등) 정보 등 여러 가지 정보를 추출합니다. 예를 들어 Column 정보는 다음과 같은 쿼리로 추출합니다. 이렇게 실행한 쿼리 결과를 Datahub에서 이용하는 json 형식에 맞게 바꿔줍니다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# python script 중 information_schema에서 column info를 뽑아내는 부분
&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;get_column_info_query&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pattern_clause&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;column_info_query&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot;
        SELECT Concat(table_schema, '.', table_name) AS schemaName,
               column_name,
               column_comment,
               data_type,
               column_type,
               is_nullable,
               column_key
        FROM   information_schema.columns 
        {pattern_clause}
        ORDER BY schemaname,
                 ordinal_position; 
        &quot;&quot;&quot;&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;column_info_query&lt;/span&gt;
 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;최종-테스트&quot;&gt;최종 테스트&lt;/h4&gt;

&lt;p&gt;이렇게 기능을 구현한 뒤 프로젝트에 같이 참여하시고 계시는 DBA 제이든과 직접 테스트를 해보았습니다. 마지막으로 MySQL 계정 권한에 변경이 필요했습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;AS-IS : 모든 DB에 대해 SELECT 권한&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;TO-BE : 모든 DB에 대해 REFERENCE 권한&lt;/p&gt;

    &lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;USER&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'&amp;lt;username&amp;gt;'&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;@&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'XX.XX.%'&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;IDENTIFIED&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'&amp;lt;password&amp;gt;'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;GRANT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;References&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ON&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TO&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'&amp;lt;username&amp;gt;'&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;@&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'XX.XX.%'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;결과적으로 원하는 DB의 모든 메타데이터를 가져와서 Datahub에 주입하는 데에 성공했습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/data-discovery-platform-02/datahub-test-success.png&quot; alt=&quot;datahub-test-success&quot; /&gt; &lt;em&gt;기능 구현 내용&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/data-discovery-platform-02/datahub-test-success-3.png&quot; alt=&quot;datahub-test-success&quot; /&gt; &lt;em&gt;축소된 권한으로 모든 정보를 가져올 수 있습니다.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;이 기능 개발로 쏘카의 DB에 접근하는 Datahub 계정의 권한이 크게 축소되어 내부 정보보호 규칙에 맞게 보안을 개선할 수 있습니다. 그리고 Datahub 최종 도입 결정에 긍정적인 영향을 미쳤습니다.&lt;/p&gt;

&lt;h2 id=&quot;4-마무리--&quot;&gt;4. 마무리  &lt;a name=&quot;wrap-up&quot;&gt;&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;이러한 여러 과정 끝에, Datahub가 쏘카에 도입될 준비를 마쳤습니다. 현재는 이렇게 테스트 배포를 마치고 사내 공개를 위한 준비 작업을 하고 있습니다. 이 자리를 빌려 Datahub 도입에 힘써주신 모든 분들에게 감사드립니다.&lt;/p&gt;

&lt;p&gt;입사하고 맡은 첫 프로젝트였는데 쏘카 데이터 플랫폼팀의 전반적인 인프라와 배포 흐름에 대해 알 수 있는 좋은 기회였습니다. 여담으로, 구현하면서 슬랙에서 질답을 너무 많이 한 나머지 커뮤니티 기여자로 Datahub 팀과 원격 인터뷰를 하는 기회도 얻었습니다 (!)&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/data-discovery-platform-02/datahub-swag-all.jpeg&quot; alt=&quot;datahub-swag-all&quot; /&gt; &lt;em&gt;인터뷰 기념품으로 준 Datahub 기념품 세트&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/data-discovery-platform-02/datahub-swag-thanks.jpeg&quot; alt=&quot;datahub-swag-thanks&quot; /&gt;&lt;em&gt;기념품과 함께 온 감사 메시지&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;마지막으로 Datahub를 도입하려는 분들에게 팁을 드리자면 다음과 같습니다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;데이터 소스 특성에 따라서 메타데이터 파이프라인 구현 방법 정하기&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;데이터 소스와 업데이트 주기를 결정한 뒤 구현 방법을 결정하기를 추천합니다.&lt;/li&gt;
  &lt;li&gt;하루 한 번 정도의 Batch 작업이라면 &lt;code class=&quot;highlighter-rouge&quot;&gt;Airflow DAG&lt;/code&gt; 로도 충분합니다.&lt;/li&gt;
  &lt;li&gt;최근에는 Datahub UI 상에서 Ingestion을 설정할 수 있는 기능도 나왔습니다. 장단점을 비교해 보고 결정하시면 좋을 것 같습니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;DB 특성에 따라서 메타데이터 추출 로직 조정하기&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;권한에 민감한 DB라면 information_schema에서 바로 메타데이터를 뽑는 로직을 구현하는 방법이 있습니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Datahub 공식 Slack Workspace에 참여하기&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Ingestion, Deployment 등 다양한 주제별로 질답을 나눌 수 있는 채널이 있습니다.&lt;/li&gt;
  &lt;li&gt;거의 모든 질문에 빠르게 답이 달릴 정도로 커뮤니티가 활성화되어 있습니다. 적극적으로 참여하시면서 도움을 얻기를 추천드립니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;다음 편에서는 실제로 데이터 디스커버리 플랫폼이 도입된 후의 운영 방식과 효과에 대해서 살펴보겠습니다.&lt;/p&gt;

&lt;p&gt;긴 글 읽어주셔서 감사합니다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;데이터 플랫폼팀이 하는 업무가 궁금하시다면 &lt;a href=&quot;https://tech.socarcorp.kr/data/2021/03/24/what-socar-data-engineering-team-does.html&quot;&gt;데이터 엔지니어링 팀이 하는 일&lt;/a&gt;과 &lt;a href=&quot;https://www.notion.so/socarcorp/d458b6b77a2243fb873d1ac800c321f7?p=7c55b58735794368876dfb58acae96c5&quot;&gt;쏘카 데이터 플랫폼 엔지니어 채용공고&lt;/a&gt;를, 데이터 플랫폼 팀의 신입 온보딩 과정이 궁금하시다면 &lt;a href=&quot;https://tech.socarcorp.kr/data/2021/12/28/data-engineering-team-onboarding.html&quot;&gt;쏘카 신입 데이터 엔지니어 디니의 4개월 회고&lt;/a&gt;를 보시기를 추천드립니다.&lt;/p&gt;
&lt;/blockquote&gt;</content><author><name>디니</name></author><category term="data" /><category term="data" /><category term="metadata-platform" /><category term="data-engineering" /><summary type="html">안녕하세요, 데이터 플랫폼 팀의 디니입니다.</summary></entry><entry><title type="html">데이터 디스커버리 플랫폼 도입기 - 1편. 데이터 디스커버리란?(feat. Datahub VS Amundsen 비교 분석)</title><link href="https://tech.socarcorp.kr/data/2022/02/25/data-discovery-platform-01.html" rel="alternate" type="text/html" title="데이터 디스커버리 플랫폼 도입기 - 1편. 데이터 디스커버리란?(feat. Datahub VS Amundsen 비교 분석)" /><published>2022-02-25T02:00:00+00:00</published><updated>2022-02-25T02:00:00+00:00</updated><id>https://tech.socarcorp.kr/data/2022/02/25/data-discovery-platform-01</id><content type="html" xml:base="https://tech.socarcorp.kr/data/2022/02/25/data-discovery-platform-01.html">&lt;p&gt;안녕하세요. 데이터 플랫폼 팀의 디니입니다.&lt;/p&gt;

&lt;p&gt;여러분 혹시 도서관에서 가서 책을 찾아보신 경험이 있으신가요? 방대한 도서관에서 원하는 책을 찾으려면 책의 제목, 저자, 분류 기호 같은 정보가 매우 중요합니다. 이런 정보가 없다면 책을 찾기가 많이 힘들어질 겁니다.&lt;/p&gt;

&lt;p&gt;데이터 분석, 머신러닝을 위해 회사의 데이터베이스에서 원하는 데이터를 찾으려고 할때도 비슷한 일이 발생합니다. 어느 데이터가 어디에 있는지, 이 데이터는 무슨 의미인지에 대한 안내가 없으면 데이터를 이용하기가 불편할 것입니다. 이런 문제를 해결하기 위해 데이터의 위치와 의미를 한눈에 보게 돕는 플랫폼이 &lt;strong&gt;“데이터 디스커버리 플랫폼”(DDP, Data Discovery Platform)&lt;/strong&gt;입니다.&lt;/p&gt;

&lt;p&gt;앞으로 3부에 걸쳐 쏘카의 데이터 디스커버리 플랫폼 도입기를 소개하려고 합니다. 그중 1부인 이 글에서는 데이터 디스커버리의 개념과 데이터 디스커버리 플랫폼은 왜 필요한지, 쏘카는 어떤 기준으로 데이터 디스커버리 플랫폼을 선택했는지를 담으려고 합니다. 다음과 같은 분들이 읽으시면 도움이 되리라고 생각합니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;사내 데이터 디스커버리 플랫폼 도입에 관심이 있는 분&lt;/li&gt;
  &lt;li&gt;Datahub, Amundsen 등의 데이터 디스커버리 플랫폼을 PoC 하고 있는 개발자&lt;/li&gt;
  &lt;li&gt;쏘카가 데이터 디스커버리 및 메타데이터 관리를 어떻게 하고 있는지 궁금하신 분&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;목차는 이렇습니다. 각 제목을 클릭하시면 해당 부분으로 이동합니다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;a href=&quot;#what-is-metadata&quot;&gt;데이터 디스커버리란 무엇인가요?&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#why-we-need-metadata-platform&quot;&gt;데이터 디스커버리 플랫폼이 왜 필요한가요?&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#metadata-platform-comparison&quot;&gt;데이터 디스커버리 플랫폼 비교 분석 : Datahub VS Amundsen&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#final-decision&quot;&gt;최종 결정 : Datahub 결정 이유&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#wrap-up&quot;&gt;마무리 &amp;amp; 다음 편 예고&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;
&lt;h2 id=&quot;1-데이터-디스커버리란-무엇인가요--&quot;&gt;1. 데이터 디스커버리란 무엇인가요?  &lt;a name=&quot;what-is-metadata&quot;&gt;&lt;/a&gt;&lt;/h2&gt;

&lt;h3 id=&quot;데이터-디스커버리의-정의&quot;&gt;데이터 디스커버리의 정의&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;데이터 디스커버리(Data Discovery)&lt;/strong&gt;란, “원하는 데이터를 쉽고 빠르게 찾을 수 있다” 의 개념입니다. 빅데이터 시대라는 흐름에 맞게, 회사에도 많은 양의 데이터가 여러 형태로 존재하게 되었습니다. 그리고 많은 사람이 데이터를 생산 및 소비하고 시간이 지나게 되면서 히스토리 파악도 점점 복잡해지기 시작합니다. 이런 상황에서 데이터 디스커버리는 데이터 이용자에게 &lt;strong&gt;“어떤 데이터”가 “어디에” “어떻게 존재”하는지에 대한 정보를 편리하게 제공&lt;/strong&gt;합니다.&lt;/p&gt;

&lt;p&gt;이런 데이터 디스커버리에는 &lt;strong&gt;“메타데이터”&lt;/strong&gt;라는 개념이 중요합니다. 메타데이터는 간단히 말해서 테이블 정보, 컬럼 정보, 코멘트, 테이블을 만든 사람(오너), 테이블 사이의 관계(데이터 리니지) 등을 말합니다. 이러한 메타데이터를 잘 관리하는 것이 데이터 디스커버리의 핵심 역할입니다.&lt;/p&gt;

&lt;h3 id=&quot;데이터-디스커버리의-중요성&quot;&gt;데이터 디스커버리의 중요성&lt;/h3&gt;

&lt;p&gt;데이터를 적극적으로 활용하는 기업은 데이터 디스커버리의 존재에 따라 업무 효율성이 크게 달라집니다. 사내에 많은 직원들이 데이터를 활용해 데이터 분석, 머신러닝, 데이터 기반 기획 등을 하고 있습니다. 각자의 목적에 맞는 데이터가 “어디에 있는지”, “이 데이터가 어떤 의미인지”를 파악하는 데에 대부분의 시간을 소요하게 된다면, 업무 효율성이 매우 떨어지게 될 겁니다.&lt;br /&gt;
데이터 디스커버리를 도입하여 잘 관리한다면 이런 비효율성을 피할 수 있습니다.&lt;/p&gt;

&lt;h3 id=&quot;데이터-디스커버리-플랫폼의-정의&quot;&gt;데이터 디스커버리 플랫폼의 정의&lt;/h3&gt;

&lt;p&gt;데이터 디스커버리를 가능하게 하는 플랫폼입니다. 웹 UI 환경을 제공하며, 데이터의 구조와 관계 등 메타데이터를 한 곳에서 쉽게 보고 검색할 수 있습니다(같은 이유로 데이터 디스커버리는 메타데이터 플랫폼이라는 용어로 쓰이기도 합니다) 대표적인 데이터 디스커버리 프레임워크는 다음과 같습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/linkedin/datahub&quot;&gt;Datahub&lt;/a&gt; : LinkedIn에서 만든 플랫폼입니다.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/amundsen-io/amundsen&quot;&gt;Amundsen&lt;/a&gt; : Lyft에서 만든 플랫폼입니다.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://eng.uber.com/databook/&quot;&gt;Databook&lt;/a&gt; : Uber에서 만든 인하우스 플랫폼 입니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;2-데이터-디스커버리-플랫폼이-왜-필요한가요--&quot;&gt;2. 데이터 디스커버리 플랫폼이 왜 필요한가요?  &lt;a name=&quot;why-we-need-metadata-platform&quot;&gt;&lt;/a&gt;&lt;/h2&gt;

&lt;h3 id=&quot;도입-효과---data-discovery의-관점&quot;&gt;도입 효과 - Data Discovery의 관점&lt;/h3&gt;

&lt;p&gt;쏘카에서는 데이터 분석가, PM, 마케터 등 여러 직군이 업무에 데이터를 활용합니다. 하지만 데이터가 다양한 형식으로 존재하고 비개발 직군 입장에서는 DB에 직접 접근하는 것도 어려움이 있습니다. 기존에 스키마에 대한 정보를 알려주는 어드민이 있었지만, 유지보수가 되고 있지 않았습니다. 이런 이유로 “어떤 데이터를 어디서 찾아야 하는지” 혹은 “이 테이블의 데이터가 어떤 의미인지” 에 대한 질문을 기존에는 슬랙 채널을 이용해 받곤 했습니다. 이런 방식은 히스토리 파악도 쉽지 않고, 답변하는 사람의 시간을 많이 사용하게 됩니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/data-discovery-platform-01/data-ask-brown.png&quot; alt=&quot;data-ask-brown&quot; /&gt;&lt;em&gt;데이터의 의미를 찾아 헤매는 브라운&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/data-discovery-platform-01/data-ask-jung.png&quot; alt=&quot;data-ask-jung&quot; /&gt;&lt;em&gt;데이터의 의미를 찾아 헤매는 정&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;데이터 디스커버리 플랫폼을 도입하면 개발에 대한 도메인이 없더라도 간편한 UI를 통해서 메타데이터를 확인할 수 있습니다.&lt;/p&gt;

&lt;h3 id=&quot;도입-효과---data-governance의-관점&quot;&gt;도입 효과 - Data Governance의 관점&lt;/h3&gt;

&lt;p&gt;데이터 거버넌스란 데이터를 효과적으로 관리하기 위한 일련의 보안, 품질, 규정 등과 관련된 체계를 말합니다. 여러 사람이 데이터를 생산하고 소비할 수록 데이터 거버넌스의 관점은 중요해집니다. 데이터 디스커버리 플랫폼을 도입하면 기존에 흩어져서 관리되던 테이블 스키마, 코멘트가 중앙 관리될 수 있습니다.&lt;/p&gt;

&lt;p&gt;이러한 여러 이유들 때문에 쏘카는 데이터 디스커버리 플랫폼을 도입하기로 결정했습니다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;3-데이터-디스커버리-플랫폼-비교-분석--datahub-vs-amundsen-&quot;&gt;3. 데이터 디스커버리 플랫폼 비교 분석 : Datahub vs Amundsen &lt;a name=&quot;metadata-platform-comparison&quot;&gt;&lt;/a&gt;&lt;/h2&gt;

&lt;h3 id=&quot;poc-과정-소개&quot;&gt;PoC 과정 소개&lt;/h3&gt;

&lt;p&gt;디스커버리 플랫폼을 선정하기 전, 공식 문서 등의 지원이 풍부하고 일반적으로 많이 쓰이는 Datahub와 Amundsen을 직접 배포하고 테스트하며 비교하는 PoC 과정을 거쳐보기로 했습니다.&lt;/p&gt;

&lt;p&gt;사용성, UI, 문서화, 권한, 인증 등 다양한 측면에서 비교해 보았는데, 이 글에서는 그중 중요한 콘셉트를 간추려서 소개해 보겠습니다.&lt;/p&gt;

&lt;h3 id=&quot;datahub-vs-amundsen-비교-분석&quot;&gt;Datahub VS Amundsen 비교 분석&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/img/data-discovery-platform-01/datahub-vs-amundsen.png&quot; alt=&quot;datathub-vs-amundsen&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;1-구조&quot;&gt;1) 구조&lt;/h4&gt;

&lt;p&gt;두 플랫폼의 구조에는 다음과 같은 공통점이 있습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;React 기반 Frontend&lt;/li&gt;
  &lt;li&gt;Elasticsearch 기반 Search Engine&lt;/li&gt;
  &lt;li&gt;Neo4j 기반 Graph DB&lt;/li&gt;
  &lt;li&gt;MySql 기반 Storage&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;차이점은 Datahub는 데이터를 주입할때 Kafka를 사용하고 Amundsen은 ETL 라이브러리를 통한 크롤링 방식을 사용하는 점입니다. 메타데이터 플랫폼 프레임워크의 히스토리를 살펴봤을 때, Amundsen 은 Monolith 방식인 반면 Datahub는 Event-based 방식입니다. 메타데이터 플랫폼의 히스토리에 대해서 좀더 궁금하신 분들은, LinkedIn의 엔지니어링 블로그에 작성된 &lt;a href=&quot;https://engineering.linkedin.com/blog/2020/datahub-popular-metadata-architectures-explained&quot;&gt;DataHub: Popular metadata architectures explained&lt;/a&gt; 글을 보시는 것을 추천합니다.&lt;/p&gt;

&lt;h4 id=&quot;2-메타데이터-주입-방식&quot;&gt;2) 메타데이터 주입 방식&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;Datahub는 &lt;code class=&quot;highlighter-rouge&quot;&gt;yaml&lt;/code&gt; 파일을 실행하여 메타데이터를 주입합니다.
    &lt;ul&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;datahub CLI&lt;/code&gt;를 이용하여 yaml 파일을 실행합니다.&lt;/li&gt;
      &lt;li&gt;연결하는 데이터 소스에 따라 Datahub 라이브러리에 따라오는 연결 플러그인 설치가 필요합니다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Amundsen은 &lt;code class=&quot;highlighter-rouge&quot;&gt;python&lt;/code&gt; 파일을 실행하여 메타데이터를 주입합니다.
    &lt;ul&gt;
      &lt;li&gt;기본적으로 &lt;code class=&quot;highlighter-rouge&quot;&gt;amundsen databuilder&lt;/code&gt; 라는 Python 라이브러리 (ETL framework) 를 사용하며, Extract, Transform, Load 각 과정에 여러 자체 모듈을 끌어와서 사용하는 방식입니다.&lt;/li&gt;
      &lt;li&gt;이 외에도 종종 여러 디펜던시(Dependancy)가 필요했습니다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;&lt;img src=&quot;/img/data-discovery-platform-01/datahub-ingestion-script.png&quot; alt=&quot;datahub-ingestion-script&quot; /&gt;&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;&lt;img src=&quot;/img/data-discovery-platform-01/amundsen-ingestion-script.png&quot; alt=&quot;amundsen-ingestion-script&quot; /&gt;&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;em&gt;Datahub -  BigQuery 데이터 주입 script&lt;/em&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;em&gt;Amundsen - BigQuery 데이터 주입 script&lt;/em&gt;&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;흥미로운 점은 같은 기능을 수행할 때 Datahub와 Amundsen의 &lt;strong&gt;script 길이 차이&lt;/strong&gt;였습니다. Datahub는 10줄 내외의 직관적인 yaml 코드로 가능한 반면, Amundsen의 script는 기본적으로 50 줄 이상이었습니다. 개인적으로 스크립트가 긴 만큼 섬세한 커스텀이 가능하거나 필요하다는 생각은 들지 않았고 오히려 읽기 무겁다는 생각이 들었습니다(공식 깃헙에 있는 샘플이 400줄이었습니다)&lt;/p&gt;

&lt;p&gt;각 ingestion 소스코드는 &lt;a href=&quot;https://github.com/linkedin/datahub/blob/master/metadata-ingestion/examples/recipes/bigquery_to_datahub.yml&quot;&gt;Datahub 공식 Github Repository&lt;/a&gt; 와 &lt;a href=&quot;https://github.com/amundsen-io/amundsen/blob/main/databuilder/example/scripts/sample_bigquery_metadata.py&quot;&gt;Amundsen 공식 Repository&lt;/a&gt; 에서 좀더 자세히 확인할 수 있습니다.&lt;/p&gt;

&lt;h4 id=&quot;3-ui&quot;&gt;3) UI&lt;/h4&gt;

&lt;p&gt;개인 차가 있을 수 있으나, 팀원들의 의견으로는 &lt;strong&gt;Datahub가 훨씬 깔끔하고 보기 편하다&lt;/strong&gt;는 의견이 많았습니다. Datahub UI는 &lt;a href=&quot;https://demo.datahubproject.io/&quot;&gt;공식 데모 사이트&lt;/a&gt;에서 더 확인하실 수 있습니다. (Amundsen은 따로 데모 사이트를 제공하지 않습니다)&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/data-discovery-platform-01/datahub-main.png&quot; alt=&quot;datahub-main&quot; /&gt;&lt;em&gt;Datahub - 메인 UI&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/data-discovery-platform-01/datahub-dataset.png&quot; alt=&quot;datahub-dataset&quot; /&gt; &lt;em&gt;Datahub - 상세 UI&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/data-discovery-platform-01/amundsen-main.png&quot; alt=&quot;amundsen-main&quot; /&gt;&lt;em&gt;Amundsen - 메인 UI&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/data-discovery-platform-01/amundsen-main.png&quot; alt=&quot;amundsen-main&quot; /&gt;&lt;em&gt;Amundsen - 상세 UI&lt;/em&gt;&lt;/p&gt;

&lt;h4 id=&quot;4-문서-기능&quot;&gt;4) 문서 기능&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;Datahub
    &lt;ul&gt;
      &lt;li&gt;테이블 별 / 컬럼 별 태그 부여가 가능합니다.&lt;/li&gt;
      &lt;li&gt;테이블 별 / 컬럼 별 풍부한 마크다운 문서 작성이 가능하고, 원본 소스의 Description을 보존합니다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Amundsen
    &lt;ul&gt;
      &lt;li&gt;테이블 별 태그 부여가 가능합니다.&lt;/li&gt;
      &lt;li&gt;역시 테이블 별 / 컬럼 별 마크다운 제한적인 문서 작성이 가능하고, 원본 소스의 Description을 보존하지 않습니다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;중요한 점은 플랫폼 UI 상에서 테이블 혹은 컬럼의 설명을 수정했을 때 &lt;strong&gt;원본 소스의 Description을 따로 확인할 수 있는지&lt;/strong&gt;의 여부였습니다. Datahub는 다음과 같은 방식으로 Original Description을 동시에 보여주지만, Amundsen은 이런 기능이 없습니다. 또한 Datahub는 원본 Description과 UI 상 Description이 별개로 버전 관리가 되고 있어서, 한쪽의 수정이 다른 쪽에 영향을 끼치지 않았습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/data-discovery-platform-01/datahub-description.png&quot; alt=&quot;datahub-dataset&quot; /&gt;&lt;em&gt;Datahub - UI 상에서 수정하더라도 “Original”(원본 코멘트)이 함께 표기됩니다.&lt;/em&gt;&lt;/p&gt;

&lt;h4 id=&quot;5-오너십&quot;&gt;5) 오너십&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;Datahub는 테이블에 유저 / 그룹 단위로 오너십을 지정할 수 있습니다.&lt;/li&gt;
  &lt;li&gt;Amundsen은 테이블에 유저 단위로만 오너십을 지정할 수 있습니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;6-데이터-계보data-lineage&quot;&gt;6) 데이터 계보(Data Lineage)&lt;/h4&gt;

&lt;p&gt;데이터 계보(Data Lineage)란 데이터의 흐름을 시각화한 개념으로 특정 테이블이 어떤 테이블들을 참조하는지, 데이터가 어디에서 와서 어디로 흘러가는지를 편리하게 알 수 있습니다.&lt;/p&gt;

&lt;p&gt;Datahub와 Amundsen 모두 dbt* 등을 연동하여 데이터 계보를 시각화 할 수 있습니다. (최근에는 Datahub에 dbt 없이 BigQuery 자체에서도 데이터 계보를 가져오는 기능이 추가되었습니다)&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;*&lt;a href=&quot;https://github.com/dbt-labs/dbt-core&quot;&gt;dbt&lt;/a&gt; : 데이터 ETL 과정에서 T(Transform) 과정을 효율화하는 도구입니다. dbt 를 이용하면 SQL 쿼리 모듈화, 테스트, 계보 확인을 편하게 할 수 있습니다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&quot;/img/data-discovery-platform-01/datahub-lineage.png&quot; alt=&quot;datahub-lineage&quot; /&gt;&lt;em&gt;Datahub - 데이터 계보&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/data-discovery-platform-01/amundsen-lineage.png&quot; alt=&quot;amundsen-lineage&quot; /&gt;&lt;em&gt;Amudsen - 데이터 계보 (출처 : https://medium.com/alvin-ai/data-lineage-in-amundsen-powered-by-alvin-df50cd40944c)&lt;/em&gt;&lt;/p&gt;

&lt;h4 id=&quot;7-인증-및-권한&quot;&gt;7) 인증 및 권한&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;Datahub는 SSO 지원 및 세부적인 권한 설정이 가능합니다.
    &lt;ul&gt;
      &lt;li&gt;SSO(Single Sing-On)로 Keycloak, Okta, Google Auth를 지원합니다.&lt;/li&gt;
      &lt;li&gt;사용자 / 그룹 단위로 정책 부여가 가능합니다. 현재는 View 관련 권한은 설정할 수 없고, 테이블이나 컬럼에 대한 설명, 오너, 태그 등을 수정할 수 있는 Edit 권한을 세부적으로 조정 가능합니다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Amundsen은 SSO을 지원하나 세부적인 권한 설정은 지원하지 않습니다.
    &lt;ul&gt;
      &lt;li&gt;SSO 로 Keycloack, Okta, Flask_oidc를 지원합니다.&lt;/li&gt;
      &lt;li&gt;Amundsen은 자체적인 권한 설정을 지원하지 않습니다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/img/data-discovery-platform-01/datahub-policies.png&quot; alt=&quot;datahub-policies&quot; /&gt;&lt;em&gt;Datahub - 권한 및 정책 페이지&lt;/em&gt;&lt;/p&gt;

&lt;h4 id=&quot;8-데이터-소스-지원&quot;&gt;8) 데이터 소스 지원&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;두 플랫폼 모두 BigQuery, Mysql, dbt, AWS S3 등 대중적으로 쓰이는 데이터 소스를 지원합니다.&lt;/li&gt;
  &lt;li&gt;Amundsen은 pandas, neo4j 등의 더 다양한 형태를 지원합니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;9-사용자-이용-통계&quot;&gt;9) 사용자 이용 통계&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;Datahub는 시각화된 이용 분석 페이지가 따로 존재합니다.
    &lt;ul&gt;
      &lt;li&gt;자주 검색된 데이터 셋  / 자주 수행된 액션 등을 그래프로 확인할 수 있습니다. (데모 사이트에서 &lt;a href=&quot;https://demo.datahubproject.io/analytics&quot;&gt;해당 페이지&lt;/a&gt;를 직접 확인하실 수 있습니다.)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Amundsen은 단편적인 이용 통계를 제공합니다.
    &lt;ul&gt;
      &lt;li&gt;메인 화면에서 “인기 있는 데이터셋”을, 각 테이블마다 “해당 테이블을 자주 이용한 사용자”을 확인할 수 있습습니다.&lt;/li&gt;
      &lt;li&gt;따로 분석 페이지는 없습니다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/img/data-discovery-platform-01/datahub-analytics.png&quot; alt=&quot;datahub-analytics&quot; /&gt;&lt;em&gt;Datahub - 사용자 이용 통계 페이지&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/data-discovery-platform-01/amundsen-analytics.png&quot; alt=&quot;amundsen-analytics&quot; /&gt;&lt;em&gt;Amundsen - 테이블을 자주 이용한 사용자&lt;/em&gt;&lt;/p&gt;

&lt;h4 id=&quot;10-서포트&quot;&gt;10) 서포트&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;공식 Github Repository 의 Star 수를 비교했을 때 Datahub가 4.5K, Amundsen이 3K 로 Datahub 가 더 많은 Star를 보유하고 있었습니다.&lt;/li&gt;
  &lt;li&gt;두 플랫폼 모두 공식 슬랙, 웹사이트, Github repository 등의 다양한 채널을 지원했으나, 슬랙의 활성화(질문, 답변의 활발함)나 공식 문서의 체계성 측면에서 Datahub가 좀더 우세했습니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;4-최종-결정--datahub--&quot;&gt;4. 최종 결정 : Datahub!  &lt;a name=&quot;final-decision&quot;&gt;&lt;/a&gt;&lt;/h2&gt;

&lt;h3 id=&quot;사용성의-편리함&quot;&gt;사용성의 편리함&lt;/h3&gt;

&lt;p&gt;가장 결정적인 이유는 사용성 차이였습니다. 사용성은 데이터 이용자와 플랫폼 개발자, 두 측면에서 생각할 수 있습니다.&lt;/p&gt;

&lt;p&gt;데이터 이용자 측면에서는 위에서도 비교했듯이, Datahub가 문서화, 오너십, 권한, 통계, 데이터 계보 관점에서 &lt;strong&gt;더 다양하고 풍부한 기능들을 지원&lt;/strong&gt;합니다. 이런 기능들이 실제로 도입됐을 때, 이용자가 원하는 데이터를 빠르게 찾고 쏘카의 데이터 디스커버리를 발전시키는 데에 더 많은 도움을 얻을 수 있을거라 판단했습니다.&lt;/p&gt;

&lt;p&gt;플랫폼 개발자 측면에서도 &lt;strong&gt;메타데이터 주입 시 Datahub가 더 편리&lt;/strong&gt;했습니다. 동일한 메타데이터를 주입한다고 가정했을 때 Datahub는 10 줄 내외의 yaml 파일로 가능한 반면, Amundsen은 100줄 이상의 Python Script가 필요했습니다. Amundsen Script가 긴 만큼 세세한 설정이 가능한지, 또 그런 세세한 설정이 가능하다고 해도 현재 상황에 필요한지를 고민해봤을 때는 의문점이 있었습니다. 따라서 메타데이터를 주입할 데이터 소스가 한정된 쏘카의 상황에는 Datahub 가 더 적절하다고 판단했습니다.&lt;/p&gt;

&lt;h3 id=&quot;ui의-깔끔함&quot;&gt;UI의 깔끔함&lt;/h3&gt;

&lt;p&gt;많은 사람이 이용하는 솔루션이나 플랫폼을 도입할때는 UI도 무시할 수 없다고 생각합니다. PoC시 Datahub UI가 훨씬 깔끔하다는 반응이 많았고, 매 버전마다 UI가 개선되고 있는 점도 Datahub으로 결정힌 이유 중 하나였습니다.&lt;/p&gt;

&lt;h3 id=&quot;빠르고-풍부한-서포트&quot;&gt;빠르고 풍부한 서포트&lt;/h3&gt;

&lt;p&gt;Datahub의 공식 슬랙 채널에는 현재 2,000명이 넘는 사람이 활동하고 있고, 주제별로 분리된 다양한 채널에서 질답과 오류 대응이 활발하게 이루어지는 편입니다. 또한 새로운 기능을 제안(Feature Request)하는 채널도 따로 있어서, 사용자의 피드백을 풍부하게 반영하려는 노력이 느껴졌습니다. 이 뿐만 아니라 최근 발생한 Log4j 취약점 사태에도 빠르게 해당 취약점을 보완한 패치가 반영되고, 모든 진행 상황이 슬랙을 통해 공유되었습니다.&lt;/p&gt;

&lt;p&gt;개인적인 경험으로는 공식 채널에 질문을 올리면 답이 안달리는 경우가 거의 없었던 것 같습니다. 국내에 데이터 디스커버리 플랫폼 관련 자료가 많지 않고, 팀에 합류하지 얼마 되지 않은 신입 엔지니어의 입장에서는 이런 활발한 서포트가 있다는 것이 매우 중요했습니다. 여담으로 PoC 과정에서 Datahub 공식 슬랙에 질문을 100개정도 한 것 같은데, 이제는 사람들이 질문이 있으면 저를 호출합니다(!)&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/data-discovery-platform-01/datahub-slack-01.png&quot; alt=&quot;datahub-slack-01&quot; /&gt;&lt;em&gt;디니 콜 1&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/data-discovery-platform-01/datahub-slack-02.png&quot; alt=&quot;datahub-slack-02&quot; /&gt;&lt;em&gt;디니 콜 2&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/data-discovery-platform-01/datahub-slack-03.png&quot; alt=&quot;datahub-slack-03&quot; /&gt;&lt;em&gt;디니 콜 3&lt;/em&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;5-마무리--다음-편-예고-&quot;&gt;5. 마무리 &amp;amp; 다음 편 예고 &lt;a name=&quot;wrap-up&quot;&gt;&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;이렇게 쏘카는 데이터 디스커버리 플랫폼으로 Datahub를 선정하게 되었습니다. 다음 편에는 구체적으로 Datahub를 어떻게 사내 인프라 환경에 구축했는지, 메타데이터 주입 방식을 어떻게 자동화하고 효율화 했는지 설명하려고 합니다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;쏘카에서 신입 데이터 엔지니어가 어떤 일을 하는지 궁금하시다면, &lt;a href=&quot;https://tech.socarcorp.kr/data/2021/12/28/data-engineering-team-onboarding.html&quot;&gt;쏘카 신입 데이터 엔지니어 디니의 4개월 회고&lt;/a&gt;에서 확인하실 수 있습니다(데이터 엔지니어링 팀이 데이터 엔지니어링 그룹으로 바뀌고 데이터 웨어하우스 팀, 데이터 플랫폼 팀, 모비딕 팀으로 세분화되었어요)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;긴 글 읽어주셔서 감사합니다. 그러면 다음 편에서 만나요!&lt;/p&gt;</content><author><name>디니</name></author><category term="data" /><category term="data" /><category term="data-engineering" /><summary type="html">안녕하세요. 데이터 플랫폼 팀의 디니입니다.</summary></entry><entry><title type="html">쏘카 PM(Product Manager)은 어떻게 성장하나요?</title><link href="https://tech.socarcorp.kr/product/2022/02/23/growing-up-together-with-the-pm-team.html" rel="alternate" type="text/html" title="쏘카 PM(Product Manager)은 어떻게 성장하나요?" /><published>2022-02-23T07:00:00+00:00</published><updated>2022-02-23T07:00:00+00:00</updated><id>https://tech.socarcorp.kr/product/2022/02/23/growing-up-together-with-the-pm-team</id><content type="html" xml:base="https://tech.socarcorp.kr/product/2022/02/23/growing-up-together-with-the-pm-team.html">&lt;p&gt;안녕하세요. 쏘카의 PM1 팀 프로덕트 매니저 마리입니다.&lt;/p&gt;

&lt;p&gt;“PM은 어떻게 성장하나요? 역량을 키워 나가기 위해 무엇을 하나요?” 주변 동료들과 종종 이런 이야기를 나누곤 합니다. 저 역시 커리어를 시작하면서, 이런 고민들을 많이 했던 것 같습니다. 
이번 글에서는 PM 개인 관점과 동료, 조직과 함께 성장했던 경험을 공유하고자 합니다. 특히 빠르게 성장하는 조직에서 성장하는 방법을 고민하는 PM, PM 팀에게 도움이 되었던 방법을 소개합니다.&lt;/p&gt;

&lt;h2 id=&quot;목차&quot;&gt;목차&lt;/h2&gt;

&lt;p&gt;글의 목차는 다음과 같습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;쏘카의 프로덕트 매니저는&lt;/li&gt;
  &lt;li&gt;빠르게 성장하는 조직, 그 성장 속도만큼 생겨나는 어려움과 고민 지점들&lt;/li&gt;
  &lt;li&gt;돌파구 1: 어려운 점이 있으면, 함께 풀어보자 ‘위클리 미팅’&lt;/li&gt;
  &lt;li&gt;돌파구 2: 업무 관련 공부 갈증은 스터디로 채워보자 ‘빅쿼리 스터디’&lt;/li&gt;
  &lt;li&gt;정리&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;쏘카의-프로덕트-매니저는&quot;&gt;쏘카의 프로덕트 매니저는&lt;/h2&gt;

&lt;p&gt;본격적으로 글을 시작하기에 앞서, 쏘카의 PM이 어떻게 일하는지를 간략하게 소개하고자 합니다.&lt;/p&gt;

&lt;p&gt;IT 스타트업 업계에서도, 회사마다 PM의 역할이 조금씩 다릅니다. 크게 Product Manager, Project Manager, Product Owner로 이야기해 볼 수 있을 것 같습니다. 주요 관리 대상이 Product라면 Product Manager, Project라면 Project Manager로 칭합니다. Product를 관장하더라도 관리의 범위 및 역할을 넓혀 Product Owner라고 칭하기도 합니다.&lt;/p&gt;

&lt;p&gt;쏘카의 PM은 Product Manager로 쏘카의 여러 Product를 관리합니다. PM 그룹은 PM1팀과 PM2팀으로 구성되어 있습니다. PM 1팀은 고객분들이 사용하는 앱&amp;amp;웹 제품을 담당하고 PM 2팀은 B2B, 쏘카 내부 구성원들을 위한 인터널 프로덕트를 담당합니다(보다 상세한 설명은 &lt;a href=&quot;https://bit.ly/SOCAR-RECRUIT&quot;&gt;채용 문서&lt;/a&gt;의 프로덕트 매니저 부분에 나와있습니다 😉)&lt;/p&gt;

&lt;p&gt;그리고 팀 명칭에서도 알 수 있듯이, 쏘카의 PM 조직은 기능 조직의 형태로 구성되어 있습니다. 기능 조직이란 조직 안에서 같은 전문 기능 영역을 수행하는 구성원들 간 같은 팀으로 구성되어 있는 형태를 말합니다. 기능 조직의 가장 큰 장점은 동일한 업무를 진행하는 PM들과 고민을 나누고, 주변 동료들이 진행하는 프로젝트를 가까이서 보면서 정말 많이 배울 수 있다는 점입니다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;빠르게-성장하는-조직-그-성장-속도만큼-생겨나는-어려움과-고민-지점들&quot;&gt;빠르게 성장하는 조직, 그 성장 속도만큼 생겨나는 어려움과 고민 지점들&lt;/h2&gt;

&lt;p&gt;팀 동료들과 서로의 프로젝트를 공유하고, 함께 성장하기까지는 부단한 노력이 필요했습니다. 조직이 빠르게 성장하는 만큼 프로젝트의 진행 속도가 빠르고, 일하는 동료들 대부분 바빠 보였습니다. 특히 지난 하반기는 IPO를 앞두고 회사가 빠르게 성장하면서 더 효율적으로 일할 수 있는 방법에 대해 고민하기 시작했습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/growing-up-together-with-the-pm-team/1.png&quot; alt=&quot;&quot; /&gt;
&lt;em&gt;제가 좋아하는 유튜브 채널 ‘존잡생각’에서도 비슷한 얘기를 합니다. 그렇기 때문에 회사에서 본인을 빠르게 성장하는 방법 - People Scaling이 필요하다고 강조합니다.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;쏘카의 PM들은 PM 직업 특성상 문제를 가만두지 않습니다. 이 문제를 해결할 방법을 찾아보기로 했습니다. 방법을 찾고, 작년에 실행했던 프로젝트 2가지를 소개합니다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;돌파구-1-어려운-점이-있으면-함께-풀어보자-위클리-미팅&quot;&gt;돌파구 1: 어려운 점이 있으면, 함께 풀어보자 ‘위클리 미팅’&lt;/h2&gt;

&lt;p&gt;우선 우리의 고민거리를 함께 이야기하는 시간을 마련했습니다. 매주 수요일 오전 11시로 미팅을 잡아두고, 안건이 있으면 이 시간에 함께 모여 이야기를 나눴습니다. 헤아려보니, 작년 6월 초에 시작해서 12월까지 7개월간 총 24번의 위클리 미팅이 진행되었습니다! 
&lt;img src=&quot;/img/growing-up-together-with-the-pm-team/2.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/growing-up-together-with-the-pm-team/3.png&quot; alt=&quot;&quot; /&gt;
위클리 미팅은 아래의 방식으로 진행되었습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;위클리 미팅 하루 전까지, 동료들과 이야기하고 싶은 안건이 있으면 ‘PM1 팀 위클리’ 노션 페이지에 해당 내용을 등록합니다.&lt;/li&gt;
  &lt;li&gt;안건이 등록되면, 매주 수요일 오전 11시에 회의실 또는 행아웃으로 만납니다. (가끔 날이 좋으면, 서울숲으로 나가기도 합니다 🌳 🎵)&lt;/li&gt;
  &lt;li&gt;발제자가 안건을 소개하고, 동료들과 함께 이야기를 나눕니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;처음 위클리 미팅을 만들자는 제안이 나왔을 때, 동료들의 의견은 반반이었습니다. “오, 너무 좋겠다. 나 이야기해보고 싶은 것 있어.” 라고 긍정적인 견해를 가진 경우도 있었지만, “매주 이야기할 만큼, 고민이 많을까.” 회의적인 동료들도 있었습니다. 그래서 안건이 있을 때마다 만나자고 한 것인데, 되돌아보니 한 달 평균 3번 이상, 1주 정도를 제외하면 늘 만났습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/growing-up-together-with-the-pm-team/4.jpg&quot; alt=&quot;&quot; /&gt;
&lt;em&gt;가을 날의 서울숲 미팅은 정말 환상입니다! 😍&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;위클리 미팅은 ‘함께’ ‘빠르게’ 문제를 풀어나가는 창구가 되었습니다. 개개인은 프로젝트를 진행하면서 겪는 다음과 같은 문제를 해결할 수 있는 아이디어를 얻어 갔습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;“배포하고 작고 큰 문제들이 발생하는데, 배포 시나리오는 어떻게 작성하고 계시나요?”&lt;/li&gt;
  &lt;li&gt;“업무 대체자는 어떻게 선정하고, 공유하는 게 좋을까요?”&lt;/li&gt;
  &lt;li&gt;“미팅이 너무 많아지고 있는데, 미팅 시간은 어떻게 조정하고 계신가요?”&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;PM들마다 경험한 프로젝트도 다르고, 강점도 다릅니다. 누군가 이런 고민을 발제하면, 각자 도움 되었던 문서와 방법을 공유했고, 꿀팁 가득한 가이드 문서가 하나 뚝딱 만들어졌습니다. 위클리 회의 이후 팀 내 모든 PM이 가이드 문서를 보고 고민 포인트가 줄었습니다.&lt;/p&gt;

&lt;p&gt;또한 PM 위클리 미팅은 팀의 문제를 하나씩 푸는 계기가 되었습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;“새로운 구성원이 오면, 매번 온보딩 준비를 해야해요. 시간도 줄이고 일관성도 갖추기 위해 가이드문서를 만드는 게 어떨까요?”&lt;/li&gt;
  &lt;li&gt;“다른 팀에서 제품에 관한 공통 질문이 자주 들어오는데요. 앱 사용설명서를 만들어서 공유하면 좋겠어요.”&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;이런 부분은 혼자 해결해 나가기 어려운 문제입니다. 문서화 작업을 하더라도 끊임없는 업데이트가 필요하고, 이를 위해 우리 팀에 필요한 일임에 공감대가 형성되어야 하기 때문입니다. 실제 이 시간을 통해 그간의 숙원 사업이었던 ‘쏘카 앱 사용설명서’도 만들어졌습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/growing-up-together-with-the-pm-team/5.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;결과적으로 위클리 미팅의 효과는 기대했던 만큼 좋았습니다. 24번의 미팅을 거치면서 총 17개의 의제가 논의되었고, 그중 9개는 안건을 제안한 동료의 문제에 공감해 새로운 방법으로 시도해 보고 있습니다. 이를테면, 새로운 구성원이 우리 팀에 왔을 때, 보다 잘 온보딩할 수 있는 방법이 필요하다는 이야기에 PM1 팀 뉴비를 위한 온보딩 프로세스가 만들어졌습니다. 프로젝트 하고 나서 백로그를 체계적으로 관리하자는 안건이 제안되어 백로그 프로세스 및 문서를 만들어 운영하고 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/growing-up-together-with-the-pm-team/6.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;돌파구-2-업무-관련-공부-갈증은-스터디로-채워보자-빅쿼리-스터디&quot;&gt;돌파구 2: 업무 관련 공부 갈증은 스터디로 채워보자 ‘빅쿼리 스터디’&lt;/h2&gt;

&lt;p&gt;일을 하다 보면 더 공부해 보고 싶은 갈증이 생깁니다. 저의 경우에는 ‘프로덕트 데이터’에 대한 공부를 좀 더 하고 싶다는 생각이 있었습니다. 기능을 배포하고, 유저들의 행동 패턴을 더 들여다보고 싶거나 백로그에 등록해 둔 일감을 좀 더 디벨롭해보고 싶을 때 데이터를 직접 조회하여 문제를 해결하고 싶다는 생각이 들었습니다.&lt;/p&gt;

&lt;p&gt;그래서 빅쿼리 조회 역량을 키워나가는데 관심이 있는 동료들을 모아, 빅쿼리 스터디를 진행했습니다. 처음에는 PM팀으로 시작해, 지금은 사업팀, CRM팀의 동료도 모여 함께 진행하고 있습니다. 헤아려보니, 작년 7월부터 시작해서 총 20회 스터디가 진행되었습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/growing-up-together-with-the-pm-team/7.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;빅쿼리 스터디는 아래의 방식으로 진행되었습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;4명의 동료들이 돌아가면서 매주 문제를 출제합니다.&lt;/li&gt;
  &lt;li&gt;직접 쿼리를 작성해 빅쿼리로 사내 데이터를 직접 조회합니다.&lt;/li&gt;
  &lt;li&gt;매주 금요일 오전 9시에 만나 서로 쿼리를 공유하며 피드백합니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;조금 더 구체적인 설명을 하기 위해 과거에 진행했던 스터디 경험을 공유합니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/growing-up-together-with-the-pm-team/8.png&quot; alt=&quot;&quot; /&gt;
&lt;em&gt;1) 문제를 출제하고, 슬랙 스터디 채널에서 공유합니다.&lt;/em&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;이 케이스는 카리나가 발제자였습니다. 화요일 중에 발제자가 문제를 제출하고, 슬랙 스터디 채널에 문제 링크를 공유합니다. 유저의 서비스 사용 자료를 기반으로, &lt;성장 지수=&quot;&quot;&gt; 지표를 집계하고 도출하는 방법을 알아보았습니다.&lt;/성장&gt;&lt;/li&gt;
  &lt;li&gt;성장지수란 사용자의 서비스 사용과 관련한 상태 변화를 수치화해서 서비스가 성장하는지를 알려주는 지표입니다. 유저의 서비스 사용 자료를 기반으로 Signup(신규 등록 후 사용을 시작함), Deactivation(활성화 유저에서 비활성화 유저로 전환), Reactivation(비활성화 유저에서 활성화 유저로 전환), Exit(서비스를 탈퇴함)을 정의하고 이를 기반으로 성장지수(signup user + reactivation user - deactivation user - exit) 지표를 도출합니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/img/growing-up-together-with-the-pm-team/9.png&quot; alt=&quot;&quot; /&gt;
&lt;em&gt;2) 퇴근 후 목요일 밤은 빅쿼리 문제 푸는 시간입니다. 😂 질문과 답변이 오고 갑니다.&lt;/em&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;발제자가 문제를 출제하고 나면 스터디가 있는 금요일 오전 전까지 각자 문제를 풀어옵니다. 보통 퇴근 후 목요일 밤 다시 출근했다고 표현하곤 합니다 😂. 문제를 풀면서, 모르는 부분에 대해서는 질문과 답변이 오고 갑니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/img/growing-up-together-with-the-pm-team/10.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/growing-up-together-with-the-pm-team/11.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;금요일 오전 9시에 만나서, 작성한 쿼리를 공유하고, 피드백을 주고 받습니다. 피드백은 ‘출제자의 의도에 부합하는 방향으로 함수를 적재적소에 사용했는지’를 중점적으로 나눕니다. 이번 문제는 12월 1일부터 12월 10일까지 해당 기간 동안 첫 사용을 한 회원의 날짜별 회원 상태를 구하고, 그 집계를 통해 성장성을 지수화하는 것이 목표였습니다. 이를 위해
    &lt;ul&gt;
      &lt;li&gt;SELECT, UNION ALL 구문을 활용해 12월 1일부터, 12월 10일까지의 날짜 컬럼을 가진 테이블 생성&lt;/li&gt;
      &lt;li&gt;CASE WHEN 함수를 활용하여, 유저의 ‘신규 등록일’과 ‘탈퇴일’, ‘사용일’ 구하기&lt;/li&gt;
      &lt;li&gt;CROSS JOIN 함수를 활용하여, 두 개의 테이블을 상호 조인하기&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;위와 같은 내용이 잘 진행되었는지 이야기합니다. “우선 유저별 회원 상태를 구할 수 있도록, 각각의 활동 로그를 모은 테이블을 만들었어. 여기서 예약 테이블과 탈퇴 테이블을 left join 했고…” 와 같이 쿼리를 왜 이렇게 작성했는지를 동료들에게 설명합니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;피드백을 주고 받는 과정을 통해 좀 더 효율적으로 쿼리를 작성할 수 있는 방법, 보다 적은 용량으로 조회할 수 있는 방법, 다른 사람들이 더 알아보기 쉽게 쿼리를 작성하는 방법을 익히게 되었습니다. 스터디 이후 서브 쿼리보다 WITH 구문을 더 애용하게 되었습니다!&lt;/li&gt;
  &lt;li&gt;특히 이번 시간에는 ‘확장성’ 에 대한 이야기를 나누었습니다. 성장 지수라는 것은 카리나가 제시한 것과 같은 특정한 날짜 구간이 아니더라도 더 넓히거나 좁혀가면서 다양하게 조회해 볼 수 있을텐데, 이를 위해서는 쿼리를 어떻게 작성해보면 좋을까는 궁금함이 생겨서 이야기를 꺼냈습니다. 이때 에이든이 이전에 실무에서 사용했던 DECLARE 구문을 소개해 주셨습니다!&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;declare&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;d1&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;date&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;DEFAULT&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;TIMESTAMP&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;CURRENT_DATE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;&quot;Asia/Seoul&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;&quot;Asia/Seoul&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
    
&lt;span class=&quot;c1&quot;&gt;-- WHERE 조건에서 아래와 같이 표현하면, '어제까지' 로 조회 가능.&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;DATE&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;d1&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;이처럼 사내 스터디는 데이터 역량을 키워나가는데 매우 효과적이었습니다. 이를 통해 SELECT / FROM / WHERE 정도의 간단한 조회만 할 수 있었는데, 윈도우 함수가 손에 익는 수준으로 쿼리를 조회할 수 있게 되었습니다. 실무 진행에도 큰 도움이 되었습니다. 직접 제품 성과를 조회해서 업무 성과를 어필할 수 있게 되었습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/growing-up-together-with-the-pm-team/12.png&quot; alt=&quot;&quot; /&gt;
&lt;em&gt;최근 1년 빅쿼리 스터디 회고하면서 나눴던 이야기들&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/growing-up-together-with-the-pm-team/13.jpg&quot; alt=&quot;&quot; /&gt;
&lt;em&gt;어느덧 8개월 가까이, 매주 금요일 온라인으로 함께 빅쿼리를 해나가고 있는 마리, 카리나, 에이든, 브라운&lt;/em&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;정리&quot;&gt;정리&lt;/h2&gt;

&lt;blockquote&gt;
  &lt;p&gt;무엇이건 실제 임팩트를 남기려면 혼자 힘으로만 되는 게 없습니다. 함께 해야 합니다. 
그리고 무엇보다 이런 ‘함께’, 그리고 ‘자라기’를 매일매일 해야 합니다. 
(…) 대화는 우리가 혼자서는 생각하지 못했던 것들을 만들게 해 줄 것입니다.&lt;/p&gt;

  &lt;p&gt;- 함께 자라기, 김창준&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;최근 재밌게 읽었던 &amp;lt;함께 자라기: 애자일로 가는 길&amp;gt; 책에 나오는 이야기입니다. 쏘카는 빠르게 성장하는 조직인 만큼, 어떻게 함께 성장할 것인가에 대한 고민을 끊임없이 하고 있습니다.&lt;/p&gt;

&lt;p&gt;이 글에서는 PM1팀 위클리와 사내 스터디를 소개해드렸습니다. PM1팀 위클리, 회고, 1on1을 통해 주 단위로 빠르게 피드백을 주고받고, 필요시 사내 스터디를 만들어 실무에 필요한 역량을 함께 키워나가고 있습니다. 만약 쏘카 PM 직군에 관심이 있다면 채용 공고를 확인 부탁드립니다!&lt;/p&gt;</content><author><name>마리</name></author><category term="product" /><category term="product manager" /><summary type="html">안녕하세요. 쏘카의 PM1 팀 프로덕트 매니저 마리입니다.</summary></entry><entry><title type="html">쏘카의 관제 장치(Telematics Device)가 하는 일</title><link href="https://tech.socarcorp.kr/mobility/2022/02/15/control-device-with-car-sharing.html" rel="alternate" type="text/html" title="쏘카의 관제 장치(Telematics Device)가 하는 일" /><published>2022-02-15T07:00:00+00:00</published><updated>2022-02-15T07:00:00+00:00</updated><id>https://tech.socarcorp.kr/mobility/2022/02/15/control-device-with-car-sharing</id><content type="html" xml:base="https://tech.socarcorp.kr/mobility/2022/02/15/control-device-with-car-sharing.html">&lt;p&gt;안녕하세요. 쏘카 커넥티드플랫폼 그룹 커넥티드디바이스팀 주노입니다.&lt;/p&gt;

&lt;p&gt;쏘카에서 운영되는 차량과 개인 소유의 차량은 어떠한 차이가 있을까요? 비대면으로 카셰어링을 운영하기 위해, 다양한 기술들이 쏘카 차량에 담겨있다는 사실 혹시 알고 계셨나요?&lt;/p&gt;

&lt;p&gt;원격으로 차량의 예약, 차량 운행, 차량 반납이 가능하도록, 쏘카의 차량에는 일반 차량과 달리 다양한 IoT 장치들이 설치되어 있습니다. 관제 장치, 블랙박스, 하이패스 등 겉으로 보기엔 일반 제품들과 유사한 모습입니다. 하지만 쏘카에는 다소 특별한 기능들을 가진 장치들이 차량 내부에 장착됩니다.&lt;/p&gt;

&lt;h2 id=&quot;목차&quot;&gt;목차&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;쏘카 차량의 관제 장치(Telematics Device)란&lt;/li&gt;
  &lt;li&gt;쏘카 차량의 관제 장치가 하는 일
    &lt;ul&gt;
      &lt;li&gt;1) 차량의 데이터를 수집합니다.&lt;/li&gt;
      &lt;li&gt;2) 차량의 문을 잠그고 열 수 있습니다.&lt;/li&gt;
      &lt;li&gt;3) 다양한 통신 방법으로 데이터를 교환합니다.&lt;/li&gt;
      &lt;li&gt;4) 외부에 노출된 차량이라는 조건(온도, 습기)을 견뎌야만 합니다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;맺으며&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;쏘카-차량의-관제-장치telematics-device란&quot;&gt;쏘카 차량의 관제 장치(Telematics Device)란&lt;/h2&gt;

&lt;p&gt;관제 장치의 사전적 정의는 ‘위성이 본래의 역할을 수행하도록 관리하여 통제하는 장치. 주로 통신 위성, 방송 위성, 탐사 위성 따위를 관제하며, 위성의 임무에 따라 기기의 내용도 달라진다’입니다. &lt;strong&gt;쏘카의 관제 장치는 ‘차량이 본래의 역할을 수행할 수 있도록 관리, 통제하는 장치’&lt;/strong&gt;라고 정의할 수 있습니다. 쏘카는 비대면으로 차량을 대여할 수 있는 비대면 카셰어링 서비스를 운영하고 있습니다. 이런 서비스를 운영하기 위해 차량을 관리하고 통제하는 장치가 필요합니다.&lt;/p&gt;

&lt;p&gt;개인이 소유한 차량과는 달리, 쏘카의 차량은 관제 장치를 장착함으로써 카셰어링 차량으로 변하게 됩니다. 고객이 차량을 예약하고, 주행하고, 반납하기 위해서는 차량의 위치나 차량의 상태가 자동으로 확인되어야 하며, 예약한 고객이 스마트키를 들고 있지 않더라도 차량을 이용할 수 있도록 차량의 문을 열고 잠글 수 있어야 하기 때문입니다.&lt;/p&gt;

&lt;p&gt;이번 글에서는 쏘카에서 운영하는 1만 7천 대의 차량에 장착된 다양한 장치들 중 관제 장치에 관해 다루고자 합니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/control-device-with-car-sharing/sts-1-app.png&quot; alt=&quot;img&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/control-device-with-car-sharing/sts-0-schematic.jpg&quot; alt=&quot;img&quot; /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;쏘카-차량의-관제-장치가-하는-일&quot;&gt;쏘카 차량의 관제 장치가 하는 일&lt;/h2&gt;

&lt;h3 id=&quot;1-차량의-데이터를-수집합니다&quot;&gt;1) 차량의 데이터를 수집합니다.&lt;/h3&gt;

&lt;p&gt;차량의 정보를 수집하여, 비대면으로 예약 / 반납이 가능할 수 있는 기능들이 숨겨져 있습니다.&lt;/p&gt;

&lt;p&gt;쏘카에는 40 종류가 넘는 다양한 차종을 보유하고 있고, 차량 대수로는 약 17,000대가 존재합니다. 이 많은 차량은 어디에 위치했는지, 반납 시 차량 시동은 잘 꺼져있는지, 주유량이나 전기차 충전량은 충분한지, 문은 제대로 잘 잠기고 열리는지 등이 원격에서 실시간으로 확인이 되어야 비대면 카셰어링 서비스가 가능합니다.&lt;/p&gt;

&lt;p&gt;데이터를 수집할 때 있어 보안에도 신경 써야 합니다. 특히 고객의 개인 정보, 위치 정보 데이터가 대표적으로 그렇습니다. 이런 데이터는 정보보호 및 개인 정보보호 관리체계 인증(ISMS-P)에 따라 보안을 철저히 하여 숨겨져 있으며, 권한을 가진 일부 직원들만 해당 정보를 조회할 수 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/control-device-with-car-sharing/sts-2-data.jpg&quot; alt=&quot;img&quot; /&gt;&lt;/p&gt;

&lt;p&gt;차량의 데이터를 수집해서 고객의 편리한 운행을 돕는 것 뿐만 아니라, 보다 효율적으로 차량을 운영하고 관리할 수 있습니다. 예를 들어 차량 내부의 다양한 센서 및 ECU(Electronic Control Unit)로 수집되는 데이터를 수집해 사용 중인 차량, 시스템, 장치의 이상 징후 및 안정성을 관리(PHM, Prognostics and Health Management)할 수 있습니다.&lt;/p&gt;

&lt;p&gt;차량의 데이터를 수집하는 엔지니어링이 궁금하신 분은 &lt;a href=&quot;https://tech.socarcorp.kr/mobility/2022/01/06/socar-iot-pipeline-1.html&quot;&gt;차량용 단말을 위한 IoT 파이프라인 구축기 #1&lt;/a&gt;, &lt;a href=&quot;https://tech.socarcorp.kr/mobility/2022/02/09/socar-iot-pipeline-2.html&quot;&gt;차량용 단말을 위한 IoT 파이프라인 구축기 (feat. Kafka) #2&lt;/a&gt; 두 글을 추천합니다.&lt;/p&gt;

&lt;h3 id=&quot;2-차량의-문을-잠그고-열-수-있습니다&quot;&gt;2) 차량의 문을 잠그고 열 수 있습니다.&lt;/h3&gt;

&lt;p&gt;쏘카의 비대면 서비스를 위해선 근거리뿐만 아니라, 원거리에서도 차량을 제어할 수 있어야 합니다.
일반적인 차량에서는 스마트키를 통해 차량의 문을 열고 잠글 수 있으며, 스마트키를 차량 실내에 두어야만 차량의 시동을 걸 수 있습니다.
쏘카에는 스마트폰만으로도 차를 열고 잠글 수 있어야 하는데, 이때 관제 장치가 차량의 문을 열고 닫는 명령하는 역할을 담당합니다. 
또한 고객분들이 차량의 위치를 보다 편하게 찾을 수 있도록, 스마트폰으로도 비상등을 켜거나 경적(Horn)을 울릴 때에도 관제 장치가 사용됩니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/control-device-with-car-sharing/sts-3-app.png&quot; alt=&quot;img&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;3-다양한-통신-방법으로-데이터를-교환합니다&quot;&gt;3) 다양한 통신 방법으로 데이터를 교환합니다.&lt;/h3&gt;

&lt;p&gt;쏘카의 관제 장치는 스마트폰처럼 LTE나 3G 통신을 통해 쏘카의 서버와 메시지를 교환하게 됩니다. 이를 통해 서버는 차량 제어에 관한 데이터를 수집하게 됩니다.&lt;/p&gt;

&lt;p&gt;LTE/3G 네트워크 망은 전국적으로 통신사의 전파 중계기가 설치되어 있어 대부분의 지역에서 네트워크 연결이 가능합니다. 하지만 전파 중계 설비가 고장났거나, 네트워크 전파가 미처 닿지 않는 통신 음영 지역에서는 데이터 송수신이 잠시 끊기는 경우가 있습니다. 이를 막기 위해 쏘카에서는 또 다른 무선 통신 기술도 사용합니다. 블루투스는 2.4~2.485GHz의 극초단파를 사용한 개인 근거리 무선 통신 산업 표준 규격입니다. 쏘카의 관제 장치는 BLE 5.0 통신이 가능하여 지하주차장, 산지, 바다지역 등 3G/LTE 통신이 매우 약한 지역에서도 문제없이 차량을 제어할 수 있습니다. 그리고 근거리에서 차량 제어 시, 스마트폰의 블루투스를 켤 경우 켜지 않았을 때 보다 더 빠르게 차량을 제어할 수 있습니다.&lt;/p&gt;

&lt;p&gt;블루투스 통신을 통해 스마트폰뿐만 아니라 다양한 전자 장치와도 무선 통신이 가능합니다. 이를 통해 차량 내/외부, 도로와 주차장 등 다양한 환경에서의 센서나 장치에서 무선으로 데이터를 수집할 수 있습니다. 보다 정확하게 차량의 위치를 찾거나, 차량에 장착된 센서에서 데이터를 획득하고, 차량의 다양한 정보들을 수집하거나 데이터를 교환할 수 있습니다.&lt;/p&gt;

&lt;h3 id=&quot;4-외부에-노출된-차량이라는-조건온도-습기을-견뎌야만-합니다&quot;&gt;4) 외부에 노출된 차량이라는 조건(온도, 습기)을 견뎌야만 합니다.&lt;/h3&gt;

&lt;p&gt;쏘카의 차량은 자연 환경에 노출되어 있습니다. 운전 중 일 때의 수많은 진동, 여름에는 90도 겨울에는 -20도까지 변하는 온도, 비 오는 날에는 엄청난 습기까지 일반적인 전자 장비는 바로 고장이 날 수 밖에 없는 조건입니다.&lt;/p&gt;

&lt;p&gt;이런 조건에서 정상적인 사용이 가능할 수 있도록 쏘카 차량 내 장치들은 &lt;a href=&quot;https://www.koreascience.or.kr/article/JAKO202129159578200.pdf&quot;&gt;AEC-Q100&lt;/a&gt; 같은 인증을 획득하거나, 인증 규격 이상의 성능을 가져야만 합니다. (인증은 환경 시험(Environmental Test, 저/고온, 열 충격시험 등), 기구 시험(Mechanical Test, 진동 낙하 충격 시험 등), 전기적 성능 시험(Electrical Test, 작동 전압, 전원 순단 및 전압 변동 시험)을 통해 장치의 성능을 평가하게 됩니다)&lt;/p&gt;

&lt;p&gt;220V 콘센트가 아니라 차량의 배터리만 사용할 수 있는 차량 내 전자 장치들은 전기를 공급 받는 것도 힘든 일입니다. 모든 전자 장치는 회로에서 전자기 노이즈가 발생하며, 이 정도가 심한 경우 다른 전자 장치가 영향을 받아 오작동을 하거나 고장날 수도 있습니다. 차량에 설치되는 장치인만큼, 장착된 장비들이 전자 장치 간 간섭(EMI/EMC)로 인한 영향을 방지하기 위해, &lt;a href=&quot;https://www.rra.go.kr/FileDownSvl?file_type=LAWKR&amp;amp;file_parentseq=113&amp;amp;file_seq=1&quot;&gt;표준 인증(KN41)&lt;/a&gt;을 득하거나 표준 규격보다 더 낮은 양의 전자기 노이즈만 발생시키도록 해야합니다.&lt;/p&gt;

&lt;p&gt;이러한 조건 속에서도 서비스가 가능할 수 있도록, 관제 장치에는 개발, 제조, 납품, 장착, AS 전반에 걸친 다양한 노하우와 기술이 포함되어 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/control-device-with-car-sharing/sts-4-env.png&quot; alt=&quot;img&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/control-device-with-car-sharing/sts-5-soldering.png&quot; alt=&quot;img&quot; /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;맺으며&quot;&gt;맺으며&lt;/h2&gt;

&lt;p&gt;쏘카의 손으로 제작된 관제 장치는 2020년 처음 장착된 이래 10,000대가 넘는 차량에 장착되었습니다.
관제 장치는 약 6천만 시간 동안, 57만 명의 고객들의 176만 번의 차량 운행을 가능하게 하였으며 2억 Km의 거리의 여정 동안 3천만 번의 제어를 수행하고 6억 개의 데이터셋을 수집하였습니다.&lt;/p&gt;

&lt;p&gt;쏘카 차량 내부에는 쏘카에서 직접 제작한 관제 장치뿐만 아니라, 고객이 보다 편하고 효율적으로 차량을 운영할 수 있도록 하기 위해 또 다른 장치들이 장착되어 있습니다.
다음 글에서는 운전 편의를 위한 장치에 대해서 소개 드리겠습니다.&lt;/p&gt;</content><author><name>주노</name></author><category term="mobility" /><category term="iot" /><summary type="html">안녕하세요. 쏘카 커넥티드플랫폼 그룹 커넥티드디바이스팀 주노입니다.</summary></entry><entry><title type="html">차량용 단말을 위한 IoT 파이프라인 구축기 (feat. Kafka) #2</title><link href="https://tech.socarcorp.kr/mobility/2022/02/09/socar-iot-pipeline-2.html" rel="alternate" type="text/html" title="차량용 단말을 위한 IoT 파이프라인 구축기 (feat. Kafka) #2" /><published>2022-02-09T01:00:00+00:00</published><updated>2022-02-09T01:00:00+00:00</updated><id>https://tech.socarcorp.kr/mobility/2022/02/09/socar-iot-pipeline-2</id><content type="html" xml:base="https://tech.socarcorp.kr/mobility/2022/02/09/socar-iot-pipeline-2.html">&lt;div class=&quot;photo-copyright&quot;&gt;
Photo by &lt;a href=&quot;https://unsplash.com/@selimarda?utm_source=unsplash&amp;amp;utm_medium=referral&amp;amp;utm_content=creditCopyText&quot;&gt;SELİM ARDA ERYILMAZ&lt;/a&gt; on &lt;a href=&quot;https://unsplash.com/photos/XYeCKHcZNz8?utm_source=unsplash&amp;amp;utm_medium=referral&amp;amp;utm_content=creditCopyText&quot;&gt;Unsplash&lt;/a&gt;
&lt;/div&gt;

&lt;p&gt;안녕하세요. 데이터 엔지니어링 그룹 모비딕 팀의 바다, 올리버입니다.
&lt;a href=&quot;https://tech.socarcorp.kr/mobility/2022/01/06/socar-iot-pipeline-1.html&quot;&gt;차량용 단말을 위한 IoT 파이프라인 구축기 #1&lt;/a&gt;에 이어, 차량에서 수집한 정보를 전사적으로 활용할 수 있도록 어떻게 단말 파이프라인을 설계하고 만들어 가는지에 대해 자세히 이야기하려고 합니다.&lt;/p&gt;

&lt;p&gt;이 글은 다음과 같은 분들에게 도움이 됩니다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;데이터 파이프라인 구축에 관심 있는 개발자&lt;/li&gt;
  &lt;li&gt;차량의 정보 수집과 데이터 흐름에 관심 있는 분&lt;/li&gt;
  &lt;li&gt;AWS IoT Core, MSK(Managed Streaming for Apache Kafka) 솔루션에 관심 있는 개발자&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;목차&quot;&gt;목차&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;#쏘카의-첫-단말-파이프라인을-소개합니다-&quot;&gt;쏘카의 첫 단말 파이프라인을 소개합니다 &lt;a name=&quot;introduce&quot;&gt;&lt;/a&gt;&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#기존-단말-파이프라인&quot;&gt;기존 단말 파이프라인&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#기존-파이프라인의-한계&quot;&gt;기존 파이프라인의 한계&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#한계를-넘기-위한-신규-파이프라인-설계&quot;&gt;한계를 넘기 위한 신규 파이프라인 설계&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#본격적으로-신규-단말-파이프라인을-구축해봅시다-&quot;&gt;본격적으로 신규 단말 파이프라인을 구축해봅시다 &lt;a name=&quot;build&quot;&gt;&lt;/a&gt;&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#kafka-클러스터&quot;&gt;Kafka 클러스터&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#producer&quot;&gt;Producer&lt;/a&gt;
        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#iot-core의-메시지-생성&quot;&gt;IoT Core의 메시지 생성&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#텔레매틱스-서버의-메시지-생성&quot;&gt;텔레매틱스 서버의 메시지 생성&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#consumer&quot;&gt;Consumer&lt;/a&gt;
        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#kafka-connect&quot;&gt;Kafka Connect&lt;/a&gt;
            &lt;ul&gt;
              &lt;li&gt;&lt;a href=&quot;#s3-sink-connector&quot;&gt;S3 Sink Connector&lt;/a&gt;&lt;/li&gt;
              &lt;li&gt;&lt;a href=&quot;#elasticsearch-sink-connector&quot;&gt;Elasticsearch Sink Connector&lt;/a&gt;&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#단말-차량-converter&quot;&gt;단말-차량 Converter&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#단말-파이프라인-모니터링-&quot;&gt;단말 파이프라인 모니터링 &lt;a name=&quot;monitoring&quot;&gt;&lt;/a&gt;&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#마치며-&quot;&gt;마치며 &lt;a name=&quot;wrap-up&quot;&gt;&lt;/a&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;쏘카의-첫-단말-파이프라인을-소개합니다-&quot;&gt;쏘카의 첫 단말 파이프라인을 소개합니다 &lt;a name=&quot;introduce&quot;&gt;&lt;/a&gt;&lt;/h2&gt;

&lt;h3 id=&quot;기존-단말-파이프라인&quot;&gt;기존 단말 파이프라인&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;/img/iot-pipeline-2/pipeline-prev.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;과거에는 차량에서 수집한 정보를 HTTPS 프로토콜을 이용해 쏘카의 텔레매틱스 서버에 전달했습니다. 텔레매틱스 서버에서 단말 데이터를 수집, 가공, 적재하는 작업의 일환으로 파이프라인에 단말 데이터를 투입했습니다. 텔레매틱스 서버는 쏘카 서비스의 원활한 운영과 고객 불편의 최소화를 위해 차량에서 수집한 정보를 최대한 빠른 시간 안에 처리하여야 합니다.&lt;/p&gt;

&lt;p&gt;단말이 차량에서 수집한 정보의 종류에 따라 텔레매틱스 서버의 다른 엔드포인트에 이를 보고합니다. 예를 들어 일반적인 차량 정보의 주기적 보고의 경우 &lt;code class=&quot;highlighter-rouge&quot;&gt;/log&lt;/code&gt; 엔드포인트로, 단말 재부팅시에  대한 보고는 &lt;code class=&quot;highlighter-rouge&quot;&gt;/boot&lt;/code&gt; 엔드포인트로 보고하는 방식입니다.&lt;/p&gt;

&lt;p&gt;차량에서 수집한 정보를 보고받은 텔레매틱스 서버는 이 정보를 서비스 운영을 위해 데이터베이스의 차량 정보 스키마에 맞추어 변환하여 데이터베이스에 적재합니다. 이렇게 변환하는 과정에서 운영에 꼭 필요한 데이터만을 필터링해 적재하기 때문에, 운영에는 충분한 정보를 가지고 있지만 연구와 분석을 위해 사용하기에는 한계가 있습니다.&lt;/p&gt;

&lt;p&gt;따라서 연구, 분석에도 차량에서 수집한 정보를 충분히 활용할 수 있도록 필터링 되지 않은 데이터를 AWS Kinesis에 흘려보냅니다. Kinesis는 실시간으로 데이터 스트림을 수집하고 처리, 분석하는 데에 사용하는 AWS의 솔루션입니다. 당시 Kinesis를 선택했던 이유는 데이터 스트림에 대한 관리와 개발을 최소화하면서도 차량에서 수집한 정보를 필요한 곳에서 최대한으로 활용하고자 했던 선택이었습니다.&lt;/p&gt;

&lt;p&gt;이렇게 Kinesis Stream에 전달된 차량에서 수집한 정보는 Kinesis Firehose를 거쳐 각각 Elasticsearch, S3, BigQuery에 저장하여 활용하고 있었습니다.&lt;/p&gt;

&lt;h3 id=&quot;기존-파이프라인의-한계&quot;&gt;기존 파이프라인의 한계&lt;/h3&gt;
&lt;p&gt;하지만 단순히 ‘수집 정보를 흘려보내기만 하면 되겠다’라고 가볍게 여겼던 Kinesis는 생각보다 많은 관리가 필요했고, Kinesis Stream을 사용하는 프로젝트가 늘어날수록 파이프라인은 점점 복잡해졌습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/iot-pipeline-2/pipeline-bang.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;기본적으로 Elasticsearch와 S3, BigQuery에 적재하는 것 외에도, 전사에서 필요한 용도에 따라 단말 수집 정보가 실시간으로 수집되는 Kinesis Stream에 Consumer를 연결하여 활용할 수 있었습니다. 그러나 이 파이프라인을 관리하는 주체가 없어서 불필요하게 많은 Consumer가 연결되었습니다. &lt;strong&gt;Kinesis 스트림에 많은 Lambda 함수, 많은 Process들이 붙었고 Kinesis Stream에 병목이 생기는 경우가 생겼습니다.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;더 많은 처리량을 위해 샤드(샤드 당 1초에 최대 2MB의 데이터 처리)를 늘려보기도 하고, 향상된 팬아웃 기능을 사용하여 극복할 수 있었지만 이는 비용 증가와 직결되며, 근본적인 해결책도 아니었습니다.&lt;/p&gt;

&lt;h3 id=&quot;한계를-넘기-위한-신규-파이프라인-설계&quot;&gt;한계를 넘기 위한 신규 파이프라인 설계&lt;/h3&gt;
&lt;p&gt;Server-side Application의 업데이트는 보통 즉각적인 효과를 발휘하지만, 사용자의 PC에 설치되는 소프트웨어나 하드웨어의 펌웨어는 상황에 따라 업데이트에 상당한 시간을 필요로 합니다. 쏘카의 단말 펌웨어 업데이트도 항상 쉽지 않은 일입니다.&lt;/p&gt;

&lt;p&gt;차량에 명령을 내리는 명령 채널에 &lt;a href=&quot;https://aws.amazon.com/ko/iot-core&quot;&gt;IoT Core&lt;/a&gt;를 사용하게 되면서, 보고 채널에도 IoT Core로 갈아탈 수 있는 기회가 왔고, 기존 파이프라인의 한계점을 개선할 수 있는 절호의 찬스를 맞이했습니다! 그리하여 발 빠르게 신규 파이프라인 설계에 착수했습니다. 설계하면서 중점을 두었던 주제들은 다음과 같습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;단말 수집 정보를 수집-가공-저장하던 텔레매틱스 서버를 은퇴시키자
    &lt;ul&gt;
      &lt;li&gt;텔레매틱스 서버는 그동안 단말 데이터 처리를 위해 수고해주었지만, 장애가 발생하면 파이프라인의 병목이 되는 원인이기도 했습니다. 이는 파이프라인의 흐름에 치명적일 수 있어 용도를 최소화하거나 은퇴시키고자 했습니다.&lt;/li&gt;
      &lt;li&gt;IoT Core를 사용하면서 프로토콜이 제한적인 HTTP 프로토콜 통신을 걷어내고 대용량의 데이터를 전송하기 적합한 MQTT 프로토콜 통신을 사용할 수 있습니다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;전사에서 Kafka를 사용하는 분위기에 발맞추어, 데이터 스트리밍 플랫폼의 최강자인 Kafka를 사용하자
    &lt;ul&gt;
      &lt;li&gt;모비딕 팀뿐만 아니라 전사에서 Kafka를 도입하고자 하는 준비 과정이 있었고, Kafka에 대한 사내 지식이 쌓여가고 공유하고 있었기 때문에 이 또한 좋은 기회라고 생각했습니다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;하나로 통합되어 있던 토픽을 관심 분류에 따라 여러 토픽으로 나누어 사용하자
    &lt;ul&gt;
      &lt;li&gt;기존 파이프라인에서는 차량에서 수집한 정보를 저장되는 데에 하나의 토픽을 사용하고 있었습니다. 이 때문에 스트림 내의 차량 수집 정보를 특정 프로젝트 내에서 사용하기 위해서는 프로젝트에 불필요한 정보도 일단 모두 읽어야 하는 문제가 있었습니다. 이러한 비효율을 제거하고자, 단말 수집 정보의 토픽을 관심사별로 분리하고자 했습니다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;시스템 부하가 일으키는 장애에 대한 걱정 없이 신규 서비스를 개발하자
    &lt;ul&gt;
      &lt;li&gt;Kinesis 파이프라인에서 Throttling이 지속적으로 발생하면서 Kinesis와 연결하여 사용하려던 신규 서비스를 투입하는 것도 굉장히 부담스러워졌습니다. 이를 극복하면서 신규 서비스 개발에도 데이터 스트림이 걸림돌이 되지 않았으면 했습니다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;MSK를 사용하여, 운영 리소스를 최소화하자
    &lt;ul&gt;
      &lt;li&gt;우리의 리소스를 고려한다면 Kafka 운영을 위한 리소스가 추가 투입되는 것도 부담스러운 요소 중 하나였습니다. AWS에서 완전 관리형 Kafka 서비스인 MSK를 제공하고 있습니다. MSK 덕분에 Kafka를 직접 사용하면서 운영 리소스를 최소화하며 빠르게 요구사항을 충족할 수 있겠다고 생각했습니다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;데이터 파이프라인의 토픽, 파티션 등의 세부 설정을 우리가 직접 하여 상황에 맞게 사용할 수 있도록 하자&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;이런 목표들을 가지고 설계한 파이프라인을 통해 차량에서 수집한 정보를 보고받고, MSK의 토픽에 정보가 담긴 메시지를 전달하며, 각각의 Consumer가 MSK에 붙어 필요한 데이터들을 가져갈 수 있는 기존보다 안정적인 새로운 파이프라인을 구성하기로 했습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/iot-pipeline-2/pipeline-next.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;이제 본격적으로 파이프라인을 구현해볼까요?&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;본격적으로-신규-단말-파이프라인을-구축해봅시다-&quot;&gt;본격적으로 신규 단말 파이프라인을 구축해봅시다 &lt;a name=&quot;build&quot;&gt;&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;쏘카의 신규 단말 파이프라인은 크게 토픽을 관리하며 메시지를 저장하는 Kafka 클러스터와 메시지를 생산하는 Producer, 메시지를 소비하는 Consumer 세 가지로 구성됩니다.&lt;/p&gt;

&lt;h3 id=&quot;kafka-클러스터&quot;&gt;Kafka 클러스터&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/img/iot-pipeline-2/create-msk-cluster.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Kafka 클러스터는 AWS MSK를 통해 쉽게 구축할 수 있었습니다. 사용하고자 하는 인스턴스와 브로커 당 용량 및 Kafka의 버전, 보안 설정만 거치면 쉽게 클러스터를 구축할 수 있습니다.&lt;/p&gt;

&lt;p&gt;주의할 점은 생성 후 클러스터의 설정 변경에 제약이 있다는 점입니다. 예를 들어 인스턴스의 타입은 자유롭게 Up &amp;amp; Down이 가능하나, 브로커의 수량과 브로커의 용량은 증설만 가능합니다. (이 부분을 놓쳐 초기에 클러스터를 여러 번 새로 만드는 고생하기도 했습니다)&lt;/p&gt;

&lt;p&gt;스토리지의 경우 그동안 기존 파이프라인을 운영했던 데이터에 기반하여 최대 피크 수준도 버틸 수 있도록 설정했습니다. 이를 넘어서서 스토리지가 꽉 차게 되면 메시지가 유실되는 문제가 발생합니다. 이런 문제를 겪지 않도록 MSK에서는 스토리지 오토스케일링 기능을 제공합니다. 전체 용량의 10~80%에 도달하면 Auto Scaling이 되도록 설정이 가능합니다. 다만 안타깝게도 오토 스케일링도 스케일링 업만 가능하며 다운은 불가능하다는 점 유의하셔야 합니다.&lt;/p&gt;

&lt;p&gt;마지막으로 Cluster Configuration을 통해 Kafka 클러스터 설정을 할 수 있습니다. Kafka는 스트리밍 데이터 처리 플랫폼으로 데이터를 영구 저장할 수도 있지만 보통은 메시지의 저장 기간을 정해놓고 사용합니다. 장애가 발생해도 2일 이내에 해결하겠다는 마음으로 48시간(2일)로 설정했습니다. 이외 자세한 설정값들은 &lt;a href=&quot;https://kafka.apache.org/documentation/&quot;&gt;Kafka 문서&lt;/a&gt;를 참고해주세요.&lt;/p&gt;

&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;s&quot;&gt;log.cleanup.policy&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;delete&lt;/span&gt;
&lt;span class=&quot;s&quot;&gt;log.retention.hours&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;48&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;이렇게 기본적인 클러스터 설정이 끝나면 수분 내에 Kafka 클러스터가 생성됩니다. 이제 메시지를 위한 토픽을 만들어주어야겠죠. 로컬 머신에 MSK와 같은 버전(권장)의 Kafka를 다운로드하시면 기본적으로 제공하는 CLI를 이용하여 토픽을 생성할 수 있습니다. (또는 원하는 언어의 Kafka 클라이언트를 통해서도 생성할 수 있어요!)&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;/bin/kafka-topics.sh --create \
    --zookeeper &amp;lt;주키퍼 호스트&amp;gt;:&amp;lt;주키퍼 포트&amp;gt; \
    --topic &amp;lt;토픽 이름&amp;gt; \
    --partitions &amp;lt;파티션 수&amp;gt; \
    --replication-factor &amp;lt;복제 팩터&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;참고로 &lt;code class=&quot;highlighter-rouge&quot;&gt;auto.create.topics.enable&lt;/code&gt; 설정을 켜두면 자동으로 토픽을 생성하게 할 수 있습니다. 저희는 무분별하게 토픽이 생성되는 것을 막고자 이 방식은 사용하지 않았습니다.&lt;/p&gt;

&lt;p&gt;토픽 생성 시에는 토픽 이름, 파티션의 개수, 복제 팩터를 설정하게 됩니다.&lt;/p&gt;

&lt;p&gt;Kafka는 토픽에 메시지를 저장할 때 파일 시스템을 사용하기 때문에, 파티션을 하나로 지정하면 브로커의 I/O에 따라 성능이 좌지우지됩니다. 따라서 클러스터의 브로커 수, 데이터의 크기, Consumer의 수 같은 요소를 적절하게 고려하여 파티션의 수량을 정해야 합니다.&lt;/p&gt;

&lt;p&gt;복제 팩터는 중요한 설정 중 하나로, 하나의 파티션이 몇 개까지 복제될지를 설정하는 수치입니다. MSK는 중요 보안 업데이트나 설정 변경 시에 브로커를 한 대씩 차례차례 재부팅합니다. 이때 복제 팩터가 1인 경우 해당 파티션이 있는 브로커가 업데이트 등으로 인해 잠시 OFF되어 있을 때 Producer가 해당 파티션에 데이터를 쓰려고 하면 데이터 유실이 발생할 수 있습니다. 이러한 문제 없이 운영하기 위해서는 복제 팩터를 최소 2 이상으로 설정해 주셔야 합니다. 2 이상으로 설정한 경우, 기존 파티션 Leader를 가지고 있던 브로커가 OFF 되어도 복제본을 갖고 있던 다른 브로커가 파티션 Leader를 넘겨받아 Kafka 클러스터가 다운타임 없이 정상적으로 역할을 수행해냅니다.&lt;/p&gt;

&lt;h3 id=&quot;producer&quot;&gt;Producer&lt;/h3&gt;
&lt;p&gt;Kafka 클러스터가 준비되었으니, 메시지를 생산할 Producer를 설정해 보겠습니다. 엄밀히 말하면 단말에서 차량 정보를 수집하여 전달하는 부분을 Producer라고 볼 수도 있겠지만, 여기서는 Kafka 클러스터를 기준으로 하여, Kafka에 메시지를 생성하는 부분을 Producer의 역할로 정의하겠습니다.&lt;/p&gt;

&lt;p&gt;위에서 말씀드린 것처럼, &lt;strong&gt;단말의 펌웨어는 Server-side Application처럼 어느 시점에 한 번에 업데이트하기 어렵습니다&lt;/strong&gt;. 빨라도 몇 주에서 오래 걸리면 몇 달은 길게 두고 보아야 하는 작업입니다. 이렇게 짧지 않은 기간동안 보고 채널이 파편화되어 있는 동안에도 파이프라인에는 펌웨어 구분 없이 모든 차량에서 수집한 정보가 적재되어야 했습니다. 그렇게 하기 위해 IoT Core의 메시지 생성과 텔레매틱스 서버의 메시지 생성을 모두 구현하게 되었습니다.&lt;/p&gt;

&lt;h4 id=&quot;iot-core의-메시지-생성&quot;&gt;IoT Core의 메시지 생성&lt;/h4&gt;
&lt;p&gt;먼저 신규 펌웨어에서 IoT Core로 차량에서 수집한 정보를 전달하는 경우를 살펴보겠습니다. 단말에서는 차량 정보를 수집하여 IoT Core의 특정 토픽에 보고합니다. 그리고 IoT Core Rule을 만들어 이 정보를 구독할 수 있습니다. 예를 들어 단말은 &lt;code class=&quot;highlighter-rouge&quot;&gt;report&lt;/code&gt;라는 토픽에 차량 정보를 보고하고, IoT Core Rule에 &lt;code class=&quot;highlighter-rouge&quot;&gt;report&lt;/code&gt; 토픽을 구독하도록 Rule을 생성했다면, 새로운 차량 정보 메시지가 보고될 때마다 Rule에 설정된 작업이 실행됩니다.&lt;/p&gt;

&lt;p&gt;IoT Core Rule에 대해 자세히 알아볼까요? IoT Core Rule은 익숙한 SQL 쿼리(정확히는 AWS IoT Core SQL)를 통해 입맛에 맞게 단말에서 보고한 데이터를 가공할 수 있으며, 다른 데이터 시스템으로 전달하는 역할을 수행합니다. 신규 단말 파이프라인에서는 단말에서 JSON 형식의 메시지를 전달받고, 여기에 SQL을 이용하여 Timestamp를 추가해 사용합니다. 이를 위해 다음과 같은 쿼리문을 사용합니다.&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parse_time&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;&quot;yyyy-MM-dd'T'HH:mm:ssz&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;timestamp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;timestamp&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'report'&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;AWS IoT Core SQL에서 지원하는 SQL 구문은 일반적인 SQL 구문과 비슷하지만 다를 수 있으니, 자세한 내용은 AWS에서 제공하는 &lt;a href=&quot;https://docs.aws.amazon.com/iot/latest/developerguide/iot-sql-reference.html&quot;&gt;AWS IoT Core SQL 레퍼런스&lt;/a&gt;를 참고하시기 바랍니다. IoT Core SQL의 특별한 점을 꼽자면, 무려 Lambda 함수를 실행할 수 있는 Function까지 지원해 원하는 대로 데이터 가공이 가능합니다.&lt;/p&gt;

&lt;p&gt;이렇게 원하는 대로 가공을 마쳤다면, 이 데이터를 다른 데이터 시스템으로 전달하기 위해 여러 개의 작업을 설정할 수 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/iot-pipeline-2/worker-list.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;작업에는 미리 정의된 약 20개의 템플릿이 있으며, HTTPS 엔드포인트로도 전송할 수 있는 작업까지 준비되어 있어 원하는 대로 커스텀이 가능합니다. 이제 Kafka에 메시지를 전송할 수 있도록 작업을 추가해 보겠습니다.&lt;/p&gt;

&lt;p&gt;Apache Kafka 클러스터에 메시지 전송을 선택한 후 구성을 누르면, Kafka의 구성 정보를 입력하여 세팅할 수 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/iot-pipeline-2/create-kafka-sink-worker.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;먼저 기본적인 Kafka 정보(Kafka 엔드포인트, SASL 구성 등)를 설정해 주세요.
Kafka에서 어떤 토픽에 메시지를 저장할 것인지 토픽 이름을 지정해야 합니다. 저희는 여기서 하나의 토픽에만 메시지를 전달하는 것이 아니라, 차량에서 수집된 정보의 종류에 따라 다른 토픽에 메시지를 전달하고 싶었습니다. 이런 처리를 위해서는 &lt;a href=&quot;https://docs.aws.amazon.com/ko_kr/iot/latest/developerguide/iot-substitution-templates.html&quot;&gt;대체 템플릿&lt;/a&gt;을 사용할 수 있습니다.&lt;/p&gt;

&lt;p&gt;대체 템플릿은 치환자라고 생각하시면 됩니다. IoT SQL 레퍼런스에서 지원하는 SELECT 절, WHERE 절 또는 Function을 사용할 수 있습니다. 쏘카 단말에서 보고하는 정보 중에는 해당 정보의 종류를 나타내는 타입이 존재합니다. 이 타입 별로 토픽을 분리하기 위해, 토픽 이름을 &lt;code class=&quot;highlighter-rouge&quot;&gt;message-${type}&lt;/code&gt; 으로 지정하였습니다. 이렇게 설정하면 log 타입의 메시지는 &lt;code class=&quot;highlighter-rouge&quot;&gt;message-log&lt;/code&gt;에, boot 타입의 메시지는 &lt;code class=&quot;highlighter-rouge&quot;&gt;message-boot&lt;/code&gt;에 저장하게 됩니다. 토픽이 자동 생성되는 옵션을 켜지 않으신 경우 꼭 미리 각 type에 대한 토픽을 먼저 생성하셔야 한다는 점 잊지 말아 주세요!&lt;/p&gt;

&lt;p&gt;다음은 파티션 설정입니다. 파티션은 파티션 번호를 직접 지정할 수도 있고, 지정하지 않으면 Kafka의 &lt;code class=&quot;highlighter-rouge&quot;&gt;DefaultPartitioner&lt;/code&gt;에 따라 파티션이 선택되어 메시지가 분배되게 됩니다. 여기에서 카프카의 중요한 특징을 하나 알고 가셔야 하는데, 파티션이 2개 이상인 토픽 내 메시지는 시간 순서가 지켜지지 않는다는 점입니다. 다만 파티션 내에서는 시간 순서가 지켜집니다. 쏘카에서는 각각의 프로젝트에서 실시간으로 데이터를 사용하게 될 때, 최소한 단말기 별로라도 메시지의 시간 순서가 꼭 지켜져야 합니다. 같은 단말의 메시지들이 다른 파티션에 저장되어 시간 순서대로 메시지를 사용할 수 없다면 실시간 처리가 사실상 불가능하게 됩니다. 대체 템플릿을 이용하여 메시지의 Key를 단말 번호인 &lt;code class=&quot;highlighter-rouge&quot;&gt;${device_no}&lt;/code&gt;로 지정하여 같은 단말의 메시지는 같은 파티션에 생성될 수 있도록 설정하여 이와 같은 문제를 해결할 수 있었습니다.&lt;/p&gt;

&lt;p&gt;(참고로, Kafka의 &lt;code class=&quot;highlighter-rouge&quot;&gt;DefaultPartitioner&lt;/code&gt;는 Key 값이 Null인 경우 해당 토픽의 파티션에 Round Robin 방식으로 분배하며, Key 값이 Null이 아닌 경우 Key 값을 해시화하여 파티션을 선택해 분배합니다)&lt;/p&gt;

&lt;p&gt;이렇게 메시지를 IoT Core에서 Kafka 토픽으로 무사히 전달했습니다!&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/iot-pipeline-2/pipeline-next-msk.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;텔레매틱스-서버의-메시지-생성&quot;&gt;텔레매틱스 서버의 메시지 생성&lt;/h4&gt;
&lt;p&gt;기존에 차량과 통신할 때에는 총 두 채널로 통신했습니다. 명령 전달은 MQTT로 하고, 명령에 대한 응답 보고 혹은 상태 보고들을 텔레매틱스 서버로 HTTPS 방식의 보고를 하고 있었습니다. 이때, 신규 STS 단말기의 데이터 형태와 구형 단말기(CSA 단말기)의 형태가 달라 데이터를 호환시켜주는 모듈을 거쳐 동일하게 데이터가 쏘카 데이터베이스에 적재될 수 있도록 하는 일련의 과정들을 거칩니다.&lt;/p&gt;

&lt;p&gt;텔레매틱스 서버가 AWS IoT Core로 전환이 된다면, HTTPS로 텔레매틱스 서버에 상태 데이터를 전달하고 쏘카 데이터베이스에 적재되는 일련의 과정들이 생략됩니다. 기존의 연구나 분석에 사용하고 있던 데이터의 형태가 달라질 수 있기 때문에 기존에 보내고 있는 데이터의 형태와 호환성을 잘 가져갈 수 있도록 하는 것을 우선적인 목표로 잡았습니다.&lt;/p&gt;

&lt;p&gt;첫 번째로, 텔레매틱스 서버로 차량이 상태를 보고 하게 되면, 차량의 정보와 상태가 담긴 데이터가 Kinesis와 Kafka로 동시에 보내도록 작업을 했습니다. Kafka는 데이터를 전송할 때 여러 개의 토픽으로 나누어 데이터를 전송할 수 있습니다. 그 기능을 활용해 차량에서 올라오는 데이터들을 GPS, Kinematic, ADAS와 차량 주기 보고 데이터 등 각각 다른 토픽에 전송했습니다. 이로써 차량 데이터가 쏘카 데이터베이스에 저장됨은 물론, 프로젝트별로 데이터를 가져갈 때 실시간 데이터를 원하는 정보만, 원하는 토픽만을 가져와서 쉽게 처리할 수 있게 되었습니다.&lt;/p&gt;

&lt;p&gt;Kafka로 데이터를 보내기 위해 작업하는 도중, 서버 앞단의 트래픽을 보조하기 위해 사용한 uWSGI 모듈과 Python에서 Kafka를 사용할 수 있게 해 주는 kafka-python 모듈 간에 서로 충돌이 생겨서 첫 테스트에는 많은 어려움을 겪었습니다. 결국 uWSGI을 gunicorn으로 대체하고, Kafka 라이브러리도 kafka-python 대신 AWS가 제공하는 라이브러리인 boto3로 대체했습니다.&lt;/p&gt;

&lt;p&gt;두 번째로, IoT Core에서 전송된 데이터를 판별하여 데이터베이스에 적재할 수 있도록 고민이 필요했습니다. 단말기가 IoT Core로 보고하고 데이터가 바로 Kafka로 전송이 된다면, 데이터베이스에 데이터를 저장해 주는 역할을 하는 텔레매틱스 서버를 거치지 않기 때문에 차량 정보에 대해 저장이 어렵게 됩니다. 이를 위해 AWS IoT Core에 Rule을 추가해 주어 IoT Core의 데이터가 바로 Kafka로 전송되지 않고, 텔레매틱스 서버를 한번 거쳐서 Kafka로 전송할 수 있도록 해주었습니다. 텔레매틱스 서버에서 IoT Core에 대한 새로운 엔드포인트를 만들고, 해당하는 엔드포인트에서 데이터를 받아온 후 판별하여 Kafka 토픽별로 전송했습니다.&lt;/p&gt;

&lt;p&gt;IoT Core를 도입하면서 텔레매틱스 서버의 역할을 점차 줄여나가고, 결국에는 텔레매틱스 서버의 역할을 Kakfa와 연결된 Consumer 들에서 처리할 수 있도록 기능들을 점차 옮기려고 합니다. 현재는 여러 차량들을 놓고 테스트해 보고 있습니다. IoT Core를 적용 한 차량이 기존 차량과 동일하게 큰 어려움 없이 차량 데이터를 보내주고 있습니다. 아직은 초기지만, 많은 차량들이 점차 업데이트가 되어서 IoT Core로 데이터를 보낼 수 있게 되는 날이 벌써 기대가 됩니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/iot-pipeline-2/pipeline-prev-msk.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;consumer&quot;&gt;Consumer&lt;/h3&gt;
&lt;p&gt;이제 수집된 차량 정보가 Kafka 토픽에 안전하게 저장되어 있습니다. 이 데이터를 적재적소에 가져다가 활용하면 됩니다.
하지만 카프카는 영구 저장소가 아니라서, 우리가 설정한 값에 따르면 2일 후에 사라지게 됩니다. 먼저 이를 더 오랫동안 보관하고 활용할 수 있는 공간으로 먼저 저장해야 합니다. 이런 툴을 일일이 개발해야 할까요?&lt;/p&gt;

&lt;h4 id=&quot;kafka-connect&quot;&gt;Kafka Connect&lt;/h4&gt;
&lt;p&gt;물론 자신 있는 언어의 Kafka 클라이언트를 이용하여 Consumer를 한 땀 한 땀 개발할 수도 있겠지만, Kafka 생태계에서는 Kafka와 다른 데이터 시스템 사이를 쉽고 믿을 수 있게 이어줄 수 있는 Kafka Connect를 제공합니다.&lt;/p&gt;

&lt;p&gt;많은 회사와 개발자들이 사용하는 RDBMS부터 NoSQL, S3 같은 클라우드 저장소, Elasticsearch 등 수많은 데이터 시스템과 카프카를 이어주는 Connector를 공식적으로 제공하고 있으며, 커뮤니티에서 만든 비공식의 Connector들도 활발하게 만들어져 있어 Kafka Connect 클러스터만 구축한다면 Connector들을 바로 사용할 수 있습니다.&lt;/p&gt;

&lt;p&gt;다른 데이터 시스템에서 Kafka로 데이터를 가져오는 커넥터를 Source Connector라 하고, Kafka에서 다른 데이터 시스템으로 데이터를 적재하는 커넥터를 Sink Connector라고 합니다. 우리는 Kafka에 있는 데이터를 소비하는 Consumer를 만드는 과정이므로 Sink Connector를 설정해보겠습니다.&lt;/p&gt;

&lt;p&gt;쏘카의 단말 데이터는 오래 저장하고 다시 여러 가지 용도로 사용할 수 있도록 1차적으로 S3에 저장하고 있으며, 최신 데이터는 바로 분석과 연구에 사용할 수 있도록 Elasticsearch에 적재해 활용하고 있습니다.&lt;/p&gt;

&lt;p&gt;Kafka Connect 클러스터는 구축되어 있다고 가정하고, 바로 Sink Connector를 설정해보겠습니다. Kafka Connect에서는 Connector를 실행시킬 수 있는 REST API를 제공합니다. S3와 Elasticsearch Sink Connector를 세팅하면서 자세히 알아보도록 하겠습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/iot-pipeline-2/pipeline-next-kafkaconnect.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h5 id=&quot;s3-sink-connector&quot;&gt;S3 Sink Connector&lt;/h5&gt;
&lt;p&gt;Confluent에서 공식으로 제공하는 S3 Sink Connector입니다.
다음 요청을 통해 해당 커넥터를 이용한 Worker를 생성할 수 있습니다.&lt;/p&gt;

&lt;p&gt;Endpoint : &lt;code class=&quot;highlighter-rouge&quot;&gt;POST ${카프카_커넥트_호스트}/connectors&lt;/code&gt;&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;{
    &quot;name&quot;:&quot;s3-sink-worker&quot;,
    &quot;config&quot;: {
        // 사용하려는 커넥터의 클래스 이름
        &quot;connector.class&quot;: &quot;io.confluent.connect.s3.S3SinkConnector&quot;,

        // S3가 위치한 리전
        &quot;s3.region&quot;: &quot;ap-northeast-2&quot;,

        &quot;partition.duration.ms&quot;: &quot;180000&quot;,
        
        // 여기서 지정한 수만큼 메시지가 쌓이면 S3에 파일로 저장합니다.
        &quot;flush.size&quot;: &quot;20000&quot;,
        
        &quot;schema.compatibility&quot;: &quot;NONE&quot;,
        
        // 메시지를 가져오려는 카프카의 토픽 이름을 지정합니다. 콤마를 사용해 여러 토픽을 가져올 수 있습니다.
        &quot;topics&quot;: &quot;토픽 이름&quot;,
        
        // 하나의 파일이 가질 최대 용량을 지정합니다.
        &quot;s3.part.size&quot;: &quot;5242880&quot;,
        
        // 타임존을 지정합니다.
        &quot;timezone&quot;: &quot;Asia/Seoul&quot;,
        
        // 로케일을 지정합니다.
        &quot;locale&quot;: &quot;ko_KR&quot;,
        
        // 압축 방식을 지정합니다. none 또는 gzip을 사용할 수 있습니다.
        &quot;s3.compression.type&quot;: &quot;gzip&quot;,
        
        // 데이터 포맷을 지정힙니다. JSON 타입이므로 JsonFormat을 사용합니다.
        &quot;format.class&quot;: &quot;io.confluent.connect.s3.format.json.JsonFormat&quot;,
        
        // 메시지를 어떻게 파티셔닝할지 설정합니다. 여기서는 TimeBasedPartitioner를 사용하여 날짜 기준으로 S3에 저장되는 폴더를 분리합니다.
        &quot;partitioner.class&quot;: &quot;io.confluent.connect.storage.partitioner.TimeBasedPartitioner&quot;,
        
        // S3Storage로 지정해주시면 됩니다.
        &quot;storage.class&quot;: &quot;io.confluent.connect.s3.storage.S3Storage&quot;,
        
        // 저장될 S3의 버킷 이름입니다.
        &quot;s3.bucket.name&quot;: &quot;S3 버킷 이름&quot;,
        
        // 얼마나 주기적으로 S3에 파일을 저장할지 설정합니다. flush.size에서 설정한 메시지 수에 도달하지 않아도 해당 주기가 되면 S3에 파일을 쓰게 됩니다.
        &quot;rotate.schedule.interval.ms&quot;: &quot;180000&quot;,
        
        // 파일이 저장될 위치를 설정합니다. 시간 기반의 파티셔닝을 통해 시간별로 폴더가 나눠지도록 설정했습니다.
        &quot;path.format&quot;: &quot;YYYY/MM/dd/HH&quot;
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Worker를 생성한 후, 다음 REST API를 통해 Worker가 제대로 동작하는지 확인하실 수 있습니다.&lt;/p&gt;

&lt;p&gt;Endpoint : &lt;code class=&quot;highlighter-rouge&quot;&gt;${카프카_커넥트_호스트}/connectors?expand=info&amp;amp;expand=status&lt;/code&gt;&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;{
  &quot;s3-sink-worker&quot;: {
    &quot;status&quot;: {
      &quot;name&quot;: &quot;s3-sink-worker&quot;,
      &quot;connector&quot;: {
        &quot;state&quot;: &quot;RUNNING&quot;,
        &quot;worker_id&quot;: &quot;Worker 1&quot;
      },
      &quot;tasks&quot;: [
        {
          &quot;id&quot;: 0,
          &quot;state&quot;: &quot;RUNNING&quot;,
          &quot;worker_id&quot;: &quot;Worker 1&quot;
        },
        {
          &quot;id&quot;: 1,
          &quot;state&quot;: &quot;RUNNING&quot;,
          &quot;worker_id&quot;: &quot;Worker 2&quot;
        },
        {
          &quot;id&quot;: 2,
          &quot;state&quot;: &quot;RUNNING&quot;,
          &quot;worker_id&quot;: &quot;Worker 3&quot;
        }
      ],
      &quot;type&quot;: &quot;sink&quot;
    },
    &quot;info&quot;: {
      &quot;name&quot;: &quot;s3-sink-worker&quot;,
      &quot;config&quot;: {
        &quot;connector.class&quot;: &quot;io.confluent.connect.s3.S3SinkConnector&quot;,
        &quot;s3.region&quot;: &quot;ap-northeast-2&quot;,
        &quot;partition.duration.ms&quot;: &quot;180000&quot;,
        &quot;flush.size&quot;: &quot;20000&quot;,
        &quot;schema.compatibility&quot;: &quot;NONE&quot;,
        &quot;topics&quot;: &quot;토픽 이름&quot;,
        &quot;s3.part.size&quot;: &quot;5242880&quot;,
        &quot;timezone&quot;: &quot;Asia/Seoul&quot;,
        &quot;locale&quot;: &quot;ko_KR&quot;,
        &quot;s3.compression.type&quot;: &quot;gzip&quot;,
        &quot;format.class&quot;: &quot;io.confluent.connect.s3.format.json.JsonFormat&quot;,
        &quot;partitioner.class&quot;: &quot;io.confluent.connect.storage.partitioner.TimeBasedPartitioner&quot;,
        &quot;storage.class&quot;: &quot;io.confluent.connect.s3.storage.S3Storage&quot;,
        &quot;s3.bucket.name&quot;: &quot;S3 버킷 이름&quot;,
        &quot;rotate.schedule.interval.ms&quot;: &quot;180000&quot;,
        &quot;path.format&quot;: &quot;YYYY/MM/dd/HH&quot;
      },
      &quot;tasks&quot;: [
        {
          &quot;connector&quot;: &quot;s3-sink-worker&quot;,
          &quot;task&quot;: 0
        },
        {
          &quot;connector&quot;: &quot;s3-sink-worker&quot;,
          &quot;task&quot;: 1
        },
        {
          &quot;connector&quot;: &quot;s3-sink-worker&quot;,
          &quot;task&quot;: 2
        }
      ],
      &quot;type&quot;: &quot;sink&quot;
    }
  },
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;다른 문제가 없다면 수 분 내로 S3의 파일로 메시지가 잘 적재되는 모습을 확인하실 수 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/iot-pipeline-2/result-s3.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Kafka Connect의 Worker들은 동작하면서 필요한 메타데이터를 Kafka에 별도의 토픽으로 저장합니다. Worker는 자신의 업무 프로세스를 기억하기 위해 순차적으로 토픽의 파티션에서 데이터를 읽어가면서 책갈피를 꽂아둡니다. 이 책갈피를 Offset이라고 합니다. Kafka Connect는 프로세스가 죽어서 Worker가 재시작되는 상황이 발생해도 이 메타데이터를 다시 읽어와 책갈피를 꽂은 부분에서부터 다시 데이터를 읽어가도록 설계되어 있습니다.&lt;/p&gt;

&lt;h5 id=&quot;elasticsearch-sink-connector&quot;&gt;Elasticsearch Sink Connector&lt;/h5&gt;
&lt;p&gt;S3에 무사히 적재했다면, 다음은 분석과 연구를 위한 Elasticsearch에 적재해보겠습니다. Confluent에서 공식으로 제공하는 Elasticsearch Sink Connector를 사용합니다. S3 Sink Connector와 같은 방식으로 생성하는데, 다음과 같은 요청을 통해 Elasticsearch Sink Worker를 실행할 수 있습니다.&lt;/p&gt;

&lt;p&gt;Endpoint : &lt;code class=&quot;highlighter-rouge&quot;&gt;POST ${카프카_커넥트_호스트}/connectors&lt;/code&gt;&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;{
  &quot;name&quot;:&quot;es-sink-worker&quot;,
  &quot;config&quot;: {
    // 사용하려는 커넥터의 클래스 이름
    &quot;connector.class&quot;: &quot;io.confluent.connect.elasticsearch.ElasticsearchSinkConnector&quot;,
    
    // Elasticsearch7부터는 type이 사라져, _doc로 지정하면 됩니다.
    &quot;type.name&quot;: &quot;_doc&quot;,
    
    &quot;behavior.on.null.values&quot;: &quot;IGNORE&quot;,
    
    // 메시지를 가져오려는 토픽 이름
    &quot;topics&quot;: &quot;토픽 이름&quot;,
    
    // true일 때, 메시지에 문제가 있는 경우 무시합니다.
    &quot;drop.invalid.message&quot;: &quot;true&quot;,
    
    // 문제가 생긴 경우 최대 재시도 횟수를 설정합니다.
    &quot;max.retries&quot;: &quot;50&quot;,
    
    // true일 때, Elasticsearch 문서의 키로 메시지의 key를 사용하지 않고, topic+partition+offset를 사용합니다. ex) message-log+0+1
    &quot;key.ignore&quot;: &quot;true&quot;,
    
    // Elasticsearch 동시 요청 수를 제한합니다. retry.backoff.ms: 요청 실패 후 재시도까지 기다릴 시간을 설정합니다. 다음 재시도할 때엔 이전 재시도 대기 시간보다 2배 더 기다립니다.
    &quot;max.in.flight.requests&quot;: &quot;20&quot;,
    
    &quot;retry.backoff.ms&quot;: &quot;2000&quot;,
    
    // 사용하려는 Elasticsearch의 Endpoint
    &quot;connection.url&quot;: &quot;ELASTICSEARCH_ENDPOINT&quot;,
    
    // Elasticsearch 서버와의 Read Timeout을 설정합니다.
    &quot;read.timeout.ms&quot;: &quot;60000&quot;,
    
    // 주어진 시간만큼 데이터가 쌓이기를 기다린 다음, Bulk Request로 처리하여 효율성을 높입니다. connection.compression: Elasticsearch 서버와 통신 시에 gzip 압축을 사용할지 여부를 선택합니다.
    &quot;linger.ms&quot;: &quot;1000&quot;,
    &quot;connection.compression&quot;: &quot;true&quot;,
    
    // 메시지가 원하는 만큼 쌓이지 않았더라도, 해당 주기가 되면 Elasticsearch로 메시지를 전송합니다.
    &quot;flush.timeout.ms&quot;: &quot;60000&quot;,
    
    // 배치로 처리할 메시지의 수
    &quot;batch.size&quot;: &quot;2000&quot;,
    
    // 최대 버퍼 될 레코드의 수, 태스크 당 메모리 사용량 제한을 위해 사용합니다.
    &quot;max.buffered.records&quot;: &quot;40000&quot;
  }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;S3 커넥터 설정할 때와 마찬가지로 REST API를 통해 Worker가 정상적으로 동작하고 있는지를 확인해 주세요. 잠시만 기다리면 Elasticsearch에도 메시지가 잘 적재되는 것을 확인하실 수 있습니다!&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/iot-pipeline-2/result-es.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Elasticsearch Sink Connector에는 알려진 버그가 있습니다. 쏘카에서는 최신의 단말 데이터만 Elasticsearch에서 활용하고 있어서 일자별로 인덱스를 생성하고, 며칠 뒤 오래된 인덱스를 삭제하는 형식을 취하고 있습니다. Elasticsearch Sink Connector는 &lt;code class=&quot;highlighter-rouge&quot;&gt;TimebasedPartitioner&lt;/code&gt;를 사용하면 Offset을 제대로 기록하지 못해 설정을 변경하는 등의 이유로 Worker를 재시작할 때마다 토픽에 있는 모든 데이터를 처음부터 다시 읽는 버그가 있습니다.&lt;/p&gt;

&lt;p&gt;이를 해결하기 위해, Elasticsearch Sink Connector를 사용할 때에는 &lt;code class=&quot;highlighter-rouge&quot;&gt;TimeBasedPartitioner&lt;/code&gt;를 사용하지 않고 Elasticsearch의 Index를 고정하여 사용하기로 했습니다. Elasticsearch에서 Index를 생성할 때 Write Index와 Rollover를 사용하여 Index가 일자별로 자동으로 생성되도록 데이터가 저장되도록 설정해 이 문제를 해결할 수 있었습니다.&lt;/p&gt;

&lt;h3 id=&quot;단말-차량-converter&quot;&gt;단말-차량 Converter&lt;/h3&gt;
&lt;p&gt;“단말-차량 Converter”는 모비딕 팀에서 최근에 시작한 프로젝트로, Kafka의 도입과 비슷한 시기에 시작한 프로젝트입니다. Kafka에서 수집하는 차량의 데이터는 거의 실시간으로 파악할 수 있기 때문에 이 데이터의 활용도가 무척 높을 거라고 생각했습니다.&lt;/p&gt;

&lt;p&gt;차량 데이터는 차량 단말기 번호를 기준으로 수집되는데, “단말-차량 Converter”는 이 데이터를 바로 사용할 수 있도록, 데이터를 변형하여 Kafka로 다시 흘려보내주는 역할을 합니다. 즉, “단말-차량 Converter”는 확장성이 높은 첫 Consumer이자 동시에 데이터를 제공해 주는 Producer 역할을 동시에 하게 됩니다. 이렇게 수집된 데이터는 원하는 곳에서, 필요한 만큼 실시간으로 확인할 수 있습니다.&lt;/p&gt;

&lt;p&gt;“단말-차량 Converter”의 기능을 구체적으로 말씀드리면, 단말기에서 올라온 정보를 기반으로 차량 정보를 매칭해 주고, 해당하는 데이터가 어떤 차량의 어떤 상태인지 파악할 수 있도록 데이터 조립을 해 줍니다. 차량의 정보를 데이터베이스에서 계속 가져온다면 너무 비효율적이기 때문에, 임시로 저장해 놓은 캐싱 된 데이터를 사용하고, 일정 주기로 데이터를 새로 받아오는 일들을 하고 있습니다.&lt;/p&gt;

&lt;p&gt;이렇게 조립한 데이터들이 앞으로 필요한 프로젝트들에 잘 활용될거라 기대하고 있습니다. 또한 어떤 프로젝트든 쉽게 데이터를 사용할 수 있게 데이터를 좀 더 유연하게 설계해나가고 싶습니다. 
추가적으로 필요한 연산 작업이라든지, 적재 작업들도 “단말-차량 Converter”를 통해 만들어나갈 수 있을 것 같고, 최근 뜨고 있는 스트림 처리 프레임워크인 Flink를 써 볼 수 있지 않을까 하는 기대감도 가지고 있습니다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;단말-파이프라인-모니터링-&quot;&gt;단말 파이프라인 모니터링 &lt;a name=&quot;monitoring&quot;&gt;&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;구축한 단말 파이프라인이 문제 없이 원활히 흘러가도록 하려면 모니터링의 역할도 아주 중요합니다.&lt;/p&gt;

&lt;p&gt;쏘카에는 여러 모니터링 시스템이 구축되어 있는데, 그중 Grafana를 통해 단말 파이프라인 모니터링 대시보드를 구축했습니다. 데이터 소스로 CloudWatch가 이미 연동되어 있어, MSK의 중요한 메트릭으로 대시보드를 꾸리기만 하면 완성입니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/iot-pipeline-2/monitoring.png&quot; alt=&quot;&quot; /&gt;
&lt;em&gt;운영 중인 Grafana 대시보드&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;CPU, Disk 사용량, 네트워크 In/Out, Elasticsearch의 스토리지 사용량을 기본적으로 모니터링하고 있으며, 각 Consumer의 OffsetLag까지 추가적으로 모니터링하여 각 Consumer에서 데이터를 가져가는 데에 지연이 발생하지 않는지를 모니터링하고 있습니다.&lt;/p&gt;

&lt;p&gt;OffsetLag가 무엇일까요? 각 Consumer에서는 토픽의 파티션 별로 메시지를 어디까지 가져갔는지를 기록하는 책갈피를 남겨놓는다고 했는데, 바로 Offset입니다. 파티션의 가장 마지막 메시지와 Offset의 차이가 OffsetLag입니다. OffsetLag가 줄어들지 않고 지속적으로 증가하는 경우 해당 Consumer가 제대로 동작하지 않는다고 판단할 수 있고, 이를 통하여 Consumer의 장애를 인지하고 장애에 대한 조치를 수행할 수 있습니다.&lt;/p&gt;

&lt;p&gt;(참고로 OffsetLag는 MSK의 고급 모니터링 옵션을 사용해야 모니터링이 가능합니다.)&lt;/p&gt;

&lt;p&gt;이렇게 단말 데이터 파이프라인을 모니터링할 수 있는 대시보드가 완성되었습니다! 필요한 메트릭에 알림을 만들어, 임계치에 도달한 경우 Slack 또는 Opsgenie를 통해 알림을 받아 장애를 인지하고, 조치하고 있습니다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;마치며-&quot;&gt;마치며 &lt;a name=&quot;wrap-up&quot;&gt;&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;여전히 신규 데이터 파이프라인 개발은 현재진행형입니다. Schema Registry를 이용해 단말 데이터에 스키마를 입히고, 사내 많은 분들이 활발하게 사용 중인 BigQuery에 스트리밍으로 단말 데이터를 적재해야 하는 등 해야 할 일들이 많이 있습니다.&lt;br /&gt;
하지만 첫 술에 배부를 수 없듯이, 이번 목표는 토대를 단단하게 구축하여 어떤 서비스나 프로젝트에 찰떡처럼 붙을 수 있는 파이프라인을 만드는 것이었고, 결과적으로 짧은 시간 안에 소기의 성과를 달성할 수 있었습니다.&lt;/p&gt;

&lt;p&gt;이번에 개선한 신규 단말 파이프라인을 토대로 전사에서 단말 데이터를 더욱 잘 활용할 수 있도록 하고, 더 나아가 유저에게 더 나은 쏘카 서비스 경험을 선물할 수 있도록 앞으로도 모비딕 팀이 계속 노력하겠습니다.&lt;/p&gt;</content><author><name>bada, oliver</name></author><category term="mobility" /><category term="iot" /><category term="data" /><category term="data-engineering" /><summary type="html">Photo by SELİM ARDA ERYILMAZ on Unsplash</summary></entry><entry><title type="html">Android Studio 플러그인으로 코드 자동 리팩토링하기</title><link href="https://tech.socarcorp.kr/dev/2022/02/03/refactoring-with-intellij-plugin.html" rel="alternate" type="text/html" title="Android Studio 플러그인으로 코드 자동 리팩토링하기" /><published>2022-02-03T08:00:00+00:00</published><updated>2022-02-03T08:00:00+00:00</updated><id>https://tech.socarcorp.kr/dev/2022/02/03/refactoring-with-intellij-plugin</id><content type="html" xml:base="https://tech.socarcorp.kr/dev/2022/02/03/refactoring-with-intellij-plugin.html">&lt;p&gt;안녕하세요, 쏘카 안드로이드 팀의 지안입니다.&lt;/p&gt;

&lt;p&gt;리팩토링 작업은 한두 개의 함수를 개선하는 것으로 충분한 때도 있지만, 때로는 여러 개의 파일을 전체적으로 고치고 나서야 끝이 나는 경우도 있습니다.
복잡한 로직이 아닌 단순한 코드 수정 작업이라 생각하여 가볍게 시작하더라도, 리팩토링의 대상이 되는 코드가 곳곳에 사용되고 있다면 처음에 생각한 예상 시간보다 많은 시간이 걸려 난처해지는 경우도 생기곤 합니다.
또한 그 과정에서 처음에는 예상하지 못했던 특이한 케이스라던가, 수정 과정에서 실수로 빠트리는 부분, 반복되는 동일 작업으로 인한 집중력 하락 등으로 인해 일정이 밀리다 보면 ‘리팩토링을 시작하지 말았어야 했나?’ 하는 생각이 드는 경우도 있습니다.&lt;/p&gt;

&lt;p&gt;저희 안드로이드 팀에서도 몇 개월 전, 광범위한 코드에 대한 리팩토링을 수행한 경험이 있습니다.
코드 변환의 규칙은 단순했지만, 수십에서 수백 개 파일에 걸친 변경사항을 하나하나 고치려고 하다 보니 마냥 쉽지만은 않았습니다.
그리고 자칫 길어질 뻔했던 그 반복적인 작업은 IntelliJ Platform Plugin을 통해서 훨씬 수월해질 수 있었습니다.&lt;/p&gt;

&lt;p&gt;당시에 리팩토링 작업을 하며 내부 세미나를 통해 발표했던 내용을, 연말연시를 맞이하여 이 글을 통해 다시금 정리해서 공유해 보고자 합니다.&lt;/p&gt;

&lt;hr /&gt;
&lt;h2 id=&quot;리팩토링을-마음먹게-된-계기&quot;&gt;리팩토링을 마음먹게 된 계기&lt;/h2&gt;
&lt;h3 id=&quot;view-binding으로의-전환&quot;&gt;View Binding으로의 전환&lt;/h3&gt;
&lt;p&gt;안드로이드에서 View에 접근하는 방식은 &lt;a href=&quot;https://medium.com/mobile-app-development-publication/how-android-access-view-item-the-past-to-the-future-bb003ae84527&quot;&gt;계속해서 바뀌어&lt;/a&gt; 왔습니다.
이러한 변화 중에서 현재 가장 이슈가 되고 있는 것은 아무래도 Jetpack Compose의 &lt;a href=&quot;https://android-developers.googleblog.com/2021/07/jetpack-compose-announcement.html&quot;&gt;정식 출시&lt;/a&gt;겠지만, 이 글은 그보다 약간 이전에 있었던 사건에 관한 이야기입니다.&lt;/p&gt;

&lt;p&gt;2020년 말, Kotlin Synthetics 가 Kotlin Android Extensions와 함께 &lt;a href=&quot;https://github.com/JetBrains/kotlin/releases/tag/v1.4.20&quot;&gt;deprecated&lt;/a&gt; 되었습니다.
다행스럽게도 저희는 그 시점에 Kotlin Synthetics를 직접 사용하지 않고 &lt;a href=&quot;https://github.com/JakeWharton/butterknife&quot;&gt;ButterKnife&lt;/a&gt; 기반의 &lt;a href=&quot;https://github.com/Rajin9601/ButterKt&quot;&gt;ButterKt&lt;/a&gt;를 수정해서 활용하고 있었기 때문에 deprecation의 직접적인 영향 없이 Kotlin 버전을 업데이트할 수 있었습니다.
그러나 ButterKnife의 README 파일에도 적혀있듯이, View Binding을 사용하라는 권고는 늘 마음 한편과 기술 부채 목록에 남아있었죠.&lt;/p&gt;

&lt;p&gt;하기야 View에 대한 타입 추론도 잘해주고, 속도도 이전에 비해 빨라지고, View에 대한 구조적인 접근도 가능한 View Binding을 사용하는 것에 딱히 나쁜 점은 없었습니다.
더군다나 이렇게 &lt;a href=&quot;https://developer.android.com/topic/libraries/view-binding/migration&quot;&gt;Migration 가이드&lt;/a&gt;도 제공하고 있고요.&lt;/p&gt;

&lt;p&gt;가이드를 보면서 저희 코드를 기준으로 얼핏 생각해 보았을 때는 기존에 사용하던 아래와 같은 코드를&lt;/p&gt;
&lt;div class=&quot;language-kotlin highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kd&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;SomeActivity&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;BaseActivity&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;py&quot;&gt;maybe_different_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;TextView&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;by&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;bindView&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;R&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;declared_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

  &lt;span class=&quot;k&quot;&gt;fun&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;someFunction&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;..&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;maybe_different_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;text&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;value&quot;&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;이렇게 아래처럼 변경해 주기만 하면 될 것으로 보입니다.&lt;/p&gt;
&lt;div class=&quot;language-kotlin highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kd&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;ChangedActivity&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;BaseActivity&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;fun&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;changedFunction&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;..&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;binding&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;declaredId&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;text&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;value&quot;&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;그러나 이렇게 가벼운 마음으로 작업을 하다 보면 이어지는 절에서 이야기할 번거로운 부분들이 보이기 시작합니다.
혹시 이런 번거로운 부분들을 해결해 줄 더 좋은 Migration 방법이 제공될까 싶어서 기다리다 보니, 어느새 이 작업의 우선순위는 다른 Feature들에 의해 계속해서 밀리게 되었습니다.&lt;/p&gt;

&lt;p&gt;하지만 역설적이게도 우선순위가 높은 Feature 화면의 개발 중에는 여전히 View의 타입이나 XML ID 매칭으로 인한 문제가 종종 발생해서 시간을 소비하곤 했습니다.
결국 이러한 문제로 인해 개발 시간이 불필요하게 늘어나고 있다는 의견에 도달하자 View Binding으로 전환하는 리팩토링을 본격적으로 시작하게 되었습니다.
다만, 무작정 작업에 돌입하기보다는 효율적인 방법에 대해서 생각해 볼 필요가 있었죠.&lt;/p&gt;

&lt;hr /&gt;
&lt;h2 id=&quot;리팩토링-검토&quot;&gt;리팩토링 검토&lt;/h2&gt;
&lt;h3 id=&quot;view-binding-전환에-필요한-것&quot;&gt;View Binding 전환에 필요한 것&lt;/h3&gt;
&lt;p&gt;위에서도 언급했다시피 View Binding으로 리팩토링하는 작업을 위해 요구사항을 정리하다 보면 처음에 가졌던 생각보다 번거로운 지점이 보여서 멈칫멈칫하게 되는 부분들이 있었습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;by bindView&lt;/code&gt; Delegate를 사용하는 변수들을 쓰고 있는 모든 Usage에 대해 이름 변경이 필요하다.&lt;/li&gt;
  &lt;li&gt;기존 방식과는 달리 앞에 &lt;code class=&quot;highlighter-rouge&quot;&gt;binding.&lt;/code&gt;을 붙여서 접근하도록 해야 한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;위의 요구사항만 놓고 보면 단순하게 Regex를 사용해서 치환해도 어떻게든 작업이 가능할 것 같다는 생각이 듭니다.&lt;/p&gt;

&lt;p&gt;그러나 요구사항 검토를 계속해서 진행하다가 아래와 같이 조금 더 까다로운 항목을 발견하게 되면 골치가 아파지기 시작합니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Kotlin 파일에서 &lt;code class=&quot;highlighter-rouge&quot;&gt;bindView&lt;/code&gt;로 사용하고 있는 변수명의 케이스를 변경(&lt;code class=&quot;highlighter-rouge&quot;&gt;snake_case&lt;/code&gt; → &lt;code class=&quot;highlighter-rouge&quot;&gt;lowerCamelCase&lt;/code&gt;)해줘야 한다.&lt;/li&gt;
  &lt;li&gt;만약 XML에 있는 ID(&lt;code class=&quot;highlighter-rouge&quot;&gt;R.id.~&lt;/code&gt;)와 다른 변수명을 사용하고 있다면 XML의 ID를 사용하도록 변경해야 한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;이 시점에서 Regex를 이용한 ‘단순’ 치환은 어렵겠다는 생각이 듭니다.
그래도 Android Studio를 사용하고 있으니 IDE의 기능을 빌어서 &lt;code class=&quot;highlighter-rouge&quot;&gt;Refactoring → Rename&lt;/code&gt; 기능을 시도해 볼 수는 있을 것 같습니다.
변수 하나를 변경하는데 타이핑을 빠르게 하면 5~10초 정도 걸리는 것 같으니 나쁘지는 않아 보입니다.
하지만…&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Activity, Fragment, Custom View를 포함한 뷰 코드 파일들이 백 개가 넘고, 각각의 파일에는 XML ID와 연결되어 있는 변수가 수십 개 있다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;이렇게 되면 하나하나 타이핑해가면서 수동으로 수정하기에는 부담스러운 분량입니다.
수정하는 과정에서 행여나 누락되는 곳이나 실수하는 곳이 있지는 않을지 걱정도 되고요.
단순한 작업이다 싶어서 시작한 일인데 이렇게까지 반복적인 작업을 오랜 시간에 걸쳐서 신경 써가며 작업해야 할까 싶은 생각이 듭니다.&lt;/p&gt;

&lt;p&gt;그렇게 해서 자동으로 Kotlin 코드를 파싱 하여 수정하는 방법들까지도 검토해 보게 되었습니다.&lt;/p&gt;

&lt;h3 id=&quot;사용해-볼-만한-방법들&quot;&gt;사용해 볼 만한 방법들&lt;/h3&gt;
&lt;p&gt;그런 생각을 거쳐서 아래에 있는 다섯 가지 정도의 방법을 떠올리고 간단하게 비교를 진행했습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Android Studio의 Rename 기능을 변수 하나하나에 적용해서 바꾸기&lt;/li&gt;
  &lt;li&gt;Regex를 사용해서 찾아 바꾸기&lt;/li&gt;
  &lt;li&gt;Kotlin Compiler의 &lt;a href=&quot;https://github.com/JetBrains/kotlin/tree/master/compiler/psi/src/org/jetbrains/kotlin/parsing&quot;&gt;Parsing&lt;/a&gt;을 사용하기&lt;/li&gt;
  &lt;li&gt;LSP와 &lt;a href=&quot;https://github.com/fwcd/kotlin-language-server&quot;&gt;비공식 Kotlin Language Server&lt;/a&gt;의 &lt;a href=&quot;https://github.com/fwcd/kotlin-language-server/pull/319&quot;&gt;Rename&lt;/a&gt;을 사용하기&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://plugins.jetbrains.com/docs/intellij/welcome.html&quot;&gt;IntelliJ Platform Plugin&lt;/a&gt;을 만들어서 동작시키기&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;이 중에서 Android Studio의 IDE 기능을 써서 Renaming 하는 방식은 신뢰도가 높고 추가적인 개발이 필요 없지만, 각각의 변수들을 하나하나 수정해야 하므로 작업에 걸리는 시간이 길어진다는 단점이 있었습니다.&lt;/p&gt;

&lt;p&gt;그리고 정규 표현식으로 찾아 바꾸는 작업은 여러 변수나 파일들을 한꺼번에 고칠 수는 있었지만, Reference(Usage)를 명확하게 구분해 내기가 어렵고 정규 표현식을 작성하는 것에도 시간이 많이 소요된다는 문제가 있었습니다.&lt;/p&gt;

&lt;p&gt;Kotlin Compiler를 써서 Parsing 하거나, LSP를 사용해서 수정하는 것은 해당 기능을 개발하기 위해 필요한 배경지식들이 과도하게 많이 필요했습니다.
전체 작업에 드는 시간을 고려하면 변수를 하나하나 바꾸는 데 걸리는 시간이 오히려 비슷하거나 빠를 수도 있겠다는 판단도 들었습니다.
또한 Kotlin Language Server는 아직 &lt;a href=&quot;https://discuss.kotlinlang.org/t/any-plan-for-supporting-language-server-protocol/2471&quot;&gt;공식적으로 제공되지 않고 있으며&lt;/a&gt;, 비공식 Language Server에서는 &lt;a href=&quot;https://github.com/fwcd/kotlin-language-server/pull/319&quot;&gt;Rename 기능에 문제&lt;/a&gt;가 있다는 이야기도 있어서 섣불리 시도해 보기도 어려웠고요.&lt;/p&gt;

&lt;p&gt;반면에 IntelliJ Platform Plugin은 기존에 IDE에서도 사용해왔던 기능들을 그대로 사용할 테니 Reference를 제대로 찾아서 변경해 주는 안정성이 확보되어 있다고 볼 수 있었습니다.
또한 이미 다양한 기능을 가진 플러그인들이 Plugin Marketplace에 올라와 있는 것을 보면 단지 이번 리팩토링뿐만 아니라 다른 기능을 추가해 볼 수도 있을 것이라는 생각도 들었습니다.
물론 개발에 들어가는 시간이 있겠지만 Kotlin Compiler나 LSP를 다루는 것보다는 빠르게 진행할 수 있으리라고 보았습니다.&lt;/p&gt;

&lt;p&gt;앞서 이야기한 몇몇 기준점을 가지고 각각의 방식을 간략하게 비교하면 아래의 표와 같이 정리할 수 있습니다.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: center&quot;&gt; &lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;IntelliJ Rename&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Regex Replace&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Kotlin Parser&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Language Server&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;IntelliJ Plugin&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;대량 수정(자동화)&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;X&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;O&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;O&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;O&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;strong&gt;O&lt;/strong&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Usage 검색 기능&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;O&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;X&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;O&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;O&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;strong&gt;O&lt;/strong&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;포매팅 유지&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;O&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;X&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;?&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;?&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;strong&gt;O&lt;/strong&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;개발에 필요한 시간&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;없음&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;보통&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;많음&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;많음&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;보통&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;확장성&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;낮음&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;낮음&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;보통&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;보통&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;strong&gt;높음&lt;/strong&gt;&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;이러한 비교를 바탕으로 개발 시간이 많이 필요하지 않으면서도 자동화가 가능한 IntelliJ Platform Plugin 방식을 선택했고, 이를 통해 View Binding으로의 리팩토링을 진행해 보기로 했습니다.&lt;/p&gt;

&lt;hr /&gt;
&lt;h2 id=&quot;intellij-platform-plugin&quot;&gt;IntelliJ Platform Plugin&lt;/h2&gt;
&lt;p&gt;그렇다고 하더라도 자료를 찾기 어렵다면 개발 시간이 길어질 것이므로 걱정했지만, 다행스럽게도 JetBrains에서는 공식적으로 IntelliJ Platform에서 사용 가능한 &lt;a href=&quot;https://lp.jetbrains.com/gradle-intellij-plugin/&quot;&gt;플러그인&lt;/a&gt; 개발에 대한 &lt;a href=&quot;https://plugins.jetbrains.com/docs/intellij/welcome.html&quot;&gt;문서&lt;/a&gt;를 제공하고 있었습니다.
이 문서의 &lt;a href=&quot;https://plugins.jetbrains.com/docs/intellij/getting-started.html&quot;&gt;Getting Started 페이지&lt;/a&gt;에 따르면 아래와 같은 방식으로 플러그인을 개발하는 것을 권장하고 있습니다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;There are three supported workflows available for building plugins. The &lt;strong&gt;recommended workflow&lt;/strong&gt; for new projects is to use &lt;a href=&quot;https://github.com/JetBrains/intellij-platform-plugin-template&quot;&gt;GitHub Template&lt;/a&gt; or to use &lt;a href=&quot;https://github.com/JetBrains/gradle-intellij-plugin&quot;&gt;Gradle&lt;/a&gt; to create everything from scratch. The old Plugin DevKit workflow still supports existing projects.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;이렇게 나열된 방식 중에서 비교적 간단하게 개발할 수 있는 방식인 &lt;a href=&quot;https://github.com/JetBrains/intellij-platform-plugin-template&quot;&gt;GitHub Template&lt;/a&gt;를 통해 그 안에 있는 예제 플러그인 코드로부터 개발을 시작했습니다.&lt;/p&gt;

&lt;h3 id=&quot;예제-플러그인-동작-확인&quot;&gt;예제 플러그인 동작 확인&lt;/h3&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/JetBrains/intellij-platform-plugin-template&quot;&gt;링크&lt;/a&gt;로부터 예제 템플릿 레포지토리를 클론 해와서 Android Studio로 열어보면 &lt;code class=&quot;highlighter-rouge&quot;&gt;Run Configurations&lt;/code&gt; 중에 &lt;code class=&quot;highlighter-rouge&quot;&gt;Run Plugin&lt;/code&gt;이라는 항목을 볼 수 있습니다.
그 항목을 선택하고 &lt;code class=&quot;highlighter-rouge&quot;&gt;Run&lt;/code&gt; 버튼을 눌러서 이를 실행시키면 예제 플러그인이 설치되어 동작할 IntelliJ Community Edition이 자동으로 다운로드되고, 그 Sandbox 인스턴스 IDE가 새로 뜨며, 그 위에서 예제 플러그인이 돌아가는 것을 확인해 볼 수 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/JetBrains/intellij-platform-plugin-template/tree/v1.1.0#plugin-configuration-file&quot;&gt;설명&lt;/a&gt;에도 나와있듯이 &lt;code class=&quot;highlighter-rouge&quot;&gt;/src/main/resources/META-INF/plugin.xml&lt;/code&gt; 파일에 &lt;code class=&quot;highlighter-rouge&quot;&gt;applicationService&lt;/code&gt;로 지정된 &lt;code class=&quot;highlighter-rouge&quot;&gt;MyApplicationService.kt&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;projectService&lt;/code&gt;로 지정된 &lt;code class=&quot;highlighter-rouge&quot;&gt;MyProjectService.kt&lt;/code&gt;가 Sandbox IDE의 로드 시점에 수행되며, &lt;code class=&quot;highlighter-rouge&quot;&gt;println&lt;/code&gt;으로 출력하는 메시지가 바깥쪽 IDE의 Run 탭에 출력되는 것을 확인할 수 있었습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/intellij-plugin/sample.png&quot; alt=&quot;기본 예제 확인&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;kotlin-코드-다루기&quot;&gt;Kotlin 코드 다루기&lt;/h3&gt;
&lt;p&gt;하지만 우리가 플러그인을 통해 최종적으로 이름 변경을 하기 위해서는 Kotlin 코드를 인식하고 분석하는 기능이 필요합니다.
기존에 Android Studio를 비롯한 IntelliJ 계열 IDE에도 Renaming 기능이 있기 때문에, 플러그인에도 관련 내용이 있으리라 판단했고, 아니나 다를까 &lt;a href=&quot;https://plugins.jetbrains.com/docs/intellij/kotlin.html#handling-kotlin-code&quot;&gt;이 문서&lt;/a&gt;에서 Kotlin 관련 내용을 찾을 수 있었습니다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;If a plugin processes Kotlin code (e.g., providing inspections), it needs to add a dependency on the Kotlin plugin (Plugin ID &lt;code class=&quot;highlighter-rouge&quot;&gt;org.jetbrains.kotlin&lt;/code&gt;) itself. Please refer to &lt;a href=&quot;https://plugins.jetbrains.com/docs/intellij/plugin-dependencies.html&quot;&gt;Plugin Dependencies&lt;/a&gt; for more information.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;제시된 여러 문서를 따라가 보면 아래의 두 가지 작업으로 귀결됩니다.
우선 &lt;code class=&quot;highlighter-rouge&quot;&gt;plugin.xml&lt;/code&gt;에 아래의 코드를 추가하고,&lt;/p&gt;

&lt;div class=&quot;language-xml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;...
&lt;span class=&quot;nt&quot;&gt;&amp;lt;depends&amp;gt;&lt;/span&gt;org.jetbrains.kotlin&lt;span class=&quot;nt&quot;&gt;&amp;lt;/depends&amp;gt;&lt;/span&gt;
...
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;build.gradle.kts&lt;/code&gt;이 플러그인 의존성 값을 받아오고 있는 &lt;code class=&quot;highlighter-rouge&quot;&gt;gradle.properties&lt;/code&gt; 파일에다가 아래와 같이 &lt;code class=&quot;highlighter-rouge&quot;&gt;java&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;Kotlin&lt;/code&gt; 플러그인 의존성을 추가해서 IntelliJ &lt;strong&gt;Kotlin&lt;/strong&gt; Plugin 의존성을 사용하도록 하면 됩니다.&lt;/p&gt;
&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nn&quot;&gt;...&lt;/span&gt;
&lt;span class=&quot;s&quot;&gt;platformPlugins = ..., java, Kotlin&lt;/span&gt;
&lt;span class=&quot;nn&quot;&gt;...&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;이제 해당 변경사항을 IDE가 인지할 수 있도록 &lt;code class=&quot;highlighter-rouge&quot;&gt;Sync Project with Gradle Files&lt;/code&gt;를 해주면 Kotlin 코드를 다룰 준비가 되었습니다.&lt;/p&gt;

&lt;h3 id=&quot;psi-사용하기&quot;&gt;PSI 사용하기&lt;/h3&gt;
&lt;p&gt;실질적으로 코드를 다루는 작업은 IntelliJ platform에서 제공하는 인터페이스인 &lt;a href=&quot;https://plugins.jetbrains.com/docs/intellij/psi.html&quot;&gt;PSI(Program Structure Interface)&lt;/a&gt;를 통해서 진행합니다.
여기서 PSI란 &lt;a href=&quot;https://plugins.jetbrains.com/docs/intellij/implementing-parser-and-psi.html&quot;&gt;공식 문서&lt;/a&gt;에 적혀있는 것처럼 특정 언어를 다루기 쉽도록 IntelliJ Platform이 파싱한 AST 요소들 위에 부가정보(문법적인 정보나, 언어 특유의 속성)들을 더한 것입니다.
저희는 위에서 적었던 &lt;code class=&quot;highlighter-rouge&quot;&gt;platformPlugins = ..., Kotlin&lt;/code&gt;을 통해서 IntelliJ Kotlin Plugin이 제공하는 Kotlin PSI를 사용할 수 있게 되었습니다.&lt;/p&gt;

&lt;p&gt;즉, 위에서 &lt;code class=&quot;highlighter-rouge&quot;&gt;Kotlin&lt;/code&gt; 의존성을 추가해 줌으로써 &lt;code class=&quot;highlighter-rouge&quot;&gt;org.jetbrains.kotlin.psi.KtClass&lt;/code&gt;와 같이 &lt;code class=&quot;highlighter-rouge&quot;&gt;org.jetbrains.kotlin&lt;/code&gt; 패키지에 있는 내용을 우리가 만드는 플러그인 코드에서 사용할 수 있습니다.
결과적으로 우리가 만드는 플러그인에서 PSI tree에 있는 이 Kotlin PSI Element에 대해 다음과 같은 동작들을 해볼 수 있습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;해당 Element가 Class인지 Property인지 Function인지 판별&lt;/li&gt;
  &lt;li&gt;이 Element를 참조하고 있는 다른 Element로 이동&lt;/li&gt;
  &lt;li&gt;AST에 있는 하위 Element들은 어떤 것들이 있는지 확인&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;모든-ktclass-이름-출력&quot;&gt;모든 KtClass 이름 출력&lt;/h3&gt;
&lt;p&gt;Kotlin PSI를 사용해서 프로젝트에 있는 모든 &lt;code class=&quot;highlighter-rouge&quot;&gt;.kt&lt;/code&gt; 파일에 정의된 Kotlin Class의 이름을 출력해 보려면 아래와 같은 함수를 만들어서 사용해 볼 수 있습니다.&lt;/p&gt;

&lt;div class=&quot;language-kotlin highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;fun&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;printKtClassNames&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;project&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Project&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;project&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;allModules&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;forEach&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;module&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;-&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;nc&quot;&gt;FilenameIndex&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;getAllFilesByExt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;project&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;kt&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;module&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;moduleContentScope&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;mapNotNull&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;it&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;toPsiFile&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;project&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;?&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;KtFile&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
            &lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;flatMap&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ktFile&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ktFile&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;collectDescendantsOfType&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;KtClass&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;&amp;gt;()&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
            &lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;forEach&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ktClass&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;println&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ktClass&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;아래의 스크린샷은 기본 예제 프로젝트의 &lt;code class=&quot;highlighter-rouge&quot;&gt;MyProjectService.kt&lt;/code&gt;파일을 수정한 뒤에 &lt;code class=&quot;highlighter-rouge&quot;&gt;Run Plugin&lt;/code&gt;을 통해 실행된 테스트용 Sandbox IDE에서 동일한 프로젝트를 열었을 때 바깥쪽 IDE에 값들이 출력되는 모습입니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/intellij-plugin/ktclass.png&quot; alt=&quot;KtClass 이름 출력&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Sandbox IDE에서 열린 프로젝트의 &lt;code class=&quot;highlighter-rouge&quot;&gt;KtClass&lt;/code&gt; 이름들이 아래쪽의 콘솔 창에 찍힌 것을 확인해 볼 수 있습니다.
다만 프로젝트가 열리는 시점에는 Indexing이 끝나지 않아 모듈이나 파일 목록들이 아직 구성되지 않은 상태일 수도 있기 때문에 위와 같이 &lt;code class=&quot;highlighter-rouge&quot;&gt;DumbService.getInstance(project).runWhenSmart()&lt;/code&gt;를 사용해서 Indexing이 완료된 후에 실행될 수 있도록 했습니다.&lt;/p&gt;

&lt;h3 id=&quot;특정-프로퍼티-가져오기&quot;&gt;특정 프로퍼티 가져오기&lt;/h3&gt;
&lt;p&gt;그렇다면 &lt;code class=&quot;highlighter-rouge&quot;&gt;KtClass&lt;/code&gt; 내부에 정의된 &lt;code class=&quot;highlighter-rouge&quot;&gt;bindView&lt;/code&gt;를 사용하는 프로퍼티와 연결된 XML ID는 어떻게 가져올 수 있을까요?&lt;/p&gt;

&lt;p&gt;클래스 안에 정의된 프로퍼티를 가져와서 그 PSI tree를 보면서 &lt;code class=&quot;highlighter-rouge&quot;&gt;bindView&lt;/code&gt;를 사용하고 있는지, 그리고 어떤 ID를 사용하는지 확인해 보면 됩니다.
현재 활성화된 파일의 PSI tree가 어떤 식으로 구성되어 있는지 간단하게 확인해 보기 위해 &lt;a href=&quot;https://plugins.jetbrains.com/docs/intellij/explore-api.html#31-use-internal-mode-and-psiviewer&quot;&gt;이 문서&lt;/a&gt;에 나와 있는 것처럼 IntelliJ Plugins Marketplace에 있는 &lt;em&gt;PsiViewer&lt;/em&gt; 플러그인을 사용했습니다.&lt;/p&gt;

&lt;p&gt;해당 플러그인을 사용하면 아래와 같이 현재 커서가 있는 곳의 PSI element가 전체 트리의 어떤 위치에 있는지 파악하는 것이 가능합니다.
&lt;img src=&quot;/assets/images/intellij-plugin/psi-viewer.png&quot; alt=&quot;PsiViewer plugin&quot; /&gt;&lt;/p&gt;

&lt;p&gt;이러한 기능을 바탕으로 PSI tree를 확인해서 우리가 수정할 대상인 &lt;code class=&quot;highlighter-rouge&quot;&gt;bindView&lt;/code&gt; Delegate를 사용하는 프로퍼티 목록을 가져올 수 있습니다.
가져오는 방법은 여러 가지가 있겠지만, 저는 아래와 같은 코드로 접근했습니다.&lt;/p&gt;
&lt;div class=&quot;language-kotlin highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;fun&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;KtClass&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;getBindViewProperties&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;getProperties&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;mapNotNull&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;property&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;-&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;kd&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;py&quot;&gt;bindViewCall&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;property&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;delegate&lt;/span&gt;
            &lt;span class=&quot;o&quot;&gt;?.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;expression&lt;/span&gt;
            &lt;span class=&quot;o&quot;&gt;?.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;castSafelyTo&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;KtCallExpression&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;&amp;gt;()&lt;/span&gt;
            &lt;span class=&quot;o&quot;&gt;?.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;takeIf&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;it&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;referenceExpression&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;?.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;text&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;bindView&quot;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
        &lt;span class=&quot;kd&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;py&quot;&gt;firstArgument&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bindViewCall&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;?.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;valueArgumentList&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;?.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;arguments&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;?.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;first&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;kd&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;py&quot;&gt;xmlId&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;firstArgument&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;?.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;getArgumentExpression&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;?.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lastChild&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;?.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;text&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;xmlId&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;?.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;let&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;BindViewProperty&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;property&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;it&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;kd&quot;&gt;data class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;BindViewProperty&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kd&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;py&quot;&gt;property&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;KtProperty&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;py&quot;&gt;xmlId&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;프로퍼티의-이름을-변경하기&quot;&gt;프로퍼티의 이름을 변경하기&lt;/h3&gt;
&lt;p&gt;위쪽 단락에서 받아온 Kotlin PSI의 &lt;code class=&quot;highlighter-rouge&quot;&gt;KtProperty&lt;/code&gt; 타입은 &lt;code class=&quot;highlighter-rouge&quot;&gt;PsiNamedElement&lt;/code&gt;를 구현한 타입입니다.
따라서 아래와 같이 함수를 만들어서 Reference를 포함한 모든 장소의 이름을 변경하고, 그 변경사항을 반영할 수 있습니다.&lt;/p&gt;

&lt;div class=&quot;language-kotlin highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;fun&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;PsiNamedElement&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;renameAllReferences&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;project&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Project&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;newName&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;updateAndCommit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;project&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;kd&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;py&quot;&gt;files&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;ReferencesSearch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;search&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;map&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;it&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;handleElementRename&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;newName&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;it&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;resolve&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;?.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;containingFile&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;setName&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;newName&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;println&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;[Rename] ${this.elementType} ${this.name} -&amp;gt; $newName&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;files&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;plus&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;containingFile&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;filterNotNull&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;fun&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;updateAndCommit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;project&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Project&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;action&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Iterable&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;PsiFile&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;&amp;gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;nc&quot;&gt;DumbService&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;getInstance&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;project&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;runWhenSmart&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;nc&quot;&gt;WriteCommandAction&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;runWriteCommandAction&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;project&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;kd&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;py&quot;&gt;filesToCommit&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;action&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;filesToCommit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;toSet&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;forEach&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;it&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;commitAndUnblockDocument&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;View binding에서는 snake case 대신에 lower camel case를 사용하므로, 실제 코드에서는 아래와 같이 간단한 변환 함수를 활용해서 &lt;code class=&quot;highlighter-rouge&quot;&gt;renameAllReferences()&lt;/code&gt;를 호출해 주었습니다.&lt;/p&gt;

&lt;div class=&quot;language-kotlin highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;fun&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;snakeToLowerCamelCase&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;split&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sc&quot;&gt;'_'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;joinToString&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;transform&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;capitalize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;decapitalize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;그 밖에도 &lt;code class=&quot;highlighter-rouge&quot;&gt;PsiElement.astReplace&lt;/code&gt;를 활용하면 이름을 변경하는 것을 넘어서 직접 AST를 조작하는 것 또한 가능합니다.
가령 아래와 같이 임의의 &lt;code class=&quot;highlighter-rouge&quot;&gt;PsiElement&lt;/code&gt;를 white space로 변경시킬 수 있습니다.&lt;/p&gt;
&lt;div class=&quot;language-kotlin highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;psiElement&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;astReplace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;PsiWhiteSpaceImpl&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;action으로-등록해서-사용&quot;&gt;Action으로 등록해서 사용&lt;/h3&gt;
&lt;p&gt;앞서 말한 동작들이 프로젝트 로딩 시점마다 매번 실행되는 것은 플러그인이라는 특성상 그다지 바람직하지 않은 일입니다.
따라서 IntelliJ에서는 &lt;a href=&quot;https://plugins.jetbrains.com/docs/intellij/basic-action-system.html&quot;&gt;action&lt;/a&gt;을 등록할 수 있게 해 두었습니다.
&lt;code class=&quot;highlighter-rouge&quot;&gt;plugins.xml&lt;/code&gt;에 아래와 같이 작성하고 &lt;code class=&quot;highlighter-rouge&quot;&gt;Run Plugin&lt;/code&gt;을 돌려서 켜진 Sandbox IntelliJ를 확인해 보면, 상단의 Tools 메뉴 가장 위에 Action이 등록된 것을 볼 수 있습니다.&lt;/p&gt;
&lt;div class=&quot;language-xml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nt&quot;&gt;&amp;lt;actions&amp;gt;&lt;/span&gt;
    ...
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;action&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;class=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;path.to.the.action.class&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;description=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;...&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;id=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;...&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;text=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;...&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;add-to-group&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;anchor=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;first&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;group-id=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;ToolsMenu&quot;&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;/&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;/action&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/actions&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;이제 &lt;code class=&quot;highlighter-rouge&quot;&gt;class&lt;/code&gt;에 지정한 클래스로 가서 Action에서 수행할 내용을 적어주면 됩니다.
저희 플러그인에서는 아래 코드처럼 커서가 있는 &lt;code class=&quot;highlighter-rouge&quot;&gt;KtClass&lt;/code&gt;에 대해서만 리팩토링을 수행하도록 했습니다.&lt;/p&gt;

&lt;div class=&quot;language-kotlin highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kd&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;BindViewRefactoring&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;AnAction&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;override&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;fun&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;update&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;event&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;AnActionEvent&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;// Set the availability based on whether a project is open&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;event&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;presentation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;isEnabledAndVisible&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;event&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;project&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;!=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;null&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;override&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;fun&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;actionPerformed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;event&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;AnActionEvent&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;kd&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;py&quot;&gt;elementAtCursor&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;event&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;getData&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;CommonDataKeys&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;PSI_FILE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;o&quot;&gt;?.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;findElementAt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;event&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;getData&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;CommonDataKeys&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;CARET&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;?.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;offset&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;?:&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;kd&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;py&quot;&gt;targetElement&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;elementAtCursor&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;?.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parentOfType&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;KtClass&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;&amp;gt;()&lt;/span&gt;

        &lt;span class=&quot;nc&quot;&gt;Messages&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;showOkCancelDialog&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;event&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;project&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
            &lt;span class=&quot;s&quot;&gt;&quot;리팩토링 대상: ${targetElement?.name}&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
            &lt;span class=&quot;s&quot;&gt;&quot;View Binding&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
            &lt;span class=&quot;s&quot;&gt;&quot;실행&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
            &lt;span class=&quot;s&quot;&gt;&quot;취소&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
            &lt;span class=&quot;nc&quot;&gt;Messages&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;getInformationIcon&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;let&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;it&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Messages&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;OK&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;targetElement&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;is&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;KtClass&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
                &lt;span class=&quot;nf&quot;&gt;refactorBindViewProperties&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;project&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;!!&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;targetElement&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;hr /&gt;
&lt;h2 id=&quot;마무리하며&quot;&gt;마무리하며&lt;/h2&gt;
&lt;p&gt;이러한 과정을 거쳐서 작성한 플러그인 코드를 빌드 하여 Android Studio에 설치하고, 리팩토링에 빠르게 사용해 볼 수 있었습니다.
&lt;img src=&quot;/assets/images/intellij-plugin/plugin.png&quot; alt=&quot;Android Studio에 설치한 쏘카 플러그인&quot; /&gt;&lt;/p&gt;

&lt;p&gt;또한 작성한 플러그인의 기능에는 전처리/후처리를 좀 더 편하게 할 수 있도록 위에서 언급했던 프로퍼티 변경 기능 외에도 아래와 같은 기능들을 추가했습니다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;View Binding Migration 페이지에 있는 것처럼 레이아웃을 &lt;code class=&quot;highlighter-rouge&quot;&gt;R.layout.~&lt;/code&gt; Resource 대신 &lt;code class=&quot;highlighter-rouge&quot;&gt;...Binding&lt;/code&gt; 클래스로부터 받아와서 초기화하는 코드 삽입 기능&lt;/li&gt;
  &lt;li&gt;IntelliJ에서 제공하는 &lt;code class=&quot;highlighter-rouge&quot;&gt;OptimizeImportsProcessor&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;ReformatCodeProcessor&lt;/code&gt; 등을 사용해서 수정한 코드를 다시 정리하는 기능&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;덕분에 &lt;code class=&quot;highlighter-rouge&quot;&gt;Activity&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;Fragment&lt;/code&gt;, Custom View 등 100개가 넘는 파일에 있던 &lt;code class=&quot;highlighter-rouge&quot;&gt;bindView&lt;/code&gt; 프로퍼티들을 한꺼번에 수정할 수 있었습니다.
PR에서 코드 리뷰 과정을 거치는 도중, View Binding 초기화 코드를 수정하면 좋겠다는 의견이 있어서 이를 전체적으로 반영할 때에도 하나하나 파일을 찾아가며 고칠 필요가 없던 것도 큰 이득이었습니다.&lt;/p&gt;

&lt;p&gt;그뿐만 아니라 현재는 이 플러그인을 확장해서 Live Template으로 하기에는 까다로운 템플릿 코드 기능을 추가하는 등, 더 다양한 형태로 활용하고 있습니다.
이런 식으로 앞으로도 IntelliJ 플러그인을 통해서 개발자들의 소중한 개발 시간을 조금이나마 절약해 볼 수 있으면 좋겠습니다.&lt;/p&gt;

&lt;h3 id=&quot;ps&quot;&gt;P.S.&lt;/h3&gt;
&lt;p&gt;2021년 11월 말, JetBrains에서 차세대 IDE &lt;a href=&quot;https://www.jetbrains.com/fleet/&quot;&gt;Fleet&lt;/a&gt;을 발표했습니다.
짧은 지원자 신청 기간을 거쳐 현재는 Closed Preview를 진행 중인데요, Fleet에서 Plugin 지원은 어떻게 진행할지, Language Server에 대한 정책은 어떻게 바뀔지 흥미롭습니다.
비록 플러그인을 작성하는 방식이 기존과 달라질 수도 있겠지만, 여기서 진행했던 리팩토링 자동화 경험에 약간의 변주만 더한다면 수월하게 작업할 수 있으리라 생각합니다.&lt;/p&gt;</content><author><name>지안</name></author><category term="dev" /><category term="kotlin" /><category term="intellij" /><category term="android-studio" /><category term="plugin" /><summary type="html">안녕하세요, 쏘카 안드로이드 팀의 지안입니다.</summary></entry></feed>